{"cells":[{"metadata":{"id":"svK-Tlf8_t2v"},"cell_type":"markdown","source":"enerate random parameters"},{"metadata":{"id":"vCsgJqhN_t2p","scrolled":true,"trusted":true},"cell_type":"code","source":"#Install a conda package in the current Jupyter kernel\nimport sys\n!conda install --yes --prefix {sys.prefix} numpy\n!conda install --yes --prefix {sys.prefix} tensorflow\n!conda install --yes --prefix {sys.prefix} keras\n!conda install --yes --prefix {sys.prefix} pandas\n!conda install --yes --prefix {sys.prefix} scikit-learn \n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom itertools import combinations\nfrom math import sqrt, isnan\nfrom scipy.io import arff\t\nfrom sklearn.metrics import f1_score as f1\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nimport numpy as np\nimport random\nimport pandas as pd\n","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /srv/conda/envs/notebook\n\n  added / updated specs:\n    - numpy\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n    certifi-2020.12.5          |   py37h89c1867_1         143 KB  conda-forge\n    libblas-3.9.0              |       7_openblas          11 KB  conda-forge\n    libcblas-3.9.0             |       7_openblas          11 KB  conda-forge\n    libgcc-ng-9.3.0            |      h5dbcf3e_17         7.8 MB  conda-forge\n    libgfortran-ng-9.3.0       |      he4bcb1c_17          22 KB  conda-forge\n    libgfortran5-9.3.0         |      he4bcb1c_17         2.0 MB  conda-forge\n    libgomp-9.3.0              |      h5dbcf3e_17         378 KB  conda-forge\n    liblapack-3.9.0            |       7_openblas          11 KB  conda-forge\n    libopenblas-0.3.12         |pthreads_h4812303_1         8.9 MB  conda-forge\n    numpy-1.19.5               |   py37haa41c4c_1         5.3 MB  conda-forge\n    openssl-1.1.1i             |       h7f98852_0         2.1 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        26.8 MB\n\nThe following NEW packages will be INSTALLED:\n\n  libblas            conda-forge/linux-64::libblas-3.9.0-7_openblas\n  libcblas           conda-forge/linux-64::libcblas-3.9.0-7_openblas\n  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-he4bcb1c_17\n  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-he4bcb1c_17\n  liblapack          conda-forge/linux-64::liblapack-3.9.0-7_openblas\n  libopenblas        conda-forge/linux-64::libopenblas-0.3.12-pthreads_h4812303_1\n  numpy              conda-forge/linux-64::numpy-1.19.5-py37haa41c4c_1\n\nThe following packages will be UPDATED:\n\n  ca-certificates                      2020.6.20-hecda079_0 --> 2020.12.5-ha878542_0\n  certifi                          2020.6.20-py37hc8dfbb8_0 --> 2020.12.5-py37h89c1867_1\n  libgcc-ng                                9.2.0-h24d8f2e_2 --> 9.3.0-h5dbcf3e_17\n  libgomp                                  9.2.0-h24d8f2e_2 --> 9.3.0-h5dbcf3e_17\n  openssl                                 1.1.1g-h516909a_0 --> 1.1.1i-h7f98852_0\n\n\n\nDownloading and Extracting Packages\ncertifi-2020.12.5    | 143 KB    | ##################################### | 100% \nca-certificates-2020 | 137 KB    | ##################################### | 100% \nlibgcc-ng-9.3.0      | 7.8 MB    | ##################################### | 100% \nlibopenblas-0.3.12   | 8.9 MB    | ##################################### | 100% \nnumpy-1.19.5         | 5.3 MB    | ##################################### | 100% \nliblapack-3.9.0      | 11 KB     | ##################################### | 100% \nlibcblas-3.9.0       | 11 KB     | ##################################### | 100% \nlibgfortran-ng-9.3.0 | 22 KB     | ##################################### | 100% \nlibblas-3.9.0        | 11 KB     | ##################################### | 100% \nlibgomp-9.3.0        | 378 KB    | ##################################### | 100% \nopenssl-1.1.1i       | 2.1 MB    | ##################################### | 100% \nlibgfortran5-9.3.0   | 2.0 MB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /srv/conda/envs/notebook\n\n  added / updated specs:\n    - tensorflow\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    absl-py-0.11.0             |   py37h89c1867_0         168 KB  conda-forge\n    astor-0.8.1                |     pyh9f0ad1d_0          25 KB  conda-forge\n    c-ares-1.17.1              |       h36c2ea0_0         111 KB  conda-forge\n    cached-property-1.5.1      |             py_0          10 KB  conda-forge\n    gast-0.4.0                 |     pyh9f0ad1d_0          12 KB  conda-forge\n    google-pasta-0.2.0         |     pyh8c360ce_0          42 KB  conda-forge\n    grpcio-1.34.1              |   py37hb27c1af_0         2.0 MB  conda-forge\n    h5py-3.1.0                 |nompi_py37h1e651dc_100         1.2 MB  conda-forge\n    hdf5-1.10.6                |nompi_h6a2412b_1114         3.1 MB  conda-forge\n    keras-applications-1.0.8   |             py_1          30 KB  conda-forge\n    keras-preprocessing-1.1.0  |             py_0          33 KB  conda-forge\n    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n    libprotobuf-3.14.0         |       h780b84a_0         2.5 MB  conda-forge\n    libstdcxx-ng-9.3.0         |      h2ae2ef3_17         4.0 MB  conda-forge\n    markdown-3.3.3             |     pyh9f0ad1d_0          66 KB  conda-forge\n    protobuf-3.14.0            |   py37hcd2ae1e_1         342 KB  conda-forge\n    scipy-1.6.0                |   py37h14a347d_0        20.5 MB  conda-forge\n    tensorboard-1.14.0         |           py37_0         3.2 MB  conda-forge\n    tensorflow-1.14.0          |       h4531e10_0          23 KB  conda-forge\n    tensorflow-base-1.14.0     |   py37h4531e10_0        87.6 MB  conda-forge\n    tensorflow-estimator-1.14.0|   py37h5ca1d4c_0         645 KB  conda-forge\n    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n    werkzeug-1.0.1             |     pyh9f0ad1d_0         239 KB  conda-forge\n    wrapt-1.12.1               |   py37h5e8e339_3          47 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:       126.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n  absl-py            conda-forge/linux-64::absl-py-0.11.0-py37h89c1867_0\n  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\n  c-ares             conda-forge/linux-64::c-ares-1.17.1-h36c2ea0_0\n  cached-property    conda-forge/noarch::cached-property-1.5.1-py_0\n  gast               conda-forge/noarch::gast-0.4.0-pyh9f0ad1d_0\n  google-pasta       conda-forge/noarch::google-pasta-0.2.0-pyh8c360ce_0\n  grpcio             conda-forge/linux-64::grpcio-1.34.1-py37hb27c1af_0\n  h5py               conda-forge/linux-64::h5py-3.1.0-nompi_py37h1e651dc_100\n  hdf5               conda-forge/linux-64::hdf5-1.10.6-nompi_h6a2412b_1114\n  keras-applications conda-forge/noarch::keras-applications-1.0.8-py_1\n  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.0-py_0\n  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n  libprotobuf        conda-forge/linux-64::libprotobuf-3.14.0-h780b84a_0\n  markdown           conda-forge/noarch::markdown-3.3.3-pyh9f0ad1d_0\n  protobuf           conda-forge/linux-64::protobuf-3.14.0-py37hcd2ae1e_1\n  scipy              conda-forge/linux-64::scipy-1.6.0-py37h14a347d_0\n  tensorboard        conda-forge/linux-64::tensorboard-1.14.0-py37_0\n  tensorflow         conda-forge/linux-64::tensorflow-1.14.0-h4531e10_0\n  tensorflow-base    conda-forge/linux-64::tensorflow-base-1.14.0-py37h4531e10_0\n  tensorflow-estima~ conda-forge/linux-64::tensorflow-estimator-1.14.0-py37h5ca1d4c_0\n  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n  werkzeug           conda-forge/noarch::werkzeug-1.0.1-pyh9f0ad1d_0\n  wrapt              conda-forge/linux-64::wrapt-1.12.1-py37h5e8e339_3\n\nThe following packages will be UPDATED:\n\n  libstdcxx-ng                             9.2.0-hdf63c60_2 --> 9.3.0-h2ae2ef3_17\n\n\n\nDownloading and Extracting Packages\nkeras-applications-1 | 30 KB     | ##################################### | 100% \ntermcolor-1.1.0      | 6 KB      | ##################################### | 100% \ngoogle-pasta-0.2.0   | 42 KB     | ##################################### | 100% \ntensorflow-base-1.14 | 87.6 MB   | ##################################### | 100% \ngast-0.4.0           | 12 KB     | ##################################### | 100% \n","name":"stdout"},{"output_type":"stream","text":"libstdcxx-ng-9.3.0   | 4.0 MB    | ##################################### | 100% \nwrapt-1.12.1         | 47 KB     | ##################################### | 100% \nkeras-preprocessing- | 33 KB     | ##################################### | 100% \ngrpcio-1.34.1        | 2.0 MB    | ##################################### | 100% \nlibpng-1.6.37        | 306 KB    | ##################################### | 100% \nlibprotobuf-3.14.0   | 2.5 MB    | ##################################### | 100% \nabsl-py-0.11.0       | 168 KB    | ##################################### | 100% \nhdf5-1.10.6          | 3.1 MB    | ##################################### | 100% \ntensorboard-1.14.0   | 3.2 MB    | ##################################### | 100% \nc-ares-1.17.1        | 111 KB    | ##################################### | 100% \nscipy-1.6.0          | 20.5 MB   | ##################################### | 100% \nmarkdown-3.3.3       | 66 KB     | ##################################### | 100% \nprotobuf-3.14.0      | 342 KB    | ##################################### | 100% \ntensorflow-1.14.0    | 23 KB     | ##################################### | 100% \nh5py-3.1.0           | 1.2 MB    | ##################################### | 100% \ncached-property-1.5. | 10 KB     | ##################################### | 100% \nastor-0.8.1          | 25 KB     | ##################################### | 100% \ntensorflow-estimator | 645 KB    | ##################################### | 100% \nwerkzeug-1.0.1       | 239 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /srv/conda/envs/notebook\n\n  added / updated specs:\n    - keras\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    binutils_impl_linux-64-2.31.1|       h6176602_1         3.9 MB  defaults\n    binutils_linux-64-2.31.1   |       h6176602_9          26 KB  defaults\n    gcc_impl_linux-64-7.3.0    |       habb00fd_1        41.9 MB  defaults\n    gcc_linux-64-7.3.0         |       h553295d_9          27 KB  defaults\n    gxx_impl_linux-64-7.3.0    |       hdf63c60_1        15.0 MB  defaults\n    gxx_linux-64-7.3.0         |       h553295d_9          26 KB  defaults\n    keras-2.3.1                |           py37_0         591 KB  conda-forge\n    libgpuarray-0.7.6          |    h14c3975_1003         263 KB  conda-forge\n    pygpu-0.7.6                |py37h902c9e0_1002         663 KB  conda-forge\n    pyyaml-5.3.1               |   py37h5e8e339_2         199 KB  conda-forge\n    theano-1.0.5               |   py37h745909e_1         3.7 MB  conda-forge\n    yaml-0.2.5                 |       h516909a_0          82 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        66.3 MB\n\nThe following NEW packages will be INSTALLED:\n\n  binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.31.1-h6176602_1\n  binutils_linux-64  pkgs/main/linux-64::binutils_linux-64-2.31.1-h6176602_9\n  gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-7.3.0-habb00fd_1\n  gcc_linux-64       pkgs/main/linux-64::gcc_linux-64-7.3.0-h553295d_9\n  gxx_impl_linux-64  pkgs/main/linux-64::gxx_impl_linux-64-7.3.0-hdf63c60_1\n  gxx_linux-64       pkgs/main/linux-64::gxx_linux-64-7.3.0-h553295d_9\n  keras              conda-forge/linux-64::keras-2.3.1-py37_0\n  libgpuarray        conda-forge/linux-64::libgpuarray-0.7.6-h14c3975_1003\n  pygpu              conda-forge/linux-64::pygpu-0.7.6-py37h902c9e0_1002\n  pyyaml             conda-forge/linux-64::pyyaml-5.3.1-py37h5e8e339_2\n  theano             conda-forge/linux-64::theano-1.0.5-py37h745909e_1\n  yaml               conda-forge/linux-64::yaml-0.2.5-h516909a_0\n\n\n\nDownloading and Extracting Packages\npygpu-0.7.6          | 663 KB    | ##################################### | 100% \ntheano-1.0.5         | 3.7 MB    | ##################################### | 100% \ngxx_impl_linux-64-7. | 15.0 MB   | ##################################### | 100% \ngcc_impl_linux-64-7. | 41.9 MB   | ##################################### | 100% \ngcc_linux-64-7.3.0   | 27 KB     | ##################################### | 100% \npyyaml-5.3.1         | 199 KB    | ##################################### | 100% \nkeras-2.3.1          | 591 KB    | ##################################### | 100% \nyaml-0.2.5           | 82 KB     | ##################################### | 100% \ngxx_linux-64-7.3.0   | 26 KB     | ##################################### | 100% \nlibgpuarray-0.7.6    | 263 KB    | ##################################### | 100% \nbinutils_linux-64-2. | 26 KB     | ##################################### | 100% \nbinutils_impl_linux- | 3.9 MB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /srv/conda/envs/notebook\n\n  added / updated specs:\n    - pandas\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    pandas-1.2.0               |   py37hdc94413_1        11.7 MB  conda-forge\n    pytz-2020.5                |     pyhd8ed1ab_0         244 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        12.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  pandas             conda-forge/linux-64::pandas-1.2.0-py37hdc94413_1\n  pytz               conda-forge/noarch::pytz-2020.5-pyhd8ed1ab_0\n\n\n\nDownloading and Extracting Packages\npytz-2020.5          | 244 KB    | ##################################### | 100% \npandas-1.2.0         | 11.7 MB   | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /srv/conda/envs/notebook\n\n  added / updated specs:\n    - scikit-learn\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    joblib-1.0.0               |     pyhd8ed1ab_0         206 KB  conda-forge\n    scikit-learn-0.24.0        |   py37h69acf81_0         7.5 MB  conda-forge\n    threadpoolctl-2.1.0        |     pyh5ca1d4c_0          15 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         7.7 MB\n\nThe following NEW packages will be INSTALLED:\n\n  joblib             conda-forge/noarch::joblib-1.0.0-pyhd8ed1ab_0\n  scikit-learn       conda-forge/linux-64::scikit-learn-0.24.0-py37h69acf81_0\n  threadpoolctl      conda-forge/noarch::threadpoolctl-2.1.0-pyh5ca1d4c_0\n\n\n\nDownloading and Extracting Packages\njoblib-1.0.0         | 206 KB    | ##################################### | 100% \nscikit-learn-0.24.0  | 7.5 MB    | ##################################### | 100% \nthreadpoolctl-2.1.0  | 15 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","name":"stdout"},{"output_type":"stream","text":"Using TensorFlow backend.\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"id":"_cJamNM__t2v","trusted":true},"cell_type":"code","source":"def SVM_params():\n    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\", \"decision_function_shape\",\n                         \"break_ties\"]\n    default_values=[1.0, \"rbf\", 3,\"scale\", 0.0, True, False, 0.001, 200, None, False, -1, 'ovr', False, None]\n    return default_values","execution_count":2,"outputs":[]},{"metadata":{"id":"dz_ukkbb_t2w","trusted":true},"cell_type":"code","source":"def SVM_paramsRandom():\n    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n    kernel_index = random.randint(0, len(kernel)-1)\n    TF=[True, False]\n    BN=[\"balanced\", None]\n    RN=[random.randint(0, 100), None]\n    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\",\n                         \"decision_function_shape\", \"break_ties\"]\n    random_values=[random.uniform(0,100), kernel[kernel_index], random.randint(0,100), 0.001, random.uniform(0, 1),\n                    TF[random.randint(0,len(TF)-1)], TF[random.randint(0,len(TF)-1)], 0.001, 200,\n                    BN[random.randint(0,len(BN)-1)], TF[random.randint(0,len(TF)-1)], -1, 'ovr',\n                   False,  RN[random.randint(0,len(RN)-1)]]\n    return random_values\ndef KNN_params():\n    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n    default_values=[5, 'uniform', 'auto', 30, 2, 'minkowski', None, None]\n    return default_values\ndef KNN_paramsRandom():\n    weights=['uniform', \"distance\"]\n    metric=['minkowski', 'euclidean', 'manhattan']\n    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n    random_values=[random.randint(1,10),weights[random.randint(0, len(weights)-1)], 'auto',\n                   random.randint(30,100), random.randint(2,10), metric[random.randint(0, len(metric)-1)], None, None]\n    return random_values\ndef LR_params():\n    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\", \"random_state\", \"solver\",\"max_iter\",\n                         \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\", \"l1_ratio\"]\n    default_values=[ 'l2',False, 0.0001,1.0, True, 1, None, None, 'lbfgs', 100, 'auto', 0, False, None, None]\n    return default_values\ndef LR_paramsRandom():\n    penalty=['l1', 'l2', 'elasticnet', None]\n    TF=[True, False]\n    BN=[\"balanced\", None]\n    RN=[random.randint(0, 100), None]\n    l1_ratio=[0,1, random.uniform(0,1),None]\n    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n    s= solver[random.randint(0,len(solver)-1)]\n    if(s==\"lbgs\" or s=='sag'):\n        p='l2'\n    else:\n        p=penalty[random.randint(0,len(penalty)-1)]\n    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\",\n                         \"random_state\", \"solver\",\"max_iter\", \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\",\n                         \"l1_ratio\"]\n    random_values=[ p,TF[random.randint(0,len(TF)-1)], 0.0001,\n                     random.uniform(0,100), True, random.uniform(0,100), BN[random.randint(0,len(BN)-1)],\n                     RN[random.randint(0,len(RN)-1)], s, random.randint(50,200),\n                     'ovr', random.randint(0,20), TF[random.randint(0,len(TF)-1)],\n                     None, l1_ratio[random.randint(0,len(l1_ratio)-1)]]\n    return random_values\ndef RF_params():\n    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n                                          \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\", \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n    default_values=[100,\"gini\",None, 2, 1, 0.0,\"auto\",None,0.0, None, True, False,None,None, 0, False,None,0.0,None ]\n    return default_values\ndef RF_paramsRandom():\n    criterion =[\"gini\", \"entropy\"]\n    max_features=['auto', 'sqrt', 'log2',None]\n    BN= ['balanced', 'balanced_subsample', None]\n    RN=[random.randint(0,100), None]\n    TF=[True,False]\n    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\",\n                         \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n                         \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\",\n                         \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n    random_values=[random.randint(100,200),criterion[random.randint(0,len(criterion)-1)],None,\n                   random.randint(2,10),random.randint(1,10),\n                   0.0,max_features[random.randint(0,len(max_features)-1)],\n                   None,0.0, None, TF[random.randint(0,len(TF)-1)], False,None,\n                   RN[random.randint(0,len(RN)-1)],random.randint(0,100), False,\n                   BN[random.randint(0,len(BN)-1)],0.0,None ]\n    return random_values\ndef DT_params():\n    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n    default_values=[\"gini\",\"best\",None, 2, 1, 0.0,None, None,None,0.0,None,None,0.0]\n    return default_values\ndef DT_paramsRandom():\n    criterion =[\"gini\", \"entropy\"]\n    BN= ['balanced', None]\n    RN=[random.randint(0,100), None]\n    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n    random_values=[criterion[random.randint(0,len(criterion)-1)],\"best\",None,\n                   random.randint(2, 10), random.randint(1, 10),0.0,None, RN[random.randint(0,len(RN)-1)],None,0.0,None,\n                   BN[random.randint(0,len(BN)-1)],0.0]\n    return random_values\ndef ANN_params():\n    return \"\"\ndef ANN_paramsRandom():\n    return [random.randint(10,100)]\n#these functions split the datasets into target and data and return the preprocessed form\ndef BugCatcherDatasetPreprocess():\n    data = arff.loadarff('Bugcatchers-unified-file.arff')\n    BugCatchers= pd.DataFrame(data[0])\n    BugCatchers_data=BugCatchers.iloc[:, 0:6]\n    BugCatchers_target = BugCatchers.iloc[:, 16]\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(BugCatchers_target)\n    BugCatchers_target=label_encoder.transform(BugCatchers_target)\n    BugCatchers_data_normalized = preprocessing.normalize(BugCatchers_data)\n    BugCatchers_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugCatchers_data)\n    BugCatchers_data_standardized= preprocessing.StandardScaler().fit_transform(BugCatchers_data)\n    print( \"Bug Catchers dataset is preprocessed \\n\")\n    return BugCatchers_target,BugCatchers_data_normalized,BugCatchers_data_minmax_scalled,BugCatchers_data_standardized\ndef PromiseDatasetPreprocess():\n    data = arff.loadarff('PROMISE-unified-class.arff')\n    PROMISE = pd.DataFrame(data[0])\n    PROMISE_data = PROMISE.iloc[:, 0:60]\n    PROMISE_target = PROMISE.iloc[:, 80]\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(PROMISE_target)\n    PROMISE_target=label_encoder.transform(PROMISE_target)\n    PROMISE_data_normalized = preprocessing.normalize(PROMISE_data)\n    PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n    PROMISE_data_standardized= preprocessing.StandardScaler().fit_transform(PROMISE_data)\n    print(\"PROMISE dataset is preprocessed \\n\")\n    return PROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized\ndef EclipseDatasetPreprocess():\n    data = arff.loadarff('Zimmerman-unified-file.arff')\n    Eclipse= pd.DataFrame(data[0])\n    Eclipse_data=Eclipse.iloc[:, 0:6]\n    Eclipse_target = Eclipse.iloc[:, 204]\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(Eclipse_target)\n    Eclipse_target=label_encoder.transform(Eclipse_target)\n    Eclipse_data_normalized = preprocessing.normalize(Eclipse_data)\n    Eclipse_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(Eclipse_data)\n    Eclipse_data_standardized= preprocessing.StandardScaler().fit_transform(Eclipse_data)\n    print(\"Eclipse dataset is preprocessed \\n\")\n    return Eclipse_target, Eclipse_data_normalized,Eclipse_data_minmax_scalled,Eclipse_data_standardized\ndef BugPredictionDatasetPreprocess():\n    data = arff.loadarff('BugPrediction-unified-class.arff')\n    BugPrediction= pd.DataFrame(data[0])\n    BugPrediction_data=BugPrediction.iloc[:, 0:60]\n    BugPrediction_target = BugPrediction.iloc[:, 97]\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(BugPrediction_target)\n    BugPrediction_target=label_encoder.transform(BugPrediction_target)\n    BugPrediction_data_normalized = preprocessing.normalize(BugPrediction_data)\n    BugPrediction_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugPrediction_data)\n    BugPrediction_data_standardized= preprocessing.StandardScaler().fit_transform(BugPrediction_data)\n    print( \"Bug Prediction dataset is preprocessed \\n\")\n    return BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized\ndef GitHubFileDatasetPreprocess():\n    data = arff.loadarff('GitHub-unified-file.arff')\n    GitHub_File= pd.DataFrame(data[0])\n    GitHub_File_data=GitHub_File.iloc[:, 0:6]\n    GitHub_File_target = GitHub_File.iloc[:, 10]\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(GitHub_File_target)\n    GitHub_File_target=label_encoder.transform(GitHub_File_target)\n    GitHub_File_data_normalized = preprocessing.normalize(GitHub_File_data)\n    GitHub_File_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_File_data)\n    GitHub_File_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_File_data)\n    print( \"GitHub File dataset is preprocessed \\n\")\n    return GitHub_File_target,GitHub_File_data_normalized,GitHub_File_data_minmax_scalled,GitHub_File_data_standardized\ndef GitHubClassDatasetPreprocess():\n    data = arff.loadarff('GitHub-unified-class.arff')\n    GitHub_class= np.array(dataset['data'])\n    GitHub_class_data=GitHub_class.iloc[:, 0:60]\n    GitHub_class_target = GitHub_class.iloc[:, 60]\n    GitHub_class_data=data\n\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(GitHub_class_target)\n    GitHub_class_target=label_encoder.transform(GitHub_class_target)\n    GitHub_class_data_normalized = preprocessing.normalize(GitHub_class_data)\n    GitHub_class_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_class_data)\n    GitHub_class_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_class_data)\n    print( \"GitHub Class dataset is preprocessed \\n\")\n    return GitHub_class_target,GitHub_class_data_normalized,GitHub_class_data_minmax_scalled,GitHub_class_data_standardized","execution_count":3,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7URJPNv_t20","outputId":"ed11d337-c9c6-46a3-a7ea-df2df9e47428","trusted":true},"cell_type":"code","source":"BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()\nPROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized=PromiseDatasetPreprocess()","execution_count":4,"outputs":[{"output_type":"stream","text":"Bug Prediction dataset is preprocessed \n\nPROMISE dataset is preprocessed \n\n","name":"stdout"}]},{"metadata":{"id":"UH5ANUvF_t24","trusted":true},"cell_type":"code","source":"X=PROMISE_data_normalized\ny=PROMISE_target\ndef balanced_subsample(X,y,  min_elems = 5000):\n    #return a balnced subsample of min_elems of each class\n    x=[]\n    y_s=[]\n    for yi in np.unique(y):\n        elems = X[(y == yi)]\n        np.random.shuffle(elems)\n        for e in elems[0:min_elems,:]:\n            xx=[]\n            for c in e:\n                xx.append(c)\n            x.append(xx)\n        for e in range(0,min_elems):\n            y_s.append(0 if yi == 0 else 1)\n    return x,y_s","execution_count":5,"outputs":[]},{"metadata":{"id":"KsP0VPc6_t24","trusted":true},"cell_type":"code","source":"def generateInitialPopulation(SVM=1, KNN=1, DT=1, RF=1, LR=1, ANN=1):\n    included_clf=[\"SVM\", \"KNN\", \"DT\", \"RF\", \"LR\", \"ANN\"]\n    included=[1,1,1,1,1,1]\n    if(SVM==0):\n        included[0]=0\n    if (KNN == 0):\n        included[1] = 0\n    if (DT == 0):\n        included[2] = 0\n    if (RF == 0):\n        included[3] = 0\n    if (LR == 0):\n        included[4] = 0\n    if (ANN == 0):\n        included[5] = 0\n    in_use=[]\n    combinations_of_clf=[]\n    for i in range(6):\n        if(included[i]==1):\n            in_use.append(included_clf[i])\n    #generate diffrent combinations\n    for i in range(len(in_use)+1):\n        comb= combinations(in_use,i)\n        for j in list(comb):\n            element=[]\n            for k in range(len(j)):\n                element.append(j[k])\n            if element!=[]:\n                combinations_of_clf.append( element)\n    population = []\n    # generate random paramters for all diffrent combinations\n    for combination in list(combinations_of_clf):\n        chromosome = {}\n        for clf in list(combination):\n            genes=[]\n            if(clf==\"SVM\"):\n                genes= SVM_paramsRandom()\n                chromosome[\"SVM\"]=genes\n            if (clf == \"LR\"):\n                genes = LR_paramsRandom()\n                chromosome[\"LR\"]=genes\n            if (clf == \"KNN\"):\n                genes = KNN_paramsRandom()\n                chromosome[\"KNN\"]=genes\n            if (clf == \"RF\"):\n                genes = RF_paramsRandom()\n                chromosome[\"RF\"]=genes\n            if (clf == \"DT\"):\n                genes = DT_paramsRandom()\n                chromosome[\"DT\"]=genes\n            if (clf == \"ANN\"):\n                genes = ANN_paramsRandom()\n                chromosome[\"ANN\"]=genes\n        if population != None:\n            population.append(chromosome)\n        else:\n            population=chromosome\n        #combine into one population and return\n    return population","execution_count":6,"outputs":[]},{"metadata":{"id":"SfjGAGvD_t25","trusted":true},"cell_type":"code","source":"def crossover(parent1, parent2):\n    #Generate random indices\n    index1 = random.randint(0, len(parent1) - 1)\n    index2 = random.randint(0, len(parent2) - 1)\n    offspring1={}\n    #create offspring from 0 to index1 of parent 1 and index2 till the end of parent 2\n    for i in range(0,index1):\n        key = list(parent1)[i]\n        if (offspring1 != {}):\n            count = 0\n            keytoadd =key.split('-')[0]\n            while keytoadd in offspring1.keys():\n                count+=1\n                keytoadd = key.split('-')[0] + \"-\" + str(count)\n            offspring1[keytoadd] = parent1[key]\n        else:\n            offspring1[key] = parent1[key]\n    for j in range(index2,len(parent2)):\n        key = list(parent2)[j]\n        if (offspring1 != {}):\n            count = 0\n            keytoadd =key.split('-')[0]\n            while keytoadd in offspring1.keys():\n                count+=1\n                keytoadd = key.split('-')[0] + \"-\" + str(count)\n            offspring1[keytoadd] = parent2[key]\n        else:\n            offspring1[key] = parent2[key]\n\n    #create offspring from 0 to index2 of parent 2 and index1 till the end of parent 1\n    offspring2={}\n    for i in range(0,index2):\n        key = list(parent2)[i]\n        if(offspring2!={}):\n            count = 0\n            keytoadd =key.split('-')[0]\n            while keytoadd in offspring2.keys():\n                count+=1\n                keytoadd=key.split('-')[0]+\"-\"+str(count)\n            offspring2[keytoadd] = parent2[key]\n        else:\n             offspring2[key]=parent2[key]\n    for j in range(index1,len(parent1)):\n        key = list(parent1)[j]\n        if (offspring2 != {}):\n            count = 0\n            keytoadd =key.split('-')[0]\n            while keytoadd in offspring2.keys():\n                count+=1\n                keytoadd = key.split('-')[0] + \"-\" + str(count)\n            offspring2[keytoadd] = parent1[key]\n        else:\n            offspring2[key] = parent1[key]\n    print(\"offspring1\",offspring1)\n    print(\"offspring2\",offspring2)\n    return offspring1, offspring2","execution_count":7,"outputs":[]},{"metadata":{"id":"5iindbiY_t25","trusted":true},"cell_type":"code","source":"def ANN_model(num=50):\n    from keras.models import Sequential\n    from keras.layers import Dense\n    #create an ANN\n    model =Sequential()\n    model.add(Dense(num, activation='relu', input_shape=[60]))\n    model.add(Dense(int(num/2),activation='relu'))\n    model.add(Dense(2, activation='sigmoid'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics= ['accuracy'])\n    return model","execution_count":8,"outputs":[]},{"metadata":{"id":"WDwsHHDW_t25","trusted":true},"cell_type":"code","source":"\ndef fitness(chromosome,X_train,y_train,X_test,y_test,alpha=1, beta=0,gamma=0, ensemble=\"vote\" ,count=0,gen=0):\n    fitness=0\n    clfs={}\n    for gene in chromosome:\n        # Check the gene classifier and creates a model from the paramters\n        params = chromosome[gene]\n        gene1=gene\n        if(len(gene.split('-'))>1):\n            genecount=gene.split('-')[1]\n            print(genecount)\n        else:\n            genecount=None\n        gene=gene.split('-')[0]\n        clf1=gene\n        if(genecount==None or genecount!='0'):\n            if gene==\"SVM\":\n                clf1=SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n                        coef0=params[4], shrinking=params[5], probability=True,\n                        tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10], max_iter=params[11],\n                        decision_function_shape=params[12])\n            if gene==\"KNN\":\n                clf1=KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n                                         leaf_size=params[3], p=params[4], metric=params[5],\n                                         metric_params=params[6], n_jobs=1)\n            if gene==\"DT\":\n                clf1=DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n                                            min_samples_split=params[3], min_samples_leaf=params[4],\n                                            min_weight_fraction_leaf=params[5], max_features=params[6],\n                                            random_state=params[7], max_leaf_nodes=params[8], min_impurity_decrease=params[9],\n                                            min_impurity_split=params[10], class_weight=params[11])\n            if gene == \"RF\":\n                clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n                                              min_samples_split=params[3], min_samples_leaf=params[4],\n                                              min_weight_fraction_leaf=params[5], max_features=params[6],\n                                              max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n                                              min_impurity_split=params[9],\n                                              bootstrap=params[10], oob_score=params[11], n_jobs=1,\n                                              random_state=params[13], verbose=params[14], warm_start=params[15],\n                                              class_weight=params[16])\n            if gene==\"LR\":\n                clf1=LogisticRegression(penalty='l2',dual=False, tol=params[2], C=params[3], fit_intercept=params[4],\n                                       intercept_scaling=params[5], class_weight=params[6], random_state=params[7], solver=params[8],\n                                       max_iter=params[9], multi_class=params[10], verbose=params[11], warm_start=params[12], n_jobs=1,\n                                      )\n            if gene==\"ANN\":\n                clf1 =KerasClassifier(build_fn=ANN_model,num=params[0], epochs=500, verbose=False)\n                clf1._estimator_type = \"classifier\"\n            clfs[gene1]=clf1\n    estimators=[]\n    for clf in clfs:\n        print(clf)\n        estimators.append((clf,clfs[clf]))\n    if(len(estimators)>0):\n        eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n        eclf.fit(X_train,y_train)\n        y_pred=eclf.predict(X_test)\n\n        #Get confusion matrix and calculate the ACC, MCC AND F1\n        cm=confusion_matrix(y_test, y_pred)\n        TN, FP, FN, TP = cm.ravel()\n        print( cm)\n        accuracy= (TP + TN)/(TP + TN + FP + FN)\n        print(\"accuracy:\",accuracy)\n        mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n        print(\"mcc:\",mcc)\n        precision =(TP/(TP+FP))\n        recall= (TP/(TP+FN))\n        f1_score= 2 *(precision*recall)/(precision+recall)\n        print(\"f1_score:\",f1_score)\n        if isnan(accuracy) or isnan(f1_score):\n            accuracy=0\n        if isnan(mcc):\n            mcc=0\n        if isnan(f1_score):\n            f1_score=0\n        fitness=(((alpha*accuracy)+ (beta*mcc)+(gamma*f1_score)))\n        print(\"Fitness:\",fitness)\n        return fitness, {\"mcc\":[mcc],\"acc\":[accuracy],\"f1\":[f1_score],\"cm\":[cm]},eclf\n    else:\n        return 0,{},None","execution_count":9,"outputs":[]},{"metadata":{"id":"K_-xMWlC_t26","trusted":true},"cell_type":"code","source":"def rename(old_dict,old_name,new_name):\n    new_dict = {}\n    for key,value in zip(old_dict.keys(),old_dict.values()):\n        new_key = key if key != old_name else new_name\n        new_dict[new_key] = old_dict[key]\n    return new_dict","execution_count":10,"outputs":[]},{"metadata":{"id":"o5wesBFd_t26","trusted":true},"cell_type":"code","source":"def Mutation(chromosome,X_train,y_train,X_val,y_val):\n    #Generate random index and set to 0 or 1 accordingly\n    threshold = random.uniform(0, 1)\n    index= random.randint(0,len(chromosome)-1)\n    if(threshold<=0.5):\n        if len(list(chromosome)[index].split('-'))==1:\n            print(\"set to 0\")\n            chromosome= rename(chromosome,list(chromosome)[index], list(chromosome)[index]+\"-0\")\n        elif(( len(list(chromosome)[index].split('-'))>1 and list(chromosome)[index].split('-')[1]=='0') or (len(list(chromosome)[index].split('-'))>2 and (list(chromosome)[index].split('-'))[2]=='0') ):\n            print(\"set to 1\")\n            count = 0\n            key=list(chromosome)[index].split('-')[0]\n            keytoadd = key\n            while keytoadd in chromosome.keys():\n                count+=1\n                keytoadd = key + \"-\" + str(count)\n            chromosome =rename(chromosome,list(chromosome)[index], keytoadd)\n        else:\n            print(\"set to 0\")\n            chromosome = rename(chromosome, list(chromosome)[index], list(chromosome)[index] + \"-0\")\n    else:\n        print(index)\n        gene = list(chromosome)[index]\n        print(gene)\n        clf1 = gene\n        options = []\n        gene1 = list(chromosome)[index]\n        gene=list(chromosome)[index].split('-')[0]\n        if gene == \"SVM\" or gene == \"KNN\" or gene == \"DT\" or gene == \"RF\" or gene == \"LR\" or gene == \"ANN\":\n            if gene == \"SVM\" or gene == \"SVM-0\":\n                clf1 = SVC()\n                c = list(range(1, 1000))\n                c.append(0.01)\n                c.append(0.1)\n                params = {'C': c, 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n                          \"degree\": list(range(0, 100)), 'gamma': [1e-3, 1e-4],\n                          \"coef0\": [x * 0.1 for x in range(0, 10)],\n                          'class_weight': [{0: 0.01}, {1: 1}, {1: 2}, {1: 10}, {1: 50}, 'balanced']}\n            if gene == \"KNN\" or gene == \"KNN-0\":\n                clf1 = KNeighborsClassifier()\n                params = {\"n_neighbors\": list(range(1, 50)), \"weights\": ['uniform', \"distance\"],\n                          \"leaf_size\": list(range(1, 100)), \"p\": [1, 2],\n                          \"metric\": ['minkowski', 'euclidean', 'manhattan']}\n            if gene == \"DT\" or gene == \"DT-0\":\n                clf1 = DecisionTreeClassifier()\n                BN = ['balanced', None]\n                RN = [random.randint(0, 100), None]\n                max_features = ['auto', 'sqrt']\n                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n                max_depth.append(None)\n                min_samples_split = list(range(2, 10))\n                min_samples_leaf = list(range(1, 6))\n                params = {\"criterion\": [\"gini\", \"entropy\"],\n                          'max_features': max_features,\n                          'max_depth': max_depth,\n                          'min_samples_split': min_samples_split,\n                          'min_samples_leaf': min_samples_leaf,\n                          }\n            if gene == \"RF\" or gene == \"RF-0\":\n                clf1 = RandomForestClassifier()\n                n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n                max_features = ['auto', 'sqrt']\n                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n                max_depth.append(None)\n                min_samples_split = list(range(2, 10))\n                min_samples_leaf = list(range(1, 4))\n                bootstrap = [True, False]\n                params = {\"criterion\": [\"gini\", \"entropy\"],\n                          'n_estimators': n_estimators,\n                          'max_features': max_features,\n                          'max_depth': max_depth,\n                          'min_samples_split': min_samples_split,\n                          'min_samples_leaf': min_samples_leaf,\n                          'bootstrap': bootstrap}\n            if gene == \"LR\" or gene == \"LR-0\":\n                clf1 = LogisticRegression()\n                c = list(range(1, 1000))\n                c.append(0.1)\n                c.append(0.001)\n                params = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n                          'penalty': ['l2'],\n                          'C': c}\n            if gene == \"ANN\" or gene == \"ANN-0\":\n                params = {\"num\": list(range(2, 100)), \"epochs\": list(range(400, 600))}\n                clf1 = KerasClassifier(build_fn=ANN_model, epochs=500, verbose=False)\n                clf1._estimator_type = \"classifier\"\n            print(clf1)\n            randomclf = RandomizedSearchCV(estimator=clf1, param_distributions=params,\n                                           n_iter=len(params), cv=5, verbose=2, random_state=42,\n                                           n_jobs=1)\n            search = randomclf.fit(X_train, y_train)\n            param = search.cv_results_\n            options = param['params']\n        if gene1 == \"SVM-0\" or gene1 == \"KNN-0\" or gene1 == \"DT-0\" or gene1 == \"RF-0\" or gene1 == \"LR-0\" or gene1 == \"ANN-0\":\n            options.append(None)\n        clfs = {}\n        eclfs = {}\n        ocount = 0\n        fop = {}\n        ecount = 0\n        # for all other calssifers get the parameters from the chromosomes and generate a new model\n        for option in options:\n            op = {}\n            count = 0\n            for gene in chromosome:\n                op1 = {}\n                params = chromosome[gene]\n                clf1 = gene\n                if count == index:\n                    if option == None:\n                        clf1 = None\n                    if option != None:\n                        gene1=gene\n                        gene=gene.split('-')[0]\n                        if gene == \"SVM\" or gene == \"SVM-0\":\n                            clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], degree=option[\"degree\"],\n                                       gamma=option[\"gamma\"],\n                                       coef0=option[\"coef0\"], shrinking=params[5], probability=True,\n                                       tol=params[7], cache_size=params[8], class_weight=option[\"class_weight\"],\n                                       verbose=params[10],\n                                       max_iter=params[11],\n                                       decision_function_shape=params[12])\n                            # clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], gamma=option[\"gamma\"],\n                            # class_weight=option[\"class_weight\"])\n                            op1[gene1] = [option[\"C\"], option[\"kernel\"], option[\"degree\"], option[\"gamma\"],\n                                          option[\"coef0\"], params[5], True,\n                                          params[7], params[8], option[\"class_weight\"], params[10], params[11],\n                                          params[12]]\n                        if gene == \"KNN\" or gene == \"KNN-0\":\n                            clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"], weights=option[\"weights\"],\n                                                        algorithm=params[2],\n                                                        leaf_size=option[\"leaf_size\"], p=option[\"p\"],\n                                                        metric=option[\"metric\"],\n                                                        metric_params=params[6], n_jobs=1)\n                            op1[gene1] = [option[\"n_neighbors\"], option[\"weights\"], params[2], option[\"leaf_size\"],\n                                          option[\"p\"], option[\"metric\"],\n                                          params[6], 1]\n                            # clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"],\n                            # leaf_size=option[\"leaf_size\"], p=option[\"p\"])\n                            # op1[\"KNN\"]=[option[\"n_neighbors\"],option[\"leaf_size\"],option[\"p\"]]\n                        if gene == \"DT\" or gene == \"DT-0\":\n                            clf1 = DecisionTreeClassifier(criterion=option[\"criterion\"], splitter=params[1],\n                                                          max_depth=option[\"max_depth\"],\n                                                          min_samples_split=option[\"min_samples_split\"],\n                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n                                                          min_weight_fraction_leaf=params[5],\n                                                          max_features=option[\"max_features\"],\n                                                          random_state=params[7], max_leaf_nodes=params[8],\n                                                          min_impurity_decrease=params[9],\n                                                          min_impurity_split=params[10], class_weight=params[11])\n                            op1[gene1] = [option[\"criterion\"], params[1], option[\"max_depth\"],\n                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"], params[5],\n                                         option[\"max_features\"],\n                                         params[7], params[8], params[9], params[10], params[11]]\n                            # clf1 = DecisionTreeClassifier(max_depth=option[\"max_depth\"],\n                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n                            #                               max_features=option[\"max_features\"])\n                            # op1[\"DT\"]=[option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],option[\"max_features\"]]\n                        if gene == \"RF\" or gene == \" RF-0\":\n                            clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"],\n                                                          criterion=option[\"criterion\"], max_depth=option[\"max_depth\"],\n                                                          min_samples_split=option[\"min_samples_split\"],\n                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n                                                          min_weight_fraction_leaf=params[5], max_features=params[6],\n                                                          max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n                                                          min_impurity_split=params[9],\n                                                          bootstrap=option[\"bootstrap\"], oob_score=params[11], n_jobs=1,\n                                                          random_state=params[13], verbose=params[14],\n                                                          warm_start=params[15],\n                                                          class_weight=params[16])\n                            op1[gene1] = [option[\"n_estimators\"], option[\"criterion\"], option[\"max_depth\"],\n                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n                                         params[5], option[\"max_features\"],\n                                         params[7], params[8], params[9], option[\"bootstrap\"], params[11], 1,\n                                         params[13], params[14],\n                                         params[15], params[16]]\n                            # clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"], max_depth=option[\"max_depth\"],\n                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n                            #                               max_features=option[\"max_features\"],\n                            #                               bootstrap=option[\"bootstrap\"])\n                            # op1[\"RF\"]=[option[\"n_estimators\"],option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n                            #            option[\"max_features\"],option[\"bootstrap\"]]\n                        if gene == \"LR\" or gene == \" LR-0\":\n                            clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=option[\"C\"],\n                                                      fit_intercept=params[4],\n                                                      intercept_scaling=params[5], class_weight=params[6],\n                                                      random_state=params[7],\n                                                      solver=option[\"solver\"],\n                                                      max_iter=params[9], multi_class=params[10], verbose=params[11],\n                                                      warm_start=params[12], n_jobs=1,\n                                                      )\n                            op1[gene1] = [\"l2\", False, params[2], option[\"C\"], params[4], params[5], params[6],\n                                         params[7], option[\"solver\"], params[9], params[10], params[11], params[12],\n                                         1, ]\n                            # clf1 = LogisticRegression(penalty='l2', C=option[\"C\"],solver=option[\"solver\"])\n                            # op1[\"LR\"]=[\"l2\",option[\"C\"],option[\"solver\"]]\n                        if gene == \"ANN\" or gene == \"ANN -0\":\n                            clf1 = KerasClassifier(build_fn=ANN_model, num=option[\"num\"],\n                                                                                  epochs=500,\n                                                                                  verbose=False)\n                            clf1._estimator_type = \"classifier\"\n                            op1[gene1] = [option[\"num\"]]\n                else:\n                    if gene == \"SVM\":\n                        clf1 = SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n                                   coef0=params[4], shrinking=params[5], probability=True,\n                                   tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10],\n                                   max_iter=params[11],\n                                   decision_function_shape=params[12])\n                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], True,\n                                      params[7], params[8], params[9], params[10], params[11],\n                                      params[12]]\n                    if gene == \"KNN\":\n                        clf1 = KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n                                                    leaf_size=params[3], p=params[4], metric=params[5],\n                                                    metric_params=params[6], n_jobs=1)\n                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5],\n                                      params[6], 1]\n                    if gene == \"DT\":\n                        clf1 = DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n                                                      random_state=params[7], max_leaf_nodes=params[8],\n                                                      min_impurity_decrease=params[9],\n                                                      min_impurity_split=params[10], class_weight=params[11])\n                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n                                     params[7], params[8], params[9], params[10], params[11]]\n                    if gene == \"RF\":\n                        clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n                                                      max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n                                                      min_impurity_split=params[9],\n                                                      bootstrap=params[10], oob_score=params[11], n_jobs=1,\n                                                      random_state=params[13], verbose=params[14],\n                                                      warm_start=params[15],\n                                                      class_weight=params[16])\n                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n                                     params[7], params[8], params[9], params[10], params[11], 1, params[13], params[14],\n                                     params[15], params[16]]\n                    if gene == \"LR\":\n                        clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=params[3],\n                                                  fit_intercept=params[4],\n                                                  intercept_scaling=params[5], class_weight=params[6],\n                                                  random_state=params[7],\n                                                  solver=params[8],\n                                                  max_iter=params[9], multi_class=params[10], verbose=params[11],\n                                                  warm_start=params[12], n_jobs=1,\n                                                  )\n                        op1[gene1] = [\"l2\", False, params[2], params[3], params[4], params[5], params[6],\n                                     params[7], params[8], params[9], params[10], params[11], params[12], 1, ]\n                    if gene == \"ANN\":\n                        clf1 = KerasClassifier(build_fn=ANN_model, num=params[0],\n                                                                              epochs=500,\n                                                                              verbose=False)\n                        clf1._estimator_type = \"classifier\"\n                        op1[gene1] = [params[0]]\n                op[str(count)] = op1\n                count = count + 1\n                clfs[gene1] = clf1\n            fop[str(ocount)] = op\n            ocount = ocount + 1\n            estimators=[]\n            for clf in clfs:\n              print(clf)\n              estimators.append((clf,clfs[clf]))\n            if(len(estimators)>0):\n              eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n              eclfs[str(ecount)] = eclf\n              ecount = ecount + 1\n        print(fop)\n        print(eclfs)\n\n        # set all the ensembles model in a pipeline to be able to select the best out of them using gridsearch\n        pipe = Pipeline([(\"classifier\", VotingClassifier(estimators=KNeighborsClassifier()))])\n        search_space = []\n        for ens in eclfs:\n            search_space.append({\"classifier\": [eclfs[ens]]})\n        print(search_space)\n        gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=5, n_jobs=1)\n        best_model = gridsearch.fit(X_val, y_val)\n        best = best_model.best_params_\n        print(best)\n        c = 0\n        for ss in eclfs:\n            print({'classifier': eclfs[ss]} == best)\n            if ({'classifier': eclfs[ss]} == best):\n                chromosomes = fop[str(c)]\n                if c == len(eclfs):\n                    index -= 1\n            c = c + 1\n        print(chromosomes)\n\n        # return the best ensemble in the right chromosome form\n        chromosome1 = chromosomes\n        chromosome2 = {}\n        for key in chromosome1:\n            ch = chromosome1[key]\n            for k in ch:\n                chromosome2[k] = ch[k]\n        chromosome = chromosome2\n    print(chromosome)\n    return chromosome","execution_count":11,"outputs":[]},{"metadata":{"id":"jvoLiXNm_t26","trusted":true},"cell_type":"code","source":"def roulette2(poplulation, n, fit_array):\n    fit={}\n    fitness = fit_array\n    for chromosome, i in zip(poplulation, range(0, len(poplulation))):\n        fit[str(chromosome)] = fit_array[i]\n    #calculate total fitness\n    total_fitness = float(sum(fit[str(chromosome)] for chromosome in poplulation))\n    parents=[]\n    weights=[]\n    #generate probability of Fi/sum of weights\n    for  i in range(0, len(fitness)):\n        weights.append(fitness[i] / total_fitness)\n\n    #genrate a random number and return when the chromosome at that weight is reached\n    while n:\n        r = np.random.rand()\n        acc = 0\n        idx = -1\n        while acc < r:\n            idx += 1\n            acc += weights[idx]\n        parents.append(poplulation[idx])\n        n-=1\n    return parents","execution_count":12,"outputs":[]},{"metadata":{"id":"qwgyJsjO_t26","trusted":true},"cell_type":"code","source":"def generateNewPopulation(population,all_fitness, X_train,y_train,X_val,y_val,crossover_prob=0.8, mutation_prob=0.1,elitism_range=0.2):\n    new_population=[]\n    elitism_fitness= all_fitness.copy()\n    elitism_population= population.copy()\n    #copy chromosomes in range of elitism rate and check for repetition\n    for i in range(0, int(elitism_range*len(population))):\n        max_index=elitism_fitness.index(max(elitism_fitness))\n        if(elitism_population[max_index] in new_population):\n            elitism_fitness.pop(max_index)\n            elitism_population.pop(max_index)\n        else:\n            new_population.append(elitism_population[max_index])\n            elitism_fitness.pop(max_index)\n            elitism_population.pop(max_index)\n    print(\"new_population\",new_population)\n\n    #while the length of the new population still has not reach 63 select mutate and crossover chromomsmes\n    while(len(new_population)<len(population)):\n        count = 0\n        parents = roulette2(population,2,all_fitness)\n        if np.random.random() < crossover_prob and len(new_population)<len(population)-1:\n            print(\"crossover\",parents[count])\n            print(\"and\",parents[count+1] )\n            sp1,sp2=crossover(parents[count], parents[count + 1])\n            new_population.append(sp1)\n            new_population.append(sp2)\n        parents = roulette2(population,1,all_fitness)\n        if np.random.random() < mutation_prob and len(new_population)<len(population):\n            print(\"Mutation\", parents[count])\n            try:\n              mutated=Mutation(parents[count],X_train,y_train,X_val,y_val)\n              new_population.append(mutated)\n            except Exception as e:\n                print(e)\n                print(\"not mutated\")\n    return new_population","execution_count":13,"outputs":[]},{"metadata":{"id":"2zD7Lh6X_t27","trusted":true},"cell_type":"code","source":"from numpy import array, savetxt, loadtxt\nfrom numpy import savetxt\nimport tensorflow as tf\nimport pickle\nmods=[]\n","execution_count":14,"outputs":[]},{"metadata":{"id":"yMV4bgaS_t27","trusted":true},"cell_type":"code","source":"def GA( crossover_prob=0.85, mutation_prob=0.15, elitism_range=0.15, max_generation=100, convergence_rate=100):\n    #generate initial population\n    population=generateInitialPopulation()\n    print(\"initial population\", population)\n    gen=0\n    best_fits= {'0': {\"{'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}\": [0.6936, {'mcc': [0.3868607017236362], 'acc': [0.6936], 'f1': [0.683993399339934], 'cm': [array([[905, 367],\n       [399, 829]])]}]}, '1': {\"{'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}\": [0.6892, {'mcc': [0.37873304414332953], 'acc': [0.6892], 'f1': [0.6885771543086171], 'cm': [array([[864, 408],\n       [369, 859]])]}]}, '2': {\"{'DT': ['entropy', 'best', None, 6, 9, 0.0, None, 53, None, 0.0, None, 'balanced', 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [95]}\": [0.692, {'mcc': [0.3843162871199211], 'acc': [0.692], 'f1': [0.6912590216519647], 'cm': [array([[868, 404],\n       [366, 862]])]}]}, '3': {\"{'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}\": [0.6936, {'mcc': [0.38877714769982136], 'acc': [0.6936], 'f1': [0.6666666666666667], 'cm': [array([[968, 304],\n       [462, 766]])]}]}, '4': {\"{'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'RF': [164, 'gini', None, 10, 3, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 72, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}\": [0.692, {'mcc': [0.38450722234769114], 'acc': [0.692], 'f1': [0.6706586826347305], 'cm': [array([[946, 326],\n       [444, 784]])]}]}}\n    models=[]\n    convergence_count=0\n    #split dataset\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n    #while stop conditions not met\n\n    ii=0\n    while gen<max_generation  and convergence_count<convergence_rate:\n        print(\"gen\", gen)\n        print(\"population\", population)\n        all_fitness = []\n        all_mod = []\n        done=[]\n        all_info = []\n        if gen ==5:\n            population =[{'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'RF': [164, 'gini', None, 10, 3, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 72, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'KNN-0': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'DT-0': ['gini', 'best', None, 9, 1, 0.0, None, 37, None, 0.0, None, 'balanced', 0.0], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [128, 'gini', None, 4, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 20, 50, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', True, 0.0001, 7.974803890000159, True, 80.73313721208389, None, 33, 'liblinear', 129, 'ovr', 11, True, None, 0]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'KNN-0': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'DT-1': ['gini', 'best', None, 5, 7, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'ANN': [11]}, {'KNN': [6, 'distance', 'auto', 48, 9, 'minkowski', None, None], 'SVM': [21.056444875724022, 'rbf', 63, 0.001, 0.22322055307593025, False, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'SVM-1': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['entropy', 'best', None, 10, 5, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['elasticnet', True, 0.0001, 50.91514702179476, True, 84.38877360775552, None, None, 'newton-cg', 67, 'ovr', 19, False, None, 1], 'LR-1': ['l2', True, 0.0001, 62.549973805846605, True, 9.211698683897529, 'balanced', 7, 'sag', 184, 'ovr', 16, False, None, 0], 'RF-1': [158, 'gini', None, 6, 2, 0.0, None, None, 0.0, None, False, False, None, 93, 70, False, None, 0.0, None], 'ANN': [45]}, {'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['entropy', 'best', None, 9, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'SVM': [278, 'linear', 86, 0.0001, 0.30000000000000004, True, True, 0.001, 200, {1: 2}, True, -1, 'ovr'], 'DT-1': ['entropy', 'best', 50, 8, 2, 0.0, 'auto', 61, None, 0.0, None, None]}, {'RF-1': [169, 'gini', None, 7, 2, 0.0, None, None, 0.0, None, True, False, None, None, 92, False, 'balanced', 0.0, None], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'RF-0': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'SVM': [278, 'linear', 86, 0.0001, 0.30000000000000004, True, True, 0.001, 200, {1: 2}, True, -1, 'ovr'], 'KNN': [9, 'uniform', 'auto', 67, 6, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM-1': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'SVM-2': [20.523462924341917, 'linear', 61, 0.001, 0.37201088387311465, True, True, 0.001, 200, None, False, -1, 'ovr', False, 7], 'RF': [169, 'gini', None, 10, 2, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 57, False, None, 0.0, None]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'LR': [None, True, 0.0001, 67.23036339050321, True, 50.45074585210586, None, 90, 'saga', 199, 'ovr', 4, False, None, 0]}, {'KNN-0': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'LR': [None, True, 0.0001, 14.016710913204722, True, 14.856574211288187, 'balanced', 14, 'newton-cg', 154, 'ovr', 13, False, None, 0.10979771675791761]}, {'KNN': [6, 'distance', 'auto', 48, 9, 'minkowski', None, None], 'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [151, 'gini', None, 7, 2, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 29, False, None, 0.0, None], 'LR': ['l2', False, 0.0001, 54.69859774842014, True, 15.905429432727614, 'balanced', 40, 'sag', 198, 'ovr', 16, False, None, None], 'LR-1': ['elasticnet', True, 0.0001, 27.40003521845059, True, 69.03694996811329, 'balanced', 25, 'liblinear', 100, 'ovr', 3, False, None, 1]}, {'ANN': [15]}, {'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['entropy', 'best', None, 10, 5, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'KNN': [6, 'distance', 'auto', 60, 5, 'manhattan', None, None], 'LR': [None, False, 0.0001, 35.36509150434214, True, 58.071491913076834, 'balanced', 91, 'saga', 144, 'ovr', 9, False, None, 0.5105945449044219], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'KNN-1': [9, 'uniform', 'auto', 67, 6, 'minkowski', None, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'DT': ['entropy', 'best', None, 9, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'RF': [169, 'gini', None, 7, 2, 0.0, None, None, 0.0, None, True, False, None, None, 92, False, 'balanced', 0.0, None], 'RF-1': [128, 'gini', None, 4, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 20, 50, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', True, 0.0001, 7.974803890000159, True, 80.73313721208389, None, 33, 'liblinear', 129, 'ovr', 11, True, None, 0]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'KNN-1': [6, 'distance', 'auto', 60, 5, 'manhattan', None, None], 'DT-1': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}, {'RF-1': [134, 'gini', None, 9, 1, 0.0, None, None, 0.0, None, False, False, None, None, 90, False, 'balanced_subsample', 0.0, None], 'LR': ['l2', False, 0.0001, 83.65100124415106, True, 33.009388437161114, 'balanced', 9, 'saga', 69, 'ovr', 4, False, None, 1]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['entropy', 'best', None, 9, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'DT-1': ['entropy', 'best', 50, 8, 2, 0.0, 'auto', 61, None, 0.0, None, None]}, {'RF-1': [169, 'gini', None, 7, 2, 0.0, None, None, 0.0, None, True, False, None, None, 92, False, 'balanced', 0.0, None], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'LR': ['elasticnet', False, 0.0001, 59.98191414531681, True, 7.2643157164394845, 'balanced', 34, 'saga', 82, 'ovr', 11, True, None, 0]}, {'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'RF-1': [128, 'gini', None, 4, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 20, 50, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', True, 0.0001, 7.974803890000159, True, 80.73313721208389, None, 33, 'liblinear', 129, 'ovr', 11, True, None, 0]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['entropy', 'best', None, 10, 5, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'ANN': [29]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'SVM-1': [20.523462924341917, 'linear', 61, 0.001, 0.37201088387311465, True, True, 0.001, 200, None, False, -1, 'ovr', False, 7], 'RF': [169, 'gini', None, 10, 2, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 57, False, None, 0.0, None]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'SVM-1': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'SVM-1': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'RF': [164, 'gini', None, 10, 3, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 72, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [134, 'gini', None, 9, 1, 0.0, None, None, 0.0, None, False, False, None, None, 90, False, 'balanced_subsample', 0.0, None], 'LR': ['l2', False, 0.0001, 83.65100124415106, True, 33.009388437161114, 'balanced', 9, 'saga', 69, 'ovr', 4, False, None, 1]}, {'LR': ['elasticnet', True, 0.0001, 85.96012515373184, True, 28.447572405762266, None, 65, 'saga', 85, 'ovr', 17, True, None, 0.7766706104219286], 'SVM': [21.056444875724022, 'rbf', 63, 0.001, 0.22322055307593025, False, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 7, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT-1': ['entropy', 'best', None, 10, 7, 0.0, None, 61, None, 0.0, None, None]}, {'SVM': [21.728331255799528, 'linear', 60, 0.001, 0.015683820140798943, True, False, 0.001, 200, None, False, -1, 'ovr', False, None], 'DT': ['entropy', 'best', None, 9, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'RF': [169, 'gini', None, 7, 2, 0.0, None, None, 0.0, None, True, False, None, None, 92, False, 'balanced', 0.0, None], 'DT-1': ['entropy', 'best', None, 8, 10, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF-1': [134, 'gini', None, 9, 1, 0.0, None, None, 0.0, None, False, False, None, None, 90, False, 'balanced_subsample', 0.0, None], 'RF-2': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-3': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'SVM': [278, 'linear', 86, 0.0001, 0.30000000000000004, True, True, 0.001, 200, {1: 2}, True, -1, 'ovr'], 'LR': ['elasticnet', False, 0.0001, 59.98191414531681, True, 7.2643157164394845, 'balanced', 34, 'saga', 82, 'ovr', 11, True, None, 0]}, {'KNN': [9, 'uniform', 'auto', 67, 6, 'minkowski', None, None], 'LR': [None, True, 0.0001, 67.23036339050321, True, 50.45074585210586, None, 90, 'saga', 199, 'ovr', 4, False, None, 0]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT-2': ['gini', 'best', None, 9, 1, 0.0, None, 37, None, 0.0, None, 'balanced', 0.0], 'RF-3': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'SVM': [21.728331255799528, 'linear', 60, 0.001, 0.015683820140798943, True, False, 0.001, 200, None, False, -1, 'ovr', False, None], 'LR': ['elasticnet', True, 0.0001, 85.96012515373184, True, 28.447572405762266, None, 65, 'saga', 85, 'ovr', 17, True, None, 0.7766706104219286], 'KNN': [6, 'distance', 'auto', 60, 5, 'manhattan', None, None], 'RF': [128, 'gini', None, 4, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 20, 50, False, 'balanced_subsample', 0.0, None], 'LR-1': ['elasticnet', True, 0.0001, 7.974803890000159, True, 80.73313721208389, None, 33, 'liblinear', 129, 'ovr', 11, True, None, 0]}, {'SVM-1': [21.056444875724022, 'rbf', 63, 0.001, 0.22322055307593025, False, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 7, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT-1': ['entropy', 'best', None, 10, 7, 0.0, None, 61, None, 0.0, None, None]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR': ['elasticnet', False, 0.0001, 59.98191414531681, True, 7.2643157164394845, 'balanced', 34, 'saga', 82, 'ovr', 11, True, None, 0]}, {'DT-1': ['gini', 'best', None, 9, 1, 0.0, None, 37, None, 0.0, None, 'balanced', 0.0], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'SVM': [20.523462924341917, 'linear', 61, 0.001, 0.37201088387311465, True, True, 0.001, 200, None, False, -1, 'ovr', False, 7], 'ANN': [11]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'SVM': [20.523462924341917, 'linear', 61, 0.001, 0.37201088387311465, True, True, 0.001, 200, None, False, -1, 'ovr', False, 7], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'RF-1': [134, 'gini', None, 9, 1, 0.0, None, None, 0.0, None, False, False, None, None, 90, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', False, 0.0001, 59.98191414531681, True, 7.2643157164394845, 'balanced', 34, 'saga', 82, 'ovr', 11, True, None, 0]}, {'LR': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}, {'DT-1': ['entropy', 'best', None, 10, 7, 0.0, None, 61, None, 0.0, None, None]}, {'SVM': [21.728331255799528, 'linear', 60, 0.001, 0.015683820140798943, True, False, 0.001, 200, None, False, -1, 'ovr', False, None], 'LR': ['elasticnet', True, 0.0001, 85.96012515373184, True, 28.447572405762266, None, 65, 'saga', 85, 'ovr', 17, True, None, 0.7766706104219286], 'SVM-1': [21.056444875724022, 'rbf', 63, 0.001, 0.22322055307593025, False, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 7, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR-1': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'RF-2': [151, 'gini', None, 7, 2, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 29, False, None, 0.0, None], 'LR-2': ['l2', False, 0.0001, 54.69859774842014, True, 15.905429432727614, 'balanced', 40, 'sag', 198, 'ovr', 16, False, None, None], 'ANN': [15]}, {'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'SVM-1': [27.006377836840322, 'sigmoid', 25, 0.001, 0.15810347644028822, False, True, 0.001, 200, None, False, -1, 'ovr', False, None], 'RF-1': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'SVM-1': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'ANN': [29]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'RF': [1000, 'gini', 10, 6, 3, 0.0, 'sqrt', None, 0.0, None, False, False, 1, 25, 31, False, None], 'LR': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}]\n            all_fitness= [0.6892, 0.6952, 0.6936, 0.69, 0.69, 0.6892, 0.6892, 0.6868, 0.6908, 0.66, 0.668, 0.678, 0.6636, 0.658, 0.69, 0.6896, 0.6144, 0.6384, 0.6728, 0.664, 0.68, 0.67, 0.6832, 0.6856, 0.6672, 0.666, 0.6264, 0.6664, 0.6652, 0.658, 0.6484, 0.6772, 0.674, 0.6816, 0.6632, 0.6784, 0.676, 0.676, 0.6664, 0.6764, 0.6648, 0.68, 0.6476, 0.6592, 0.6912, 0.6604, 0.6492, 0.6596, 0.6728, 0.6424, 0.668, 0.654, 0.6432, 0.626, 0.6484, 0.6924, 0.612, 0.67, 0.6884, 0.6832, 0.6744, 0.646, 0.678]\n            all_info= [{'mcc': [0.3787356176285061], 'acc': [0.6892], 'f1': [0.6686567164179105], 'cm': [array([[939, 333],\n                       [444, 784]])]}, {'mcc': [0.39086561376102064], 'acc': [0.6952], 'f1': [0.6746370623398804], 'cm': [array([[948, 324],\n                       [438, 790]])]}, {'mcc': [0.3880475271821085], 'acc': [0.6936], 'f1': [0.67039586919105], 'cm': [array([[955, 317],\n                       [449, 779]])]}, {'mcc': [0.3799186748190903], 'acc': [0.69], 'f1': [0.6858532630725577], 'cm': [array([[879, 393],\n                       [382, 846]])]}, {'mcc': [0.3799186748190903], 'acc': [0.69], 'f1': [0.6858532630725577], 'cm': [array([[879, 393],\n                       [382, 846]])]}, {'mcc': [0.37873304414332953], 'acc': [0.6892], 'f1': [0.6885771543086171], 'cm': [array([[864, 408],\n                       [369, 859]])]}, {'mcc': [0.3784174635112118], 'acc': [0.6892], 'f1': [0.686060606060606], 'cm': [array([[874, 398],\n                       [379, 849]])]}, {'mcc': [0.3738272554792019], 'acc': [0.6868], 'f1': [0.6854158296504621], 'cm': [array([[864, 408],\n                       [375, 853]])]}, {'mcc': [0.3817325807211173], 'acc': [0.6908], 'f1': [0.6886830447039871], 'cm': [array([[872, 400],\n                       [373, 855]])]}, {'mcc': [0.3197354973493437], 'acc': [0.66], 'f1': [0.6530612244897959], 'cm': [array([[850, 422],\n                       [428, 800]])]}, {'mcc': [0.3359462745734006], 'acc': [0.668], 'f1': [0.6639676113360323], 'cm': [array([[850, 422],\n                       [408, 820]])]}, {'mcc': [0.35692020752675896], 'acc': [0.678], 'f1': [0.6809353943717796], 'cm': [array([[836, 436],\n                       [369, 859]])]}, {'mcc': [0.3269146891624182], 'acc': [0.6636], 'f1': [0.6563138536984062], 'cm': [array([[856, 416],\n                       [425, 803]])]}, {'mcc': [0.32010679586920415], 'acc': [0.658], 'f1': [0.6115402089959109], 'cm': [array([[972, 300],\n                       [555, 673]])]}, {'mcc': [0.3799186748190903], 'acc': [0.69], 'f1': [0.6858532630725577], 'cm': [array([[879, 393],\n                       [382, 846]])]}, {'mcc': [0.3848952875436654], 'acc': [0.6896], 'f1': [0.7062831188493565], 'cm': [array([[791, 481],\n                       [295, 933]])]}, {'mcc': [0.25667185398037184], 'acc': [0.6144], 'f1': [0.47379912663755464], 'cm': [array([[1102,  170],\n                       [ 794,  434]])]}, {'mcc': [0.2809029199610391], 'acc': [0.6384], 'f1': [0.6557501904036558], 'cm': [array([[735, 537],\n                       [367, 861]])]}, {'mcc': [0.34524245229981076], 'acc': [0.6728], 'f1': [0.6585976627712855], 'cm': [array([[893, 379],\n                       [439, 789]])]}, {'mcc': [0.33518543787802385], 'acc': [0.664], 'f1': [0.6863330843913369], 'cm': [array([[741, 531],\n                       [309, 919]])]}, {'mcc': [0.360460188252116], 'acc': [0.68], 'f1': [0.6802557953637091], 'cm': [array([[849, 423],\n                       [377, 851]])]}, {'mcc': [0.3428568292977626], 'acc': [0.67], 'f1': [0.6321890325456978], 'cm': [array([[966, 306],\n                       [519, 709]])]}, {'mcc': [0.36690227481717413], 'acc': [0.6832], 'f1': [0.6837060702875399], 'cm': [array([[852, 420],\n                       [372, 856]])]}, {'mcc': [0.371124438626135], 'acc': [0.6856], 'f1': [0.6683544303797467], 'cm': [array([[922, 350],\n                       [436, 792]])]}, {'mcc': [0.33399946760679206], 'acc': [0.6672], 'f1': [0.6536219816819318], 'cm': [array([[883, 389],\n                       [443, 785]])]}, {'mcc': [0.332726529189035], 'acc': [0.666], 'f1': [0.6383715894326549], 'cm': [array([[928, 344],\n                       [491, 737]])]}, {'mcc': [0.2628240703476843], 'acc': [0.6264], 'f1': [0.5439453125], 'cm': [array([[1009,  263],\n                       [ 671,  557]])]}, {'mcc': [0.33637640527531754], 'acc': [0.6664], 'f1': [0.6246624662466247], 'cm': [array([[972, 300],\n                       [534, 694]])]}, {'mcc': [0.33026373136993703], 'acc': [0.6652], 'f1': [0.6601705237515226], 'cm': [array([[850, 422],\n                       [415, 813]])]}, {'mcc': [0.32010679586920415], 'acc': [0.658], 'f1': [0.6115402089959109], 'cm': [array([[972, 300],\n                       [555, 673]])]}, {'mcc': [0.30058603600018247], 'acc': [0.6484], 'f1': [0.6638623326959846], 'cm': [array([[753, 519],\n                       [360, 868]])]}, {'mcc': [0.354471439961786], 'acc': [0.6772], 'f1': [0.6570335741606459], 'cm': [array([[920, 352],\n                       [455, 773]])]}, {'mcc': [0.3504626576436145], 'acc': [0.674], 'f1': [0.6389011962782455], 'cm': [array([[964, 308],\n                       [507, 721]])]}, {'mcc': [0.3628302889789661], 'acc': [0.6816], 'f1': [0.6710743801652892], 'cm': [array([[892, 380],\n                       [416, 812]])]}, {'mcc': [0.32659711030668037], 'acc': [0.6632], 'f1': [0.6392459297343616], 'cm': [array([[912, 360],\n                       [482, 746]])]}, {'mcc': [0.3584643344341655], 'acc': [0.6784], 'f1': [0.6847058823529412], 'cm': [array([[823, 449],\n                       [355, 873]])]}, {'mcc': [0.3541046586798926], 'acc': [0.676], 'f1': [0.6840873634945398], 'cm': [array([[813, 459],\n                       [351, 877]])]}, {'mcc': [0.3541046586798926], 'acc': [0.676], 'f1': [0.6840873634945398], 'cm': [array([[813, 459],\n                       [351, 877]])]}, {'mcc': [0.3418619951934831], 'acc': [0.6664], 'f1': [0.6073446327683615], 'cm': [array([[1021,  251],\n                       [ 583,  645]])]}, {'mcc': [0.3540801399224088], 'acc': [0.6764], 'f1': [0.6811194324004731], 'cm': [array([[827, 445],\n                       [364, 864]])]}, {'mcc': [0.33363382580295275], 'acc': [0.6648], 'f1': [0.6796636085626911], 'cm': [array([[773, 499],\n                       [339, 889]])]}, {'mcc': [0.36075763006063205], 'acc': [0.68], 'f1': [0.6820349761526231], 'cm': [array([[842, 430],\n                       [370, 858]])]}, {'mcc': [0.299653443758625], 'acc': [0.6476], 'f1': [0.6651463321930825], 'cm': [array([[744, 528],\n                       [353, 875]])]}, {'mcc': [0.32208046747540464], 'acc': [0.6592], 'f1': [0.6148282097649186], 'cm': [array([[968, 304],\n                       [548, 680]])]}, {'mcc': [0.38216082733901297], 'acc': [0.6912], 'f1': [0.6848979591836736], 'cm': [array([[889, 383],\n                       [389, 839]])]}, {'mcc': [0.3264273159805274], 'acc': [0.6604], 'f1': [0.6797434930215014], 'cm': [array([[750, 522],\n                       [327, 901]])]}, {'mcc': [0.3040019094171843], 'acc': [0.6492], 'f1': [0.6696798493408662], 'cm': [array([[734, 538],\n                       [339, 889]])]}, {'mcc': [0.31881392443210294], 'acc': [0.6596], 'f1': [0.6434855467113532], 'cm': [array([[881, 391],\n                       [460, 768]])]}, {'mcc': [0.3520561951873752], 'acc': [0.6728], 'f1': [0.6233885819521179], 'cm': [array([[1005,  267],\n                       [ 551,  677]])]}, {'mcc': [0.29350606074076263], 'acc': [0.6424], 'f1': [0.5734732824427481], 'cm': [array([[1005,  267],\n                       [ 627,  601]])]}, {'mcc': [0.34117536295570494], 'acc': [0.668], 'f1': [0.6210045662100457], 'cm': [array([[990, 282],\n                       [548, 680]])]}, {'mcc': [0.30963454440182525], 'acc': [0.654], 'f1': [0.6177640300486081], 'cm': [array([[936, 336],\n                       [529, 699]])]}, {'mcc': [0.2936844012205513], 'acc': [0.6432], 'f1': [0.6684014869888475], 'cm': [array([[709, 563],\n                       [329, 899]])]}, {'mcc': [0.2621734225667568], 'acc': [0.626], 'f1': [0.5427872860635696], 'cm': [array([[1010,  262],\n                       [ 673,  555]])]}, {'mcc': [0.30135450555754606], 'acc': [0.6484], 'f1': [0.6661602734523357], 'cm': [array([[744, 528],\n                       [351, 877]])]}, {'mcc': [0.3846008322456691], 'acc': [0.6924], 'f1': [0.6867617107942973], 'cm': [array([[888, 384],\n                       [385, 843]])]}, {'mcc': [0.22380442716610888], 'acc': [0.612], 'f1': [0.6056910569105691], 'cm': [array([[785, 487],\n                       [483, 745]])]}, {'mcc': [0.3412102898854775], 'acc': [0.67], 'f1': [0.6745562130177515], 'cm': [array([[820, 452],\n                       [373, 855]])]}, {'mcc': [0.3799223867079487], 'acc': [0.6884], 'f1': [0.6991116261104674], 'cm': [array([[816, 456],\n                       [323, 905]])]}, {'mcc': [0.36725557980369755], 'acc': [0.6832], 'f1': [0.6857142857142856], 'cm': [array([[844, 428],\n                       [364, 864]])]}, {'mcc': [0.34937713524267255], 'acc': [0.6744], 'f1': [0.6754385964912281], 'cm': [array([[839, 433],\n                       [381, 847]])]}, {'mcc': [0.29902176104917616], 'acc': [0.646], 'f1': [0.5843118835133866], 'cm': [array([[993, 279],\n                       [606, 622]])]}, {'mcc': [0.35788174282963137], 'acc': [0.678], 'f1': [0.6464646464646465], 'cm': [array([[959, 313],\n                       [492, 736]])]}]\n        if gen<5:\n            print(gen)\n            print(done)\n        else:\n            for chromosome in population:\n                if chromosome in done:\n                    print(\"chromosome\", chromosome)\n                    fit = all_fitness[done.index(chromosome)]\n                    info = all_info[done.index(chromosome)]\n                    model=all_mod[done.index(chromosome)]\n                    all_fitness.append(fit)\n                    all_info.append(info)\n                    all_mod.append(model)\n                    done.append(chromosome)\n                    print(\"done out of 63\", len(done))\n                else:\n                    print(\"chromosome\", chromosome)\n                    print(ii)\n                    fit, info,model = fitness(chromosome,X_train,y_train,X_test,y_test,count=ii,gen=gen)\n                    all_fitness.append(fit)\n                    all_info.append(info)\n                    all_mod.append(model)\n                    done.append(chromosome)\n                    print(\"done out of 63\", len(done))\n                    if gen ==0 or gen ==99:\n                                ii+=1\n        elif gen >4:\n          #check if converged\n            if best_fits!={} and gen >0:\n                if(str(list(best_fits[str(gen-1)])[0])== str(population[all_fitness.index(max(all_fitness))])):\n                    print(\"converged\")\n                    convergence_count = convergence_count + 1\n                else:\n                    convergence_count=0\n            #get best fit\n            index = all_fitness.index(max(all_fitness))\n            print(\"in gen\",gen)\n            print(\"best fitness\",max(all_fitness))\n            print(\"chromosome\",population[index])\n            best_fits[str(gen)]={str(population[index]):[max(all_fitness),all_info[index]]}\n            print(\"best_fits\",best_fits)\n            print(\"all fitness\",all_fitness)\n            print(\"all_info\",all_info)\n            try:\n                if gen ==0:\n                    models.append(all_mod[index])\n                    emod=all_mod[index]\n                    print(index)\n                    filename = 'gen0_modelexp1.sav'\n                    with open(filename, \"wb\") as file:\n                      pickle.dump(emod, file)\n                if gen == 99:\n                    models.append(all_mod[index])\n                    emod=all_mod[index]\n                    print(index)\n                    filename = 'gen99_modelexp1.sav'\n                    with open(filename, \"wb\") as file:\n                      pickle.dump(emod, file)\n            except Exception as e:\n                print(e)\n                print(\"not saved\")\n            if gen ==99   :\n                mods.append(all_mod[index])\n       \n        gen=gen+1\n        #check stop conditions and generate new data\n        if gen >5 and gen<max_generation and convergence_count<convergence_rate:\n            population=generateNewPopulation(population,X_train=X_train,y_train=y_train,X_val=X_val,y_val=y_val,crossover_prob=crossover_prob,mutation_prob=mutation_prob,elitism_range=elitism_range,all_fitness=all_fitness)\n        #increase mutation rate\n        if (convergence_count >0 and convergence_count% 5==0 ):\n            mutation_prob+=0.1\n            convergence_count=0\n    return best_fits, models","execution_count":15,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQ8NXqAh_t27","outputId":"8c398027-2b3e-4008-c292-137fb254750a","trusted":true},"cell_type":"code","source":"print(mods)","execution_count":16,"outputs":[{"output_type":"stream","text":"[]\n","name":"stdout"}]},{"metadata":{"id":"_2Yp7xXp_t27","trusted":true},"cell_type":"code","source":"#x1, y1=balanced_subsample(X,y,5000)\n#x1=np.array(x1)\n#savetxt('dataexp1x.csv', x1, delimiter=',')\n#savetxt('dataexp1y.csv', y1, delimiter=',')\nX=loadtxt(\"dataexp1x.csv\", delimiter=\",\")\ny=loadtxt(\"dataexp1y.csv\", delimiter=\",\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK-egBac_t27","outputId":"1609e4b6-8acc-4e3c-c175-f6efb5b5713d","scrolled":false,"trusted":false},"cell_type":"markdown","source":"best_fits,models=GA()\nprint(best_fits)\n"},{"metadata":{"id":"dzlOTx-O_t28","trusted":true},"cell_type":"code","source":"chromosome0=best_fits['0']\nchromosome99=best_fits['99']\n","execution_count":null,"outputs":[]},{"metadata":{"id":"yqcDslydVIa1","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"TSKo3xxs_t28"},"cell_type":"markdown","source":"#validate on unseen data"},{"metadata":{"id":"00YD0swt_t28","trusted":true},"cell_type":"code","source":"print(\"equinox\")\ndata = arff.loadarff('Equinox-3.4-OSA.arff')\ndata_value = pd.DataFrame(data[0])\nPROMISE_data = data_value[:, 0:60]\nPROMISE_target = data_value[:,60]\nPROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\nX=PROMISE_data_minmax_scalled\ny=PROMISE_target","execution_count":null,"outputs":[]},{"metadata":{"id":"yS0pk6XO_t28","trusted":true},"cell_type":"code","source":"y_pred0=model0.predict(X)\ncm=confusion_matrix(y, y_pred0)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"SwN-rrvW_t28","trusted":true},"cell_type":"code","source":"y_pred99=model99.predict(X)\ncm=confusion_matrix(y, y_pred99)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"Iq3oMJUJ_t29","trusted":true},"cell_type":"code","source":"print(\"Mylyn\")\ndata = arff.loadarff('Mylyn-3.1-OSA.arff')\ndata_value = pd.DataFrame(data[0])\nPROMISE_data = data_value[:, 0:60]\nPROMISE_target = data_value[:,60]\nPROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\nX=PROMISE_data_minmax_scalled\ny=PROMISE_target\ny_pred0=model0.predict(X)\ncm=confusion_matrix(y, y_pred0)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"rVrSMFQk_t29","trusted":true},"cell_type":"code","source":"y_pred99=model99.predict(X)\ncm=confusion_matrix(y, y_pred99)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"PahiSoP1_t29","trusted":true},"cell_type":"code","source":"print(\"Eclipse_JDT_Core\")\n\ndata = arff.loadarff('Eclipse_JDT_Core-3.4-OSA.arff')\ndata_value = pd.DataFrame(data[0])\nPROMISE_data = data_value[:, 0:60]\nPROMISE_target = data_value[:,60]\nPROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\nX=PROMISE_data_minmax_scalled\ny=PROMISE_target\ny_pred0=model0.predict(X)\ncm=confusion_matrix(y, y_pred0)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"-79qIW_7_t29","trusted":true},"cell_type":"code","source":"y_pred99=model99.predict(X)\ncm=confusion_matrix(y, y_pred99)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"hlvp5_pH_t29","trusted":true},"cell_type":"code","source":"print(\"all\")\nBugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()","execution_count":null,"outputs":[]},{"metadata":{"id":"XvvFVUMT_t2-","trusted":true},"cell_type":"code","source":"X=BugPrediction_data_minmax_scalled\ny=BugPrediction_target\ny_pred0=model0.predict(X)\ncm=confusion_matrix(y, y_pred0)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"DXZ6MsKa_t2-","trusted":true},"cell_type":"code","source":"y_pred99=model99.predict(X)\ncm=confusion_matrix(y, y_pred99)\nTN, FP, FN, TP = cm.ravel()\nprint( cm)\naccuracy= (TP + TN)/(TP + TN + FP + FN)\nprint(\"accuracy:\",accuracy)\nmcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\nprint(\"mcc:\",mcc)\nprecision =(TP/(TP+FP))\nrecall= (TP/(TP+FN))\nf1_score= 2 *(precision*recall)/(precision+recall)\nprint(\"f1_score:\",f1_score)","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"commbined.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svK-Tlf8_t2v"
   },
   "source": [
    "enerate random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vCsgJqhN_t2p",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-769d2d675b51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#!conda install --yes --prefix {sys.prefix} scikit-learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} numpy\n",
    "##!conda install --yes --prefix {sys.prefix} tensorflow\n",
    "#!conda install --yes --prefix {sys.prefix} keras\n",
    "#!conda install --yes --prefix {sys.prefix} pandas\n",
    "#!conda install --yes --prefix {sys.prefix} scikit-learn \n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from itertools import combinations\n",
    "from math import sqrt, isnan\n",
    "from scipy.io import arff\t\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cJamNM__t2v"
   },
   "outputs": [],
   "source": [
    "def SVM_params():\n",
    "    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\", \"decision_function_shape\",\n",
    "                         \"break_ties\"]\n",
    "    default_values=[1.0, \"rbf\", 3,\"scale\", 0.0, True, False, 0.001, 200, None, False, -1, 'ovr', False, None]\n",
    "    return default_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz_ukkbb_t2w"
   },
   "outputs": [],
   "source": [
    "def SVM_paramsRandom():\n",
    "    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    kernel_index = random.randint(0, len(kernel)-1)\n",
    "    TF=[True, False]\n",
    "    BN=[\"balanced\", None]\n",
    "    RN=[random.randint(0, 100), None]\n",
    "    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\",\n",
    "                         \"decision_function_shape\", \"break_ties\"]\n",
    "    random_values=[random.uniform(0,100), kernel[kernel_index], random.randint(0,100), 0.001, random.uniform(0, 1),\n",
    "                    TF[random.randint(0,len(TF)-1)], TF[random.randint(0,len(TF)-1)], 0.001, 200,\n",
    "                    BN[random.randint(0,len(BN)-1)], TF[random.randint(0,len(TF)-1)], -1, 'ovr',\n",
    "                   False,  RN[random.randint(0,len(RN)-1)]]\n",
    "    return random_values\n",
    "def KNN_params():\n",
    "    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n",
    "    default_values=[5, 'uniform', 'auto', 30, 2, 'minkowski', None, None]\n",
    "    return default_values\n",
    "def KNN_paramsRandom():\n",
    "    weights=['uniform', \"distance\"]\n",
    "    metric=['minkowski', 'euclidean', 'manhattan']\n",
    "    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n",
    "    random_values=[random.randint(1,10),weights[random.randint(0, len(weights)-1)], 'auto',\n",
    "                   random.randint(30,100), random.randint(2,10), metric[random.randint(0, len(metric)-1)], None, None]\n",
    "    return random_values\n",
    "def LR_params():\n",
    "    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\", \"random_state\", \"solver\",\"max_iter\",\n",
    "                         \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\", \"l1_ratio\"]\n",
    "    default_values=[ 'l2',False, 0.0001,1.0, True, 1, None, None, 'lbfgs', 100, 'auto', 0, False, None, None]\n",
    "    return default_values\n",
    "def LR_paramsRandom():\n",
    "    penalty=['l1', 'l2', 'elasticnet', None]\n",
    "    TF=[True, False]\n",
    "    BN=[\"balanced\", None]\n",
    "    RN=[random.randint(0, 100), None]\n",
    "    l1_ratio=[0,1, random.uniform(0,1),None]\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    s= solver[random.randint(0,len(solver)-1)]\n",
    "    if(s==\"lbgs\" or s=='sag'):\n",
    "        p='l2'\n",
    "    else:\n",
    "        p=penalty[random.randint(0,len(penalty)-1)]\n",
    "    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\",\n",
    "                         \"random_state\", \"solver\",\"max_iter\", \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\",\n",
    "                         \"l1_ratio\"]\n",
    "    random_values=[ p,TF[random.randint(0,len(TF)-1)], 0.0001,\n",
    "                     random.uniform(0,100), True, random.uniform(0,100), BN[random.randint(0,len(BN)-1)],\n",
    "                     RN[random.randint(0,len(RN)-1)], s, random.randint(50,200),\n",
    "                     'ovr', random.randint(0,20), TF[random.randint(0,len(TF)-1)],\n",
    "                     None, l1_ratio[random.randint(0,len(l1_ratio)-1)]]\n",
    "    return random_values\n",
    "def RF_params():\n",
    "    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n",
    "                                          \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\", \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n",
    "    default_values=[100,\"gini\",None, 2, 1, 0.0,\"auto\",None,0.0, None, True, False,None,None, 0, False,None,0.0,None ]\n",
    "    return default_values\n",
    "def RF_paramsRandom():\n",
    "    criterion =[\"gini\", \"entropy\"]\n",
    "    max_features=['auto', 'sqrt', 'log2',None]\n",
    "    BN= ['balanced', 'balanced_subsample', None]\n",
    "    RN=[random.randint(0,100), None]\n",
    "    TF=[True,False]\n",
    "    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\",\n",
    "                         \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n",
    "                         \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\",\n",
    "                         \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n",
    "    random_values=[random.randint(100,200),criterion[random.randint(0,len(criterion)-1)],None,\n",
    "                   random.randint(2,10),random.randint(1,10),\n",
    "                   0.0,max_features[random.randint(0,len(max_features)-1)],\n",
    "                   None,0.0, None, TF[random.randint(0,len(TF)-1)], False,None,\n",
    "                   RN[random.randint(0,len(RN)-1)],random.randint(0,100), False,\n",
    "                   BN[random.randint(0,len(BN)-1)],0.0,None ]\n",
    "    return random_values\n",
    "def DT_params():\n",
    "    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n",
    "                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n",
    "    default_values=[\"gini\",\"best\",None, 2, 1, 0.0,None, None,None,0.0,None,None,0.0]\n",
    "    return default_values\n",
    "def DT_paramsRandom():\n",
    "    criterion =[\"gini\", \"entropy\"]\n",
    "    BN= ['balanced', None]\n",
    "    RN=[random.randint(0,100), None]\n",
    "    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n",
    "                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n",
    "    random_values=[criterion[random.randint(0,len(criterion)-1)],\"best\",None,\n",
    "                   random.randint(2, 10), random.randint(1, 10),0.0,None, RN[random.randint(0,len(RN)-1)],None,0.0,None,\n",
    "                   BN[random.randint(0,len(BN)-1)],0.0]\n",
    "    return random_values\n",
    "def ANN_params():\n",
    "    return \"\"\n",
    "def ANN_paramsRandom():\n",
    "    return [random.randint(10,100)]\n",
    "#these functions split the datasets into target and data and return the preprocessed form\n",
    "def BugCatcherDatasetPreprocess():\n",
    "    data = arff.loadarff('Bugcatchers-unified-file.arff')\n",
    "    BugCatchers= pd.DataFrame(data[0])\n",
    "    BugCatchers_data=BugCatchers.iloc[:, 0:6]\n",
    "    BugCatchers_target = BugCatchers.iloc[:, 16]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(BugCatchers_target)\n",
    "    BugCatchers_target=label_encoder.transform(BugCatchers_target)\n",
    "    BugCatchers_data_normalized = preprocessing.normalize(BugCatchers_data)\n",
    "    BugCatchers_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugCatchers_data)\n",
    "    BugCatchers_data_standardized= preprocessing.StandardScaler().fit_transform(BugCatchers_data)\n",
    "    print( \"Bug Catchers dataset is preprocessed \\n\")\n",
    "    return BugCatchers_target,BugCatchers_data_normalized,BugCatchers_data_minmax_scalled,BugCatchers_data_standardized\n",
    "def PromiseDatasetPreprocess():\n",
    "    data = arff.loadarff('PROMISE-unified-class.arff')\n",
    "    PROMISE = pd.DataFrame(data[0])\n",
    "    PROMISE_data = PROMISE.iloc[:, 0:60]\n",
    "    PROMISE_target = PROMISE.iloc[:, 80]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(PROMISE_target)\n",
    "    PROMISE_target=label_encoder.transform(PROMISE_target)\n",
    "    PROMISE_data_normalized = preprocessing.normalize(PROMISE_data)\n",
    "    PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "    PROMISE_data_standardized= preprocessing.StandardScaler().fit_transform(PROMISE_data)\n",
    "    print(\"PROMISE dataset is preprocessed \\n\")\n",
    "    return PROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized\n",
    "def EclipseDatasetPreprocess():\n",
    "    data = arff.loadarff('Zimmerman-unified-file.arff')\n",
    "    Eclipse= pd.DataFrame(data[0])\n",
    "    Eclipse_data=Eclipse.iloc[:, 0:6]\n",
    "    Eclipse_target = Eclipse.iloc[:, 204]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(Eclipse_target)\n",
    "    Eclipse_target=label_encoder.transform(Eclipse_target)\n",
    "    Eclipse_data_normalized = preprocessing.normalize(Eclipse_data)\n",
    "    Eclipse_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(Eclipse_data)\n",
    "    Eclipse_data_standardized= preprocessing.StandardScaler().fit_transform(Eclipse_data)\n",
    "    print(\"Eclipse dataset is preprocessed \\n\")\n",
    "    return Eclipse_target, Eclipse_data_normalized,Eclipse_data_minmax_scalled,Eclipse_data_standardized\n",
    "def BugPredictionDatasetPreprocess():\n",
    "    data = arff.loadarff('BugPrediction-unified-class.arff')\n",
    "    BugPrediction= pd.DataFrame(data[0])\n",
    "    BugPrediction_data=BugPrediction.iloc[:, 0:60]\n",
    "    BugPrediction_target = BugPrediction.iloc[:, 97]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(BugPrediction_target)\n",
    "    BugPrediction_target=label_encoder.transform(BugPrediction_target)\n",
    "    BugPrediction_data_normalized = preprocessing.normalize(BugPrediction_data)\n",
    "    BugPrediction_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugPrediction_data)\n",
    "    BugPrediction_data_standardized= preprocessing.StandardScaler().fit_transform(BugPrediction_data)\n",
    "    print( \"Bug Prediction dataset is preprocessed \\n\")\n",
    "    return BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized\n",
    "def GitHubFileDatasetPreprocess():\n",
    "    data = arff.loadarff('GitHub-unified-file.arff')\n",
    "    GitHub_File= pd.DataFrame(data[0])\n",
    "    GitHub_File_data=GitHub_File.iloc[:, 0:6]\n",
    "    GitHub_File_target = GitHub_File.iloc[:, 10]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(GitHub_File_target)\n",
    "    GitHub_File_target=label_encoder.transform(GitHub_File_target)\n",
    "    GitHub_File_data_normalized = preprocessing.normalize(GitHub_File_data)\n",
    "    GitHub_File_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_File_data)\n",
    "    GitHub_File_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_File_data)\n",
    "    print( \"GitHub File dataset is preprocessed \\n\")\n",
    "    return GitHub_File_target,GitHub_File_data_normalized,GitHub_File_data_minmax_scalled,GitHub_File_data_standardized\n",
    "def GitHubClassDatasetPreprocess():\n",
    "    data = arff.loadarff('GitHub-unified-class.arff')\n",
    "    GitHub_class= np.array(dataset['data'])\n",
    "    GitHub_class_data=GitHub_class.iloc[:, 0:60]\n",
    "    GitHub_class_target = GitHub_class.iloc[:, 60]\n",
    "    GitHub_class_data=data\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(GitHub_class_target)\n",
    "    GitHub_class_target=label_encoder.transform(GitHub_class_target)\n",
    "    GitHub_class_data_normalized = preprocessing.normalize(GitHub_class_data)\n",
    "    GitHub_class_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_class_data)\n",
    "    GitHub_class_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_class_data)\n",
    "    print( \"GitHub Class dataset is preprocessed \\n\")\n",
    "    return GitHub_class_target,GitHub_class_data_normalized,GitHub_class_data_minmax_scalled,GitHub_class_data_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7URJPNv_t20",
    "outputId": "ed11d337-c9c6-46a3-a7ea-df2df9e47428"
   },
   "outputs": [],
   "source": [
    "BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()\n",
    "PROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized=PromiseDatasetPreprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UH5ANUvF_t24"
   },
   "outputs": [],
   "source": [
    "X=PROMISE_data_normalized\n",
    "y=PROMISE_target\n",
    "def balanced_subsample(X,y,  min_elems = 5000):\n",
    "    #return a balnced subsample of min_elems of each class\n",
    "    x=[]\n",
    "    y_s=[]\n",
    "    for yi in np.unique(y):\n",
    "        elems = X[(y == yi)]\n",
    "        np.random.shuffle(elems)\n",
    "        for e in elems[0:min_elems,:]:\n",
    "            xx=[]\n",
    "            for c in e:\n",
    "                xx.append(c)\n",
    "            x.append(xx)\n",
    "        for e in range(0,min_elems):\n",
    "            y_s.append(0 if yi == 0 else 1)\n",
    "    return x,y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsP0VPc6_t24"
   },
   "outputs": [],
   "source": [
    "def generateInitialPopulation(SVM=1, KNN=1, DT=1, RF=1, LR=1, ANN=1):\n",
    "    included_clf=[\"SVM\", \"KNN\", \"DT\", \"RF\", \"LR\", \"ANN\"]\n",
    "    included=[1,1,1,1,1,1]\n",
    "    if(SVM==0):\n",
    "        included[0]=0\n",
    "    if (KNN == 0):\n",
    "        included[1] = 0\n",
    "    if (DT == 0):\n",
    "        included[2] = 0\n",
    "    if (RF == 0):\n",
    "        included[3] = 0\n",
    "    if (LR == 0):\n",
    "        included[4] = 0\n",
    "    if (ANN == 0):\n",
    "        included[5] = 0\n",
    "    in_use=[]\n",
    "    combinations_of_clf=[]\n",
    "    for i in range(6):\n",
    "        if(included[i]==1):\n",
    "            in_use.append(included_clf[i])\n",
    "    #generate diffrent combinations\n",
    "    for i in range(len(in_use)+1):\n",
    "        comb= combinations(in_use,i)\n",
    "        for j in list(comb):\n",
    "            element=[]\n",
    "            for k in range(len(j)):\n",
    "                element.append(j[k])\n",
    "            if element!=[]:\n",
    "                combinations_of_clf.append( element)\n",
    "    population = []\n",
    "    # generate random paramters for all diffrent combinations\n",
    "    for combination in list(combinations_of_clf):\n",
    "        chromosome = {}\n",
    "        for clf in list(combination):\n",
    "            genes=[]\n",
    "            if(clf==\"SVM\"):\n",
    "                genes= SVM_paramsRandom()\n",
    "                chromosome[\"SVM\"]=genes\n",
    "            if (clf == \"LR\"):\n",
    "                genes = LR_paramsRandom()\n",
    "                chromosome[\"LR\"]=genes\n",
    "            if (clf == \"KNN\"):\n",
    "                genes = KNN_paramsRandom()\n",
    "                chromosome[\"KNN\"]=genes\n",
    "            if (clf == \"RF\"):\n",
    "                genes = RF_paramsRandom()\n",
    "                chromosome[\"RF\"]=genes\n",
    "            if (clf == \"DT\"):\n",
    "                genes = DT_paramsRandom()\n",
    "                chromosome[\"DT\"]=genes\n",
    "            if (clf == \"ANN\"):\n",
    "                genes = ANN_paramsRandom()\n",
    "                chromosome[\"ANN\"]=genes\n",
    "        if population != None:\n",
    "            population.append(chromosome)\n",
    "        else:\n",
    "            population=chromosome\n",
    "        #combine into one population and return\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfjGAGvD_t25"
   },
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    #Generate random indices\n",
    "    index1 = random.randint(0, len(parent1) - 1)\n",
    "    index2 = random.randint(0, len(parent2) - 1)\n",
    "    offspring1={}\n",
    "    #create offspring from 0 to index1 of parent 1 and index2 till the end of parent 2\n",
    "    for i in range(0,index1):\n",
    "        key = list(parent1)[i]\n",
    "        if (offspring1 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring1.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring1[keytoadd] = parent1[key]\n",
    "        else:\n",
    "            offspring1[key] = parent1[key]\n",
    "    for j in range(index2,len(parent2)):\n",
    "        key = list(parent2)[j]\n",
    "        if (offspring1 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring1.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring1[keytoadd] = parent2[key]\n",
    "        else:\n",
    "            offspring1[key] = parent2[key]\n",
    "\n",
    "    #create offspring from 0 to index2 of parent 2 and index1 till the end of parent 1\n",
    "    offspring2={}\n",
    "    for i in range(0,index2):\n",
    "        key = list(parent2)[i]\n",
    "        if(offspring2!={}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring2.keys():\n",
    "                count+=1\n",
    "                keytoadd=key.split('-')[0]+\"-\"+str(count)\n",
    "            offspring2[keytoadd] = parent2[key]\n",
    "        else:\n",
    "             offspring2[key]=parent2[key]\n",
    "    for j in range(index1,len(parent1)):\n",
    "        key = list(parent1)[j]\n",
    "        if (offspring2 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring2.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring2[keytoadd] = parent1[key]\n",
    "        else:\n",
    "            offspring2[key] = parent1[key]\n",
    "    print(\"offspring1\",offspring1)\n",
    "    print(\"offspring2\",offspring2)\n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iindbiY_t25"
   },
   "outputs": [],
   "source": [
    "def ANN_model(num=50):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create an ANN\n",
    "    model =Sequential()\n",
    "    model.add(Dense(num, activation='relu', input_shape=[60]))\n",
    "    model.add(Dense(int(num/2),activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDwsHHDW_t25"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fitness(chromosome,X_train,y_train,X_test,y_test,alpha=1, beta=0,gamma=0, ensemble=\"vote\" ,count=0,gen=0):\n",
    "    fitness=0\n",
    "    clfs={}\n",
    "    for gene in chromosome:\n",
    "        # Check the gene classifier and creates a model from the paramters\n",
    "        params = chromosome[gene]\n",
    "        gene1=gene\n",
    "        if(len(gene.split('-'))>1):\n",
    "            genecount=gene.split('-')[1]\n",
    "            print(genecount)\n",
    "        else:\n",
    "            genecount=None\n",
    "        gene=gene.split('-')[0]\n",
    "        clf1=gene\n",
    "        if(genecount==None or genecount!='0'):\n",
    "            if gene==\"SVM\":\n",
    "                clf1=SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n",
    "                        coef0=params[4], shrinking=params[5], probability=True,\n",
    "                        tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10], max_iter=params[11],\n",
    "                        decision_function_shape=params[12])\n",
    "            if gene==\"KNN\":\n",
    "                clf1=KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n",
    "                                         leaf_size=params[3], p=params[4], metric=params[5],\n",
    "                                         metric_params=params[6], n_jobs=1)\n",
    "            if gene==\"DT\":\n",
    "                clf1=DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n",
    "                                            min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                            min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                            random_state=params[7], max_leaf_nodes=params[8], min_impurity_decrease=params[9],\n",
    "                                            min_impurity_split=params[10], class_weight=params[11])\n",
    "            if gene == \"RF\":\n",
    "                clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n",
    "                                              min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                              min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                              max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                              min_impurity_split=params[9],\n",
    "                                              bootstrap=params[10], oob_score=params[11], n_jobs=1,\n",
    "                                              random_state=params[13], verbose=params[14], warm_start=params[15],\n",
    "                                              class_weight=params[16])\n",
    "            if gene==\"LR\":\n",
    "                clf1=LogisticRegression(penalty='l2',dual=False, tol=params[2], C=params[3], fit_intercept=params[4],\n",
    "                                       intercept_scaling=params[5], class_weight=params[6], random_state=params[7], solver=params[8],\n",
    "                                       max_iter=params[9], multi_class=params[10], verbose=params[11], warm_start=params[12], n_jobs=1,\n",
    "                                      )\n",
    "            if gene==\"ANN\":\n",
    "                clf1 =KerasClassifier(build_fn=ANN_model,num=params[0], epochs=500, verbose=False)\n",
    "                clf1._estimator_type = \"classifier\"\n",
    "            clfs[gene1]=clf1\n",
    "    estimators=[]\n",
    "    for clf in clfs:\n",
    "        print(clf)\n",
    "        estimators.append((clf,clfs[clf]))\n",
    "    if(len(estimators)>0):\n",
    "        eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n",
    "        eclf.fit(X_train,y_train)\n",
    "        y_pred=eclf.predict(X_test)\n",
    "\n",
    "        #Get confusion matrix and calculate the ACC, MCC AND F1\n",
    "        cm=confusion_matrix(y_test, y_pred)\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        print( cm)\n",
    "        accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "        print(\"accuracy:\",accuracy)\n",
    "        mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "        print(\"mcc:\",mcc)\n",
    "        precision =(TP/(TP+FP))\n",
    "        recall= (TP/(TP+FN))\n",
    "        f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "        print(\"f1_score:\",f1_score)\n",
    "        if isnan(accuracy) or isnan(f1_score):\n",
    "            accuracy=0\n",
    "        if isnan(mcc):\n",
    "            mcc=0\n",
    "        if isnan(f1_score):\n",
    "            f1_score=0\n",
    "        fitness=(((alpha*accuracy)+ (beta*mcc)+(gamma*f1_score)))\n",
    "        print(\"Fitness:\",fitness)\n",
    "        return fitness, {\"mcc\":[mcc],\"acc\":[accuracy],\"f1\":[f1_score],\"cm\":[cm]},eclf\n",
    "    else:\n",
    "        return 0,{},None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_-xMWlC_t26"
   },
   "outputs": [],
   "source": [
    "def rename(old_dict,old_name,new_name):\n",
    "    new_dict = {}\n",
    "    for key,value in zip(old_dict.keys(),old_dict.values()):\n",
    "        new_key = key if key != old_name else new_name\n",
    "        new_dict[new_key] = old_dict[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5wesBFd_t26"
   },
   "outputs": [],
   "source": [
    "def Mutation(chromosome,X_train,y_train,X_val,y_val):\n",
    "    #Generate random index and set to 0 or 1 accordingly\n",
    "    threshold = random.uniform(0, 1)\n",
    "    index= random.randint(0,len(chromosome)-1)\n",
    "    if(threshold<=0.5):\n",
    "        if len(list(chromosome)[index].split('-'))==1:\n",
    "            print(\"set to 0\")\n",
    "            chromosome= rename(chromosome,list(chromosome)[index], list(chromosome)[index]+\"-0\")\n",
    "        elif(( len(list(chromosome)[index].split('-'))>1 and list(chromosome)[index].split('-')[1]=='0') or (len(list(chromosome)[index].split('-'))>2 and (list(chromosome)[index].split('-'))[2]=='0') ):\n",
    "            print(\"set to 1\")\n",
    "            count = 0\n",
    "            key=list(chromosome)[index].split('-')[0]\n",
    "            keytoadd = key\n",
    "            while keytoadd in chromosome.keys():\n",
    "                count+=1\n",
    "                keytoadd = key + \"-\" + str(count)\n",
    "            chromosome =rename(chromosome,list(chromosome)[index], keytoadd)\n",
    "        else:\n",
    "            print(\"set to 0\")\n",
    "            chromosome = rename(chromosome, list(chromosome)[index], list(chromosome)[index] + \"-0\")\n",
    "    else:\n",
    "        print(index)\n",
    "        gene = list(chromosome)[index]\n",
    "        print(gene)\n",
    "        clf1 = gene\n",
    "        options = []\n",
    "        gene1 = list(chromosome)[index]\n",
    "        gene=list(chromosome)[index].split('-')[0]\n",
    "        if gene == \"SVM\" or gene == \"KNN\" or gene == \"DT\" or gene == \"RF\" or gene == \"LR\" or gene == \"ANN\":\n",
    "            if gene == \"SVM\" or gene == \"SVM-0\":\n",
    "                clf1 = SVC()\n",
    "                c = list(range(1, 1000))\n",
    "                c.append(0.01)\n",
    "                c.append(0.1)\n",
    "                params = {'C': c, 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                          \"degree\": list(range(0, 100)), 'gamma': [1e-3, 1e-4],\n",
    "                          \"coef0\": [x * 0.1 for x in range(0, 10)],\n",
    "                          'class_weight': [{0: 0.01}, {1: 1}, {1: 2}, {1: 10}, {1: 50}, 'balanced']}\n",
    "            if gene == \"KNN\" or gene == \"KNN-0\":\n",
    "                clf1 = KNeighborsClassifier()\n",
    "                params = {\"n_neighbors\": list(range(1, 50)), \"weights\": ['uniform', \"distance\"],\n",
    "                          \"leaf_size\": list(range(1, 100)), \"p\": [1, 2],\n",
    "                          \"metric\": ['minkowski', 'euclidean', 'manhattan']}\n",
    "            if gene == \"DT\" or gene == \"DT-0\":\n",
    "                clf1 = DecisionTreeClassifier()\n",
    "                BN = ['balanced', None]\n",
    "                RN = [random.randint(0, 100), None]\n",
    "                max_features = ['auto', 'sqrt']\n",
    "                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "                max_depth.append(None)\n",
    "                min_samples_split = list(range(2, 10))\n",
    "                min_samples_leaf = list(range(1, 6))\n",
    "                params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                          'max_features': max_features,\n",
    "                          'max_depth': max_depth,\n",
    "                          'min_samples_split': min_samples_split,\n",
    "                          'min_samples_leaf': min_samples_leaf,\n",
    "                          }\n",
    "            if gene == \"RF\" or gene == \"RF-0\":\n",
    "                clf1 = RandomForestClassifier()\n",
    "                n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "                max_features = ['auto', 'sqrt']\n",
    "                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "                max_depth.append(None)\n",
    "                min_samples_split = list(range(2, 10))\n",
    "                min_samples_leaf = list(range(1, 4))\n",
    "                bootstrap = [True, False]\n",
    "                params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                          'n_estimators': n_estimators,\n",
    "                          'max_features': max_features,\n",
    "                          'max_depth': max_depth,\n",
    "                          'min_samples_split': min_samples_split,\n",
    "                          'min_samples_leaf': min_samples_leaf,\n",
    "                          'bootstrap': bootstrap}\n",
    "            if gene == \"LR\" or gene == \"LR-0\":\n",
    "                clf1 = LogisticRegression()\n",
    "                c = list(range(1, 1000))\n",
    "                c.append(0.1)\n",
    "                c.append(0.001)\n",
    "                params = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                          'penalty': ['l2'],\n",
    "                          'C': c}\n",
    "            if gene == \"ANN\" or gene == \"ANN-0\":\n",
    "                params = {\"num\": list(range(2, 100)), \"epochs\": list(range(400, 600))}\n",
    "                clf1 = KerasClassifier(build_fn=ANN_model, epochs=500, verbose=False)\n",
    "                clf1._estimator_type = \"classifier\"\n",
    "            print(clf1)\n",
    "            randomclf = RandomizedSearchCV(estimator=clf1, param_distributions=params,\n",
    "                                           n_iter=len(params), cv=5, verbose=2, random_state=42,\n",
    "                                           n_jobs=1)\n",
    "            search = randomclf.fit(X_train, y_train)\n",
    "            param = search.cv_results_\n",
    "            options = param['params']\n",
    "        if gene1 == \"SVM-0\" or gene1 == \"KNN-0\" or gene1 == \"DT-0\" or gene1 == \"RF-0\" or gene1 == \"LR-0\" or gene1 == \"ANN-0\":\n",
    "            options.append(None)\n",
    "        clfs = {}\n",
    "        eclfs = {}\n",
    "        ocount = 0\n",
    "        fop = {}\n",
    "        ecount = 0\n",
    "        # for all other calssifers get the parameters from the chromosomes and generate a new model\n",
    "        for option in options:\n",
    "            op = {}\n",
    "            count = 0\n",
    "            for gene in chromosome:\n",
    "                op1 = {}\n",
    "                params = chromosome[gene]\n",
    "                clf1 = gene\n",
    "                if count == index:\n",
    "                    if option == None:\n",
    "                        clf1 = None\n",
    "                    if option != None:\n",
    "                        if gene == \"SVM\" or gene == \"SVM-0\":\n",
    "                            clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], degree=option[\"degree\"],\n",
    "                                       gamma=option[\"gamma\"],\n",
    "                                       coef0=option[\"coef0\"], shrinking=params[5], probability=True,\n",
    "                                       tol=params[7], cache_size=params[8], class_weight=option[\"class_weight\"],\n",
    "                                       verbose=params[10],\n",
    "                                       max_iter=params[11],\n",
    "                                       decision_function_shape=params[12])\n",
    "                            # clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], gamma=option[\"gamma\"],\n",
    "                            # class_weight=option[\"class_weight\"])\n",
    "                            op1[\"SVM\"] = [option[\"C\"], option[\"kernel\"], option[\"degree\"], option[\"gamma\"],\n",
    "                                          option[\"coef0\"], params[5], True,\n",
    "                                          params[7], params[8], option[\"class_weight\"], params[10], params[11],\n",
    "                                          params[12]]\n",
    "                        if gene == \"KNN\" or gene == \"KNN-0\":\n",
    "                            clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"], weights=option[\"weights\"],\n",
    "                                                        algorithm=params[2],\n",
    "                                                        leaf_size=option[\"leaf_size\"], p=option[\"p\"],\n",
    "                                                        metric=option[\"metric\"],\n",
    "                                                        metric_params=params[6], n_jobs=1)\n",
    "                            op1[\"KNN\"] = [option[\"n_neighbors\"], option[\"weights\"], params[2], option[\"leaf_size\"],\n",
    "                                          option[\"p\"], option[\"metric\"],\n",
    "                                          params[6], 1]\n",
    "                            # clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"],\n",
    "                            # leaf_size=option[\"leaf_size\"], p=option[\"p\"])\n",
    "                            # op1[\"KNN\"]=[option[\"n_neighbors\"],option[\"leaf_size\"],option[\"p\"]]\n",
    "                        if gene == \"DT\" or gene == \"DT-0\":\n",
    "                            clf1 = DecisionTreeClassifier(criterion=option[\"criterion\"], splitter=params[1],\n",
    "                                                          max_depth=option[\"max_depth\"],\n",
    "                                                          min_samples_split=option[\"min_samples_split\"],\n",
    "                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                                                          min_weight_fraction_leaf=params[5],\n",
    "                                                          max_features=option[\"max_features\"],\n",
    "                                                          random_state=params[7], max_leaf_nodes=params[8],\n",
    "                                                          min_impurity_decrease=params[9],\n",
    "                                                          min_impurity_split=params[10], class_weight=params[11])\n",
    "                            op1[\"DT\"] = [option[\"criterion\"], params[1], option[\"max_depth\"],\n",
    "                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"], params[5],\n",
    "                                         option[\"max_features\"],\n",
    "                                         params[7], params[8], params[9], params[10], params[11]]\n",
    "                            # clf1 = DecisionTreeClassifier(max_depth=option[\"max_depth\"],\n",
    "                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                            #                               max_features=option[\"max_features\"])\n",
    "                            # op1[\"DT\"]=[option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],option[\"max_features\"]]\n",
    "                        if gene == \"RF\" or gene == \" RF-0\":\n",
    "                            clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"],\n",
    "                                                          criterion=option[\"criterion\"], max_depth=option[\"max_depth\"],\n",
    "                                                          min_samples_split=option[\"min_samples_split\"],\n",
    "                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                                                          min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                          max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                                          min_impurity_split=params[9],\n",
    "                                                          bootstrap=option[\"bootstrap\"], oob_score=params[11], n_jobs=1,\n",
    "                                                          random_state=params[13], verbose=params[14],\n",
    "                                                          warm_start=params[15],\n",
    "                                                          class_weight=params[16])\n",
    "                            op1[\"RF\"] = [option[\"n_estimators\"], option[\"criterion\"], option[\"max_depth\"],\n",
    "                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n",
    "                                         params[5], option[\"max_features\"],\n",
    "                                         params[7], params[8], params[9], option[\"bootstrap\"], params[11], 1,\n",
    "                                         params[13], params[14],\n",
    "                                         params[15], params[16]]\n",
    "                            # clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"], max_depth=option[\"max_depth\"],\n",
    "                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                            #                               max_features=option[\"max_features\"],\n",
    "                            #                               bootstrap=option[\"bootstrap\"])\n",
    "                            # op1[\"RF\"]=[option[\"n_estimators\"],option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n",
    "                            #            option[\"max_features\"],option[\"bootstrap\"]]\n",
    "                        if gene == \"LR\" or gene == \" LR-0\":\n",
    "                            clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=option[\"C\"],\n",
    "                                                      fit_intercept=params[4],\n",
    "                                                      intercept_scaling=params[5], class_weight=params[6],\n",
    "                                                      random_state=params[7],\n",
    "                                                      solver=option[\"solver\"],\n",
    "                                                      max_iter=params[9], multi_class=params[10], verbose=params[11],\n",
    "                                                      warm_start=params[12], n_jobs=1,\n",
    "                                                      )\n",
    "                            op1[\"LR\"] = [\"l2\", False, params[2], option[\"C\"], params[4], params[5], params[6],\n",
    "                                         params[7], option[\"solver\"], params[9], params[10], params[11], params[12],\n",
    "                                         1, ]\n",
    "                            # clf1 = LogisticRegression(penalty='l2', C=option[\"C\"],solver=option[\"solver\"])\n",
    "                            # op1[\"LR\"]=[\"l2\",option[\"C\"],option[\"solver\"]]\n",
    "                        if gene == \"ANN\" or gene == \"ANN -0\":\n",
    "                            clf1 = KerasClassifier(build_fn=ANN_model, num=option[\"num\"],\n",
    "                                                                                  epochs=500,\n",
    "                                                                                  verbose=False)\n",
    "                            clf1._estimator_type = \"classifier\"\n",
    "                            op1[\"ANN\"] = [option[\"num\"]]\n",
    "                else:\n",
    "                    if gene == \"SVM\":\n",
    "                        clf1 = SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n",
    "                                   coef0=params[4], shrinking=params[5], probability=True,\n",
    "                                   tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10],\n",
    "                                   max_iter=params[11],\n",
    "                                   decision_function_shape=params[12])\n",
    "                        op1[\"SVM\"] = [params[0], params[1], params[2], params[3], params[4], params[5], True,\n",
    "                                      params[7], params[8], params[9], params[10], params[11],\n",
    "                                      params[12]]\n",
    "                    if gene == \"KNN\":\n",
    "                        clf1 = KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n",
    "                                                    leaf_size=params[3], p=params[4], metric=params[5],\n",
    "                                                    metric_params=params[6], n_jobs=1)\n",
    "                        op1[\"KNN\"] = [params[0], params[1], params[2], params[3], params[4], params[5],\n",
    "                                      params[6], 1]\n",
    "                    if gene == \"DT\":\n",
    "                        clf1 = DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n",
    "                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                      random_state=params[7], max_leaf_nodes=params[8],\n",
    "                                                      min_impurity_decrease=params[9],\n",
    "                                                      min_impurity_split=params[10], class_weight=params[11])\n",
    "                        op1[\"DT\"] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11]]\n",
    "                    if gene == \"RF\":\n",
    "                        clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n",
    "                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                      max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                                      min_impurity_split=params[9],\n",
    "                                                      bootstrap=params[10], oob_score=params[11], n_jobs=1,\n",
    "                                                      random_state=params[13], verbose=params[14],\n",
    "                                                      warm_start=params[15],\n",
    "                                                      class_weight=params[16])\n",
    "                        op1[\"RF\"] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11], 1, params[13], params[14],\n",
    "                                     params[15], params[16]]\n",
    "                    if gene == \"LR\":\n",
    "                        clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=params[3],\n",
    "                                                  fit_intercept=params[4],\n",
    "                                                  intercept_scaling=params[5], class_weight=params[6],\n",
    "                                                  random_state=params[7],\n",
    "                                                  solver=params[8],\n",
    "                                                  max_iter=params[9], multi_class=params[10], verbose=params[11],\n",
    "                                                  warm_start=params[12], n_jobs=1,\n",
    "                                                  )\n",
    "                        op1[\"LR\"] = [\"l2\", False, params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11], params[12], 1, ]\n",
    "                    if gene == \"ANN\":\n",
    "                        clf1 = KerasClassifier(build_fn=ANN_model, num=params[0],\n",
    "                                                                              epochs=500,\n",
    "                                                                              verbose=False)\n",
    "                        clf1._estimator_type = \"classifier\"\n",
    "                        op1[\"ANN\"] = [params[0]]\n",
    "                op[str(count)] = op1\n",
    "                count = count + 1\n",
    "                clfs[gene] = clf1\n",
    "            fop[str(ocount)] = op\n",
    "            ocount = ocount + 1\n",
    "            estimators=[]\n",
    "            for clf in clfs:\n",
    "              print(clf)\n",
    "              estimators.append((clf,clfs[clf]))\n",
    "            if(len(estimators)>0):\n",
    "              eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n",
    "              eclfs[str(ecount)] = eclf\n",
    "              ecount = ecount + 1\n",
    "        print(fop)\n",
    "        print(eclfs)\n",
    "\n",
    "        # set all the ensembles model in a pipeline to be able to select the best out of them using gridsearch\n",
    "        pipe = Pipeline([(\"classifier\", VotingClassifier(estimators=KNeighborsClassifier()))])\n",
    "        search_space = []\n",
    "        for ens in eclfs:\n",
    "            search_space.append({\"classifier\": [eclfs[ens]]})\n",
    "        print(search_space)\n",
    "        gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=5, n_jobs=1)\n",
    "        best_model = gridsearch.fit(X_val, y_val)\n",
    "        best = best_model.best_params_\n",
    "        print(best)\n",
    "        c = 0\n",
    "        for ss in eclfs:\n",
    "            print({'classifier': eclfs[ss]} == best)\n",
    "            if ({'classifier': eclfs[ss]} == best):\n",
    "                chromosomes = fop[str(c)]\n",
    "                if c == len(eclfs):\n",
    "                    index -= 1\n",
    "            c = c + 1\n",
    "        print(chromosomes)\n",
    "\n",
    "        # return the best ensemble in the right chromosome form\n",
    "        chromosome1 = chromosomes\n",
    "        chromosome2 = {}\n",
    "        for key in chromosome1:\n",
    "            ch = chromosome1[key]\n",
    "            for k in ch:\n",
    "                chromosome2[k] = ch[k]\n",
    "        chromosome = chromosome2\n",
    "    print(chromosome)\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvoLiXNm_t26"
   },
   "outputs": [],
   "source": [
    "def roulette2(poplulation, n, fit_array):\n",
    "    fit={}\n",
    "    fitness = fit_array\n",
    "    for chromosome, i in zip(poplulation, range(0, len(poplulation))):\n",
    "        fit[str(chromosome)] = fit_array[i]\n",
    "    #calculate total fitness\n",
    "    total_fitness = float(sum(fit[str(chromosome)] for chromosome in poplulation))\n",
    "    parents=[]\n",
    "    weights=[]\n",
    "    #generate probability of Fi/sum of weights\n",
    "    for  i in range(0, len(fitness)):\n",
    "        weights.append(fitness[i] / total_fitness)\n",
    "\n",
    "    #genrate a random number and return when the chromosome at that weight is reached\n",
    "    while n:\n",
    "        r = np.random.rand()\n",
    "        acc = 0\n",
    "        idx = -1\n",
    "        while acc < r:\n",
    "            idx += 1\n",
    "            acc += weights[idx]\n",
    "        parents.append(poplulation[idx])\n",
    "        n-=1\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwgyJsjO_t26"
   },
   "outputs": [],
   "source": [
    "def generateNewPopulation(population,all_fitness, X_train,y_train,X_val,y_val,crossover_prob=0.8, mutation_prob=0.1,elitism_range=0.2):\n",
    "    new_population=[]\n",
    "    elitism_fitness= all_fitness.copy()\n",
    "    elitism_population= population.copy()\n",
    "    #copy chromosomes in range of elitism rate and check for repetition\n",
    "    for i in range(0, int(elitism_range*len(population))):\n",
    "        max_index=elitism_fitness.index(max(elitism_fitness))\n",
    "        if(elitism_population[max_index] in new_population):\n",
    "            elitism_fitness.pop(max_index)\n",
    "            elitism_population.pop(max_index)\n",
    "        else:\n",
    "            new_population.append(elitism_population[max_index])\n",
    "            elitism_fitness.pop(max_index)\n",
    "            elitism_population.pop(max_index)\n",
    "    print(\"new_population\",new_population)\n",
    "\n",
    "    #while the length of the new population still has not reach 63 select mutate and crossover chromomsmes\n",
    "    while(len(new_population)<len(population)):\n",
    "        count = 0\n",
    "        parents = roulette2(population,2,all_fitness)\n",
    "        if np.random.random() < crossover_prob and len(new_population)<len(population)-1:\n",
    "            print(\"crossover\",parents[count])\n",
    "            print(\"and\",parents[count+1] )\n",
    "            sp1,sp2=crossover(parents[count], parents[count + 1])\n",
    "            new_population.append(sp1)\n",
    "            new_population.append(sp2)\n",
    "        parents = roulette2(population,1,all_fitness)\n",
    "        if np.random.random() < mutation_prob and len(new_population)<len(population):\n",
    "            print(\"Mutation\", parents[count])\n",
    "            try:\n",
    "              mutated=Mutation(parents[count],X_train,y_train,X_val,y_val)\n",
    "              new_population.append(mutated)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"not mutated\")\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zD7Lh6X_t27"
   },
   "outputs": [],
   "source": [
    "from numpy import array, savetxt, loadtxt\n",
    "from numpy import savetxt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "mods=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMV4bgaS_t27"
   },
   "outputs": [],
   "source": [
    "def GA( crossover_prob=0.85, mutation_prob=0.15, elitism_range=0.15, max_generation=100, convergence_rate=100):\n",
    "    #generate initial population\n",
    "    population=generateInitialPopulation()\n",
    "    print(\"initial population\", population)\n",
    "    gen=0\n",
    "    best_fits={}\n",
    "    models=[]\n",
    "    convergence_count=0\n",
    "    #split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "    #while stop conditions not met\n",
    "\n",
    "    ii=0\n",
    "    while gen<max_generation  and convergence_count<convergence_rate:\n",
    "        print(\"gen\", gen)\n",
    "        print(\"population\", population)\n",
    "        all_fitness = []\n",
    "        all_mod = []\n",
    "        done=[]\n",
    "        all_info = []\n",
    "        if gen ==0:\n",
    "            population =[{'SVM': [13.159320452636692, 'poly', 16, 0.001, 0.3094347827289865, False, True, 0.001, 200, None, True, -1, 'ovr', False, None]}, {'KNN': [8, 'distance', 'auto', 87, 9, 'euclidean', None, None]}, {'DT': ['gini', 'best', None, 4, 5, 0.0, None, 23, None, 0.0, None, None, 0.0]}, {'RF': [105, 'entropy', None, 3, 5, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 87, False, 'balanced_subsample', 0.0, None]}, {'LR': ['elasticnet', True, 0.0001, 27.40003521845059, True, 69.03694996811329, 'balanced', 25, 'liblinear', 100, 'ovr', 3, False, None, 1]}, {'ANN': [11]}, {'SVM': [56.83482787308529, 'rbf', 56, 0.001, 0.1471499725774863, True, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'uniform', 'auto', 48, 2, 'manhattan', None, None]}, {'SVM': [95.6629149764185, 'linear', 79, 0.001, 0.00830740648726247, True, True, 0.001, 200, None, True, -1, 'ovr', False, 84], 'DT': ['entropy', 'best', None, 10, 7, 0.0, None, 61, None, 0.0, None, None, 0.0]}, {'SVM': [71.96244306499204, 'sigmoid', 5, 0.001, 0.5492971306487061, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'RF': [198, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, True, False, None, 81, 93, False, 'balanced_subsample', 0.0, None]}, {'SVM': [72.2877803985163, 'poly', 58, 0.001, 0.32776436448881874, True, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'LR': ['l2', False, 0.0001, 33.41075518012888, True, 26.949763828687612, None, None, 'saga', 56, 'ovr', 20, False, None, 0]}, {'SVM': [62.63417243030604, 'rbf', 12, 0.001, 0.5775521256446646, True, True, 0.001, 200, 'balanced', False, -1, 'ovr', False, 15], 'ANN': [38]}, {'KNN': [8, 'uniform', 'auto', 85, 10, 'manhattan', None, None], 'DT': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'KNN': [7, 'uniform', 'auto', 68, 7, 'euclidean', None, None], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'KNN': [9, 'uniform', 'auto', 39, 4, 'euclidean', None, None], 'LR': ['l2', True, 0.0001, 26.16823306908008, True, 27.593643224456134, 'balanced', 90, 'liblinear', 136, 'ovr', 9, False, None, 0]}, {'KNN': [2, 'uniform', 'auto', 79, 9, 'minkowski', None, None], 'ANN': [54]}, {'DT': ['gini', 'best', None, 9, 1, 0.0, None, 37, None, 0.0, None, 'balanced', 0.0], 'RF': [169, 'gini', None, 10, 2, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 57, False, None, 0.0, None]}, {'DT': ['gini', 'best', None, 6, 9, 0.0, None, 97, None, 0.0, None, None, 0.0], 'LR': ['l2', False, 0.0001, 94.63262765732827, True, 27.254798580910954, None, 27, 'lbfgs', 127, 'ovr', 8, False, None, 0]}, {'DT': ['entropy', 'best', None, 7, 1, 0.0, None, 43, None, 0.0, None, 'balanced', 0.0], 'ANN': [45]}, {'RF': [147, 'entropy', None, 7, 6, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 54, False, 'balanced', 0.0, None], 'LR': ['l1', True, 0.0001, 73.66626472747214, True, 25.658603878007202, None, 98, 'newton-cg', 153, 'ovr', 14, True, None, 0]}, {'RF': [115, 'entropy', None, 8, 5, 0.0, 'sqrt', None, 0.0, None, False, False, None, 34, 26, False, 'balanced_subsample', 0.0, None], 'ANN': [84]}, {'LR': [None, True, 0.0001, 73.3785646444317, True, 70.87886982015137, None, None, 'lbfgs', 177, 'ovr', 18, False, None, None], 'ANN': [33]}, {'SVM': [20.523462924341917, 'linear', 61, 0.001, 0.37201088387311465, True, True, 0.001, 200, None, False, -1, 'ovr', False, 7], 'KNN': [9, 'uniform', 'auto', 67, 6, 'minkowski', None, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'SVM': [27.006377836840322, 'sigmoid', 25, 0.001, 0.15810347644028822, False, True, 0.001, 200, None, False, -1, 'ovr', False, None], 'KNN': [7, 'distance', 'auto', 82, 7, 'minkowski', None, None], 'RF': [147, 'gini', None, 4, 1, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 78, False, None, 0.0, None]}, {'SVM': [68.60856180899256, 'linear', 40, 0.001, 0.8538864166950686, True, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [7, 'distance', 'auto', 56, 3, 'manhattan', None, None], 'LR': [None, True, 0.0001, 73.04906420623453, True, 37.937666518399546, 'balanced', 22, 'liblinear', 128, 'ovr', 19, True, None, 1]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'uniform', 'auto', 71, 6, 'euclidean', None, None], 'ANN': [88]}, {'SVM': [46.457247652767265, 'linear', 34, 0.001, 0.47464603348660295, False, True, 0.001, 200, 'balanced', False, -1, 'ovr', False, 52], 'DT': ['entropy', 'best', None, 4, 10, 0.0, None, 79, None, 0.0, None, 'balanced', 0.0], 'RF': [137, 'entropy', None, 2, 4, 0.0, 'auto', None, 0.0, None, True, False, None, 17, 86, False, None, 0.0, None]}, {'SVM': [11.515242406964155, 'linear', 66, 0.001, 0.970885575408274, True, False, 0.001, 200, 'balanced', False, -1, 'ovr', False, None], 'DT': ['entropy', 'best', None, 6, 6, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['elasticnet', False, 0.0001, 39.17051442857128, True, 68.09172582730073, 'balanced', None, 'liblinear', 103, 'ovr', 9, False, None, 0.38633604296098045]}, {'SVM': [89.4704311946148, 'rbf', 57, 0.001, 0.8251365561055917, True, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, 52], 'DT': ['entropy', 'best', None, 9, 5, 0.0, None, 96, None, 0.0, None, None, 0.0], 'ANN': [92]}, {'SVM': [96.44425584770391, 'linear', 76, 0.001, 0.3423650702402784, True, False, 0.001, 200, 'balanced', False, -1, 'ovr', False, None], 'RF': [130, 'entropy', None, 7, 3, 0.0, 'log2', None, 0.0, None, True, False, None, None, 80, False, 'balanced', 0.0, None], 'LR': ['elasticnet', True, 0.0001, 97.9844949973051, True, 87.1004756013681, None, 77, 'lbfgs', 146, 'ovr', 11, False, None, 0]}, {'SVM': [85.82093886158924, 'linear', 79, 0.001, 0.18446350442959814, True, True, 0.001, 200, 'balanced', False, -1, 'ovr', False, None], 'RF': [110, 'entropy', None, 6, 3, 0.0, 'sqrt', None, 0.0, None, False, False, None, 6, 66, False, None, 0.0, None], 'ANN': [88]}, {'SVM': [21.728331255799528, 'linear', 60, 0.001, 0.015683820140798943, True, False, 0.001, 200, None, False, -1, 'ovr', False, None], 'LR': ['elasticnet', True, 0.0001, 85.96012515373184, True, 28.447572405762266, None, 65, 'saga', 85, 'ovr', 17, True, None, 0.7766706104219286], 'ANN': [28]}, {'KNN': [5, 'distance', 'auto', 67, 2, 'minkowski', None, None], 'DT': ['entropy', 'best', None, 6, 8, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'RF': [184, 'gini', None, 10, 10, 0.0, None, None, 0.0, None, False, False, None, None, 6, False, 'balanced_subsample', 0.0, None]}, {'KNN': [3, 'uniform', 'auto', 38, 5, 'euclidean', None, None], 'DT': ['entropy', 'best', None, 2, 8, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['l2', True, 0.0001, 10.8410423643995, True, 69.69400501456717, 'balanced', 14, 'sag', 177, 'ovr', 13, False, None, 0.1561118114156067]}, {'KNN': [7, 'uniform', 'auto', 35, 6, 'manhattan', None, None], 'DT': ['entropy', 'best', None, 10, 3, 0.0, None, 15, None, 0.0, None, None, 0.0], 'ANN': [94]}, {'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'RF': [164, 'gini', None, 10, 3, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 72, False, 'balanced', 0.0, None], 'LR': [None, True, 0.0001, 67.23036339050321, True, 50.45074585210586, None, 90, 'saga', 199, 'ovr', 4, False, None, 0]}, {'KNN': [6, 'distance', 'auto', 43, 9, 'euclidean', None, None], 'RF': [166, 'gini', None, 3, 1, 0.0, 'log2', None, 0.0, None, False, False, None, 96, 98, False, 'balanced_subsample', 0.0, None], 'ANN': [88]}, {'KNN': [4, 'distance', 'auto', 54, 3, 'manhattan', None, None], 'LR': ['l1', False, 0.0001, 71.6619336583085, True, 53.064469467269404, 'balanced', 41, 'lbfgs', 51, 'ovr', 13, True, None, 0], 'ANN': [83]}, {'DT': ['entropy', 'best', None, 8, 10, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [134, 'gini', None, 9, 1, 0.0, None, None, 0.0, None, False, False, None, None, 90, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', False, 0.0001, 59.98191414531681, True, 7.2643157164394845, 'balanced', 34, 'saga', 82, 'ovr', 11, True, None, 0]}, {'DT': ['entropy', 'best', None, 5, 8, 0.0, None, 86, None, 0.0, None, 'balanced', 0.0], 'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'ANN': [49]}, {'DT': ['entropy', 'best', None, 10, 5, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['elasticnet', True, 0.0001, 50.91514702179476, True, 84.38877360775552, None, None, 'newton-cg', 67, 'ovr', 19, False, None, 1], 'ANN': [96]}, {'RF': [119, 'gini', None, 7, 5, 0.0, None, None, 0.0, None, True, False, None, None, 33, False, 'balanced', 0.0, None], 'LR': ['elasticnet', False, 0.0001, 42.33501859534018, True, 67.38757846654921, None, 60, 'lbfgs', 62, 'ovr', 2, False, None, 0], 'ANN': [54]}, {'SVM': [62.436016589775534, 'rbf', 17, 0.001, 0.4926664862618614, True, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [9, 'distance', 'auto', 54, 9, 'euclidean', None, None], 'DT': ['entropy', 'best', None, 9, 2, 0.0, None, 17, None, 0.0, None, 'balanced', 0.0], 'RF': [172, 'entropy', None, 2, 3, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 16, False, None, 0.0, None]}, {'SVM': [63.28171822307045, 'rbf', 96, 0.001, 0.5982340909054287, True, False, 0.001, 200, None, True, -1, 'ovr', False, 96], 'KNN': [5, 'distance', 'auto', 71, 2, 'minkowski', None, None], 'DT': ['gini', 'best', None, 6, 1, 0.0, None, 49, None, 0.0, None, None, 0.0], 'LR': [None, True, 0.0001, 14.016710913204722, True, 14.856574211288187, 'balanced', 14, 'newton-cg', 154, 'ovr', 13, False, None, 0.10979771675791761]}, {'SVM': [23.41232163271505, 'poly', 16, 0.001, 0.4703191168515426, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [2, 'distance', 'auto', 76, 6, 'minkowski', None, None], 'DT': ['entropy', 'best', None, 10, 2, 0.0, None, 88, None, 0.0, None, 'balanced', 0.0], 'ANN': [86]}, {'SVM': [60.264686197189036, 'linear', 24, 0.001, 0.4853623809644213, False, False, 0.001, 200, None, False, -1, 'ovr', False, 94], 'KNN': [6, 'distance', 'auto', 60, 5, 'manhattan', None, None], 'RF': [128, 'gini', None, 4, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 20, 50, False, 'balanced_subsample', 0.0, None], 'LR': ['elasticnet', True, 0.0001, 7.974803890000159, True, 80.73313721208389, None, 33, 'liblinear', 129, 'ovr', 11, True, None, 0]}, {'SVM': [58.40998836836898, 'sigmoid', 43, 0.001, 0.38506983499466874, False, False, 0.001, 200, None, False, -1, 'ovr', False, 26], 'KNN': [8, 'uniform', 'auto', 90, 10, 'minkowski', None, None], 'RF': [136, 'entropy', None, 9, 3, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 100, False, 'balanced', 0.0, None], 'ANN': [78]}, {'SVM': [62.0545082212663, 'poly', 94, 0.001, 0.9462415976951283, False, True, 0.001, 200, None, False, -1, 'ovr', False, None], 'KNN': [5, 'uniform', 'auto', 59, 6, 'euclidean', None, None], 'LR': ['l2', False, 0.0001, 11.540993663717437, True, 7.273771949163299, None, None, 'sag', 117, 'ovr', 1, True, None, None], 'ANN': [87]}, {'SVM': [21.056444875724022, 'rbf', 63, 0.001, 0.22322055307593025, False, True, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 7, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [129, 'gini', None, 4, 2, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 52, False, None, 0.0, None], 'LR': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, None, 1]}, {'SVM': [29.75588854971818, 'rbf', 51, 0.001, 0.6787275011241796, False, True, 0.001, 200, None, True, -1, 'ovr', False, None], 'DT': ['entropy', 'best', None, 6, 4, 0.0, None, 20, None, 0.0, None, 'balanced', 0.0], 'RF': [123, 'entropy', None, 4, 5, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 87, False, 'balanced_subsample', 0.0, None], 'ANN': [34]}, {'SVM': [66.06483697390368, 'poly', 67, 0.001, 0.5048922736568685, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['entropy', 'best', None, 5, 5, 0.0, None, 8, None, 0.0, None, 'balanced', 0.0], 'LR': ['l2', True, 0.0001, 4.483533982738863, True, 97.0685106874667, None, None, 'saga', 63, 'ovr', 14, True, None, 0], 'ANN': [28]}, {'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'LR': ['l2', True, 0.0001, 62.549973805846605, True, 9.211698683897529, 'balanced', 7, 'sag', 184, 'ovr', 16, False, None, 0], 'ANN': [96]}, {'KNN': [9, 'uniform', 'auto', 38, 7, 'minkowski', None, None], 'DT': ['entropy', 'best', None, 6, 9, 0.0, None, 53, None, 0.0, None, 'balanced', 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR': ['l2', True, 0.0001, 3.8098921879033187, True, 48.05176624159464, None, None, 'sag', 145, 'ovr', 17, False, None, 0.4379068452283271]}, {'KNN': [3, 'uniform', 'auto', 62, 2, 'euclidean', None, None], 'DT': ['entropy', 'best', None, 4, 4, 0.0, None, 59, None, 0.0, None, 'balanced', 0.0], 'RF': [158, 'gini', None, 6, 2, 0.0, None, None, 0.0, None, False, False, None, 93, 70, False, None, 0.0, None], 'ANN': [45]}, {'KNN': [1, 'distance', 'auto', 32, 6, 'minkowski', None, None], 'DT': ['gini', 'best', None, 2, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'LR': ['l2', True, 0.0001, 61.052319081427505, True, 36.35319716233339, 'balanced', 77, 'sag', 160, 'ovr', 17, False, None, 0.5880494234486304], 'ANN': [27]}, {'KNN': [6, 'distance', 'auto', 48, 9, 'minkowski', None, None], 'RF': [151, 'gini', None, 7, 2, 0.0, 'sqrt', None, 0.0, None, False, False, None, None, 29, False, None, 0.0, None], 'LR': ['l2', False, 0.0001, 54.69859774842014, True, 15.905429432727614, 'balanced', 40, 'sag', 198, 'ovr', 16, False, None, None], 'ANN': [15]}, {'DT': ['gini', 'best', None, 7, 8, 0.0, None, 56, None, 0.0, None, None, 0.0], 'RF': [112, 'entropy', None, 4, 4, 0.0, 'log2', None, 0.0, None, False, False, None, 5, 48, False, None, 0.0, None], 'LR': ['l2', False, 0.0001, 23.460999662723992, True, 64.8820426178088, 'balanced', None, 'lbfgs', 74, 'ovr', 9, True, None, 0], 'ANN': [63]}, {'SVM': [50.39041656351231, 'rbf', 0, 0.001, 0.5612267114347639, True, False, 0.001, 200, None, False, -1, 'ovr', False, 68], 'KNN': [4, 'uniform', 'auto', 65, 3, 'manhattan', None, None], 'DT': ['entropy', 'best', None, 6, 2, 0.0, None, 9, None, 0.0, None, None, 0.0], 'RF': [181, 'gini', None, 7, 3, 0.0, 'log2', None, 0.0, None, False, False, None, None, 72, False, None, 0.0, None], 'LR': ['l2', False, 0.0001, 83.65100124415106, True, 33.009388437161114, 'balanced', 9, 'saga', 69, 'ovr', 4, False, None, 1]}, {'SVM': [55.27923467307486, 'sigmoid', 60, 0.001, 0.8916893395389712, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, 66], 'KNN': [9, 'uniform', 'auto', 34, 10, 'manhattan', None, None], 'DT': ['gini', 'best', None, 7, 6, 0.0, None, 63, None, 0.0, None, None, 0.0], 'RF': [120, 'gini', None, 9, 7, 0.0, 'auto', None, 0.0, None, True, False, None, None, 10, False, 'balanced_subsample', 0.0, None], 'ANN': [75]}, {'SVM': [99.87065789190743, 'linear', 99, 0.001, 0.9530284491458829, False, False, 0.001, 200, None, True, -1, 'ovr', False, 59], 'KNN': [4, 'uniform', 'auto', 71, 10, 'manhattan', None, None], 'DT': ['entropy', 'best', None, 6, 5, 0.0, None, 87, None, 0.0, None, None, 0.0], 'LR': ['l1', False, 0.0001, 67.26114221854701, True, 48.68281371966956, 'balanced', None, 'saga', 51, 'ovr', 6, False, None, 0], 'ANN': [83]}, {'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'KNN': [9, 'uniform', 'auto', 45, 6, 'minkowski', None, None], 'RF': [135, 'gini', None, 2, 1, 0.0, None, None, 0.0, None, False, False, None, None, 60, False, 'balanced_subsample', 0.0, None], 'LR': ['l2', False, 0.0001, 94.39090681601368, True, 12.357342081497036, 'balanced', None, 'sag', 109, 'ovr', 17, True, None, 0], 'ANN': [77]}, {'SVM': [88.66879356970269, 'linear', 96, 0.001, 0.4378561021505064, True, False, 0.001, 200, None, False, -1, 'ovr', False, 40], 'DT': ['gini', 'best', None, 2, 5, 0.0, None, None, None, 0.0, None, None, 0.0], 'RF': [141, 'gini', None, 3, 7, 0.0, None, None, 0.0, None, True, False, None, None, 22, False, 'balanced_subsample', 0.0, None], 'LR': ['l2', False, 0.0001, 14.947986220068676, True, 35.81489810330838, None, None, 'newton-cg', 178, 'ovr', 17, True, None, 0], 'ANN': [94]}, {'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}, {'SVM': [18.508895381367186, 'linear', 75, 0.001, 0.1767066421606338, False, True, 0.001, 200, 'balanced', False, -1, 'ovr', False, 68], 'KNN': [2, 'distance', 'auto', 30, 2, 'manhattan', None, None], 'DT': ['entropy', 'best', None, 9, 10, 0.0, None, None, None, 0.0, None, 'balanced', 0.0], 'RF': [169, 'gini', None, 7, 2, 0.0, None, None, 0.0, None, True, False, None, None, 92, False, 'balanced', 0.0, None], 'LR': [None, False, 0.0001, 35.36509150434214, True, 58.071491913076834, 'balanced', 91, 'saga', 144, 'ovr', 9, False, None, 0.5105945449044219], 'ANN': [95]}]\n",
    "            all_fitness =[0.4912, 0.6464, 0.61, 0.6732, 0.6456, 0.6844, 0.6396, 0.6372, 0.666, 0.6456, 0.644, 0.6176, 0.6716, 0.6596, 0.6136, 0.6444, 0.6476, 0, 0.6776, 0, 0.6744, 0.682, 0.66, 0.6516, 0.6536, 0.6784, 0.6428, 0.6184, 0.6568, 0.6772, 0.6528, 0.6476, 0.6668, 0.634, 0.682, 0.66, 0.6504, 0.65, 0.6784, 0.662, 0.6852, 0.6532, 0.6396, 0.62, 0.6808, 0.6256, 0.6388, 0.6664, 0.6724, 0.6588, 0.6796, 0.6812, 0.6092, 0.6732, 0.682, 0.6816, 0.6804, 0.6788, 0.6608, 0.6796, 0.6732, 0.6936, 0.6616]\n",
    "            all_info= [{'mcc': [0], 'acc': [0.4912], 'f1': [0.6587982832618026], 'cm': [array([[   0, 1272],\n",
    "               [   0, 1228]])]}, {'mcc': [0.2936920718871597], 'acc': [0.6464], 'f1': [0.6497622820919177], 'cm': [array([[796, 476],\n",
    "               [408, 820]])]}, {'mcc': [0.2196650957004209], 'acc': [0.61], 'f1': [0.601552921945239], 'cm': [array([[789, 483],\n",
    "               [492, 736]])]}, {'mcc': [0.34646785595023544], 'acc': [0.6732], 'f1': [0.6704316256555062], 'cm': [array([[852, 420],\n",
    "               [397, 831]])]}, {'mcc': [0.2957541618581573], 'acc': [0.6456], 'f1': [0.6636294608959756], 'cm': [array([[740, 532],\n",
    "               [354, 874]])]}, {'mcc': [0.3684696799014371], 'acc': [0.6844], 'f1': [0.6759753593429157], 'cm': [array([[888, 384],\n",
    "               [405, 823]])]}, {'mcc': [0.2815068255474013], 'acc': [0.6396], 'f1': [0.595056179775281], 'cm': [array([[937, 335],\n",
    "               [566, 662]])]}, {'mcc': [0.2786541033547449], 'acc': [0.6372], 'f1': [0.5822201750345463], 'cm': [array([[961, 311],\n",
    "               [596, 632]])]}, {'mcc': [0.333561546398658], 'acc': [0.666], 'f1': [0.6332894158981116], 'cm': [array([[944, 328],\n",
    "               [507, 721]])]}, {'mcc': [0.2958429475381238], 'acc': [0.6456], 'f1': [0.6638846737481032], 'cm': [array([[739, 533],\n",
    "               [353, 875]])]}, {'mcc': [0.29006150825396493], 'acc': [0.644], 'f1': [0.6023235031277926], 'cm': [array([[936, 336],\n",
    "               [554, 674]])]}, {'mcc': [0.2502905145934123], 'acc': [0.6176], 'f1': [0.5127420998980632], 'cm': [array([[1041,  231],\n",
    "               [ 725,  503]])]}, {'mcc': [0.34686955681844955], 'acc': [0.6716], 'f1': [0.6310112359550563], 'cm': [array([[977, 295],\n",
    "               [526, 702]])]}, {'mcc': [0.321604765837958], 'acc': [0.6596], 'f1': [0.6209354120267261], 'cm': [array([[952, 320],\n",
    "               [531, 697]])]}, {'mcc': [0.24750343101372904], 'acc': [0.6136], 'f1': [0.4905063291139241], 'cm': [array([[1069,  203],\n",
    "               [ 763,  465]])]}, {'mcc': [0.29764232827862236], 'acc': [0.6444], 'f1': [0.5760610395803528], 'cm': [array([[1007,  265],\n",
    "               [ 624,  604]])]}, {'mcc': [0.3028316601801736], 'acc': [0.6476], 'f1': [0.5846298915605846], 'cm': [array([[999, 273],\n",
    "               [608, 620]])]}, {'mcc': [0], 'acc': [0], 'f1': [0], 'cm': [array([[1272,    0],\n",
    "               [1228,    0]])]}, {'mcc': [0.35889711233007376], 'acc': [0.6776], 'f1': [0.6385650224215247], 'cm': [array([[982, 290],\n",
    "               [516, 712]])]}, {'mcc': [0], 'acc': [0], 'f1': [0], 'cm': [array([[1272,    0],\n",
    "               [1228,    0]])]}, {'mcc': [0.34956623550403637], 'acc': [0.6744], 'f1': [0.6482281763180641], 'cm': [array([[936, 336],\n",
    "               [478, 750]])]}, {'mcc': [0.36868475682875207], 'acc': [0.682], 'f1': [0.6971428571428572], 'cm': [array([[790, 482],\n",
    "               [313, 915]])]}, {'mcc': [0.3257733718360666], 'acc': [0.66], 'f1': [0.6797287113790504], 'cm': [array([[748, 524],\n",
    "               [326, 902]])]}, {'mcc': [0.3107918133821213], 'acc': [0.6516], 'f1': [0.6763285024154589], 'cm': [array([[719, 553],\n",
    "               [318, 910]])]}, {'mcc': [0.3089117815624329], 'acc': [0.6536], 'f1': [0.6168141592920354], 'cm': [array([[937, 335],\n",
    "               [531, 697]])]}, {'mcc': [0.3597213173279607], 'acc': [0.6784], 'f1': [0.6890951276102087], 'cm': [array([[805, 467],\n",
    "               [337, 891]])]}, {'mcc': [0.2928174195195563], 'acc': [0.6428], 'f1': [0.6679062848642617], 'cm': [array([[709, 563],\n",
    "               [330, 898]])]}, {'mcc': [0.24018837977812318], 'acc': [0.6184], 'f1': [0.5587419056429233], 'cm': [array([[942, 330],\n",
    "               [624, 604]])]}, {'mcc': [0.3207084645956629], 'acc': [0.6568], 'f1': [0.6798507462686568], 'cm': [array([[731, 541],\n",
    "               [317, 911]])]}, {'mcc': [0.3566717308539513], 'acc': [0.6772], 'f1': [0.6437086092715233], 'cm': [array([[964, 308],\n",
    "               [499, 729]])]}, {'mcc': [0.31237939627535255], 'acc': [0.6528], 'f1': [0.6756352765321375], 'cm': [array([[728, 544],\n",
    "               [324, 904]])]}, {'mcc': [0.29520433484660397], 'acc': [0.6476], 'f1': [0.6440404040404041], 'cm': [array([[822, 450],\n",
    "               [431, 797]])]}, {'mcc': [0.3350202757736869], 'acc': [0.6668], 'f1': [0.6724341329138812], 'cm': [array([[812, 460],\n",
    "               [373, 855]])]}, {'mcc': [0.275681543632846], 'acc': [0.634], 'f1': [0.564078132444021], 'cm': [array([[993, 279],\n",
    "               [636, 592]])]}, {'mcc': [0.36444197754923996], 'acc': [0.682], 'f1': [0.6821271491403439], 'cm': [array([[852, 420],\n",
    "               [375, 853]])]}, {'mcc': [0.3222446805083023], 'acc': [0.66], 'f1': [0.6222222222222223], 'cm': [array([[950, 322],\n",
    "               [528, 700]])]}, {'mcc': [0.3099042168690396], 'acc': [0.6504], 'f1': [0.5842055185537584], 'cm': [array([[1012,  260],\n",
    "               [ 614,  614]])]}, {'mcc': [0.3004212245753161], 'acc': [0.65], 'f1': [0.6501399440223911], 'cm': [array([[812, 460],\n",
    "               [415, 813]])]}, {'mcc': [0.3564489341616833], 'acc': [0.6784], 'f1': [0.6694078947368421], 'cm': [array([[882, 390],\n",
    "               [414, 814]])]}, {'mcc': [0.3248944908223983], 'acc': [0.662], 'f1': [0.6650812524772096], 'cm': [array([[816, 456],\n",
    "               [389, 839]])]}, {'mcc': [0.3723141732528181], 'acc': [0.6852], 'f1': [0.6922174423152131], 'cm': [array([[828, 444],\n",
    "               [343, 885]])]}, {'mcc': [0.3060640552677656], 'acc': [0.6532], 'f1': [0.6343315056938001], 'cm': [array([[881, 391],\n",
    "               [476, 752]])]}, {'mcc': [0.27921543836271995], 'acc': [0.6396], 'f1': [0.6121394748170469], 'cm': [array([[888, 384],\n",
    "               [517, 711]])]}, {'mcc': [0.24957111805959722], 'acc': [0.62], 'f1': [0.534769833496572], 'cm': [array([[1004,  268],\n",
    "               [ 682,  546]])]}, {'mcc': [0.36134046935901964], 'acc': [0.6808], 'f1': [0.6655490360435876], 'cm': [array([[908, 364],\n",
    "               [434, 794]])]}, {'mcc': [0.2709471582426173], 'acc': [0.6256], 'f1': [0.5150259067357513], 'cm': [array([[1067,  205],\n",
    "               [ 731,  497]])]}, {'mcc': [0.2838084431994492], 'acc': [0.6388], 'f1': [0.5766526019690577], 'cm': [array([[982, 290],\n",
    "               [613, 615]])]}, {'mcc': [0.33241283437995217], 'acc': [0.6664], 'f1': [0.6519198664440734], 'cm': [array([[885, 387],\n",
    "               [447, 781]])]}, {'mcc': [0.34445372939907726], 'acc': [0.6724], 'f1': [0.6577517760133723], 'cm': [array([[894, 378],\n",
    "               [441, 787]])]}, {'mcc': [0.3189417178025654], 'acc': [0.6588], 'f1': [0.6643053915781189], 'cm': [array([[803, 469],\n",
    "               [384, 844]])]}, {'mcc': [0.36293340121217926], 'acc': [0.6796], 'f1': [0.6409681757059614], 'cm': [array([[984, 288],\n",
    "               [513, 715]])]}, {'mcc': [0.36274846698434166], 'acc': [0.6812], 'f1': [0.659256092347157], 'cm': [array([[932, 340],\n",
    "               [457, 771]])]}, {'mcc': [0.23804793673867622], 'acc': [0.6092], 'f1': [0.4833421470121629], 'cm': [array([[1066,  206],\n",
    "               [ 771,  457]])]}, {'mcc': [0.34690753857521966], 'acc': [0.6732], 'f1': [0.6486021505376345], 'cm': [array([[929, 343],\n",
    "               [474, 754]])]}, {'mcc': [0.36443523908313463], 'acc': [0.682], 'f1': [0.6595289079229121], 'cm': [array([[935, 337],\n",
    "               [458, 770]])]}, {'mcc': [0.36368955615989673], 'acc': [0.6816], 'f1': [0.6586620926243568], 'cm': [array([[936, 336],\n",
    "               [460, 768]])]}, {'mcc': [0.36124093990054373], 'acc': [0.6804], 'f1': [0.6805277888844461], 'cm': [array([[850, 422],\n",
    "               [377, 851]])]}, {'mcc': [0.3572656166554148], 'acc': [0.6788], 'f1': [0.6649979140592407], 'cm': [array([[900, 372],\n",
    "               [431, 797]])]}, {'mcc': [0.3219701897996362], 'acc': [0.6608], 'f1': [0.6347975882859603], 'cm': [array([[915, 357],\n",
    "               [491, 737]])]}, {'mcc': [0.3628346499790332], 'acc': [0.6796], 'f1': [0.6922781406069919], 'cm': [array([[798, 474],\n",
    "               [327, 901]])]}, {'mcc': [0.3460402890037907], 'acc': [0.6732], 'f1': [0.6591572799332498], 'cm': [array([[893, 379],\n",
    "               [438, 790]])]}, {'mcc': [0.3868607017236362], 'acc': [0.6936], 'f1': [0.683993399339934], 'cm': [array([[905, 367],\n",
    "               [399, 829]])]}, {'mcc': [0.3278239419119164], 'acc': [0.6616], 'f1': [0.6144029170464904], 'cm': [array([[980, 292],\n",
    "               [554, 674]])]}]\n",
    "\n",
    "            \n",
    "        else:\n",
    "            for chromosome in population:\n",
    "              #if chromsome's already calculated\n",
    "              if chromosome in done:\n",
    "                  print(\"chromosome\", chromosome)\n",
    "                  fit = all_fitness[done.index(chromosome)]\n",
    "                  info = all_info[done.index(chromosome)]\n",
    "                  model=all_mod[done.index(chromosome)]\n",
    "                  all_fitness.append(fit)\n",
    "                  all_info.append(info)\n",
    "                  all_mod.append(model)\n",
    "                  done.append(chromosome)\n",
    "                  print(\"done out of 63\", len(done))\n",
    "            else:\n",
    "                  print(\"chromosome\", chromosome)\n",
    "                  print(ii)\n",
    "                  fit, info,model = fitness(chromosome,X_train,y_train,X_test,y_test,count=ii,gen=gen)\n",
    "                  all_fitness.append(fit)\n",
    "                  all_info.append(info)\n",
    "                  all_mod.append(model)\n",
    "                  done.append(chromosome)\n",
    "                  print(\"done out of 63\", len(done))\n",
    "                  if gen ==0 or gen ==99:\n",
    "                            ii+=1\n",
    "          #check if converged\n",
    "        if best_fits!={}:\n",
    "            if(str(list(best_fits[str(gen-1)])[0])== str(population[all_fitness.index(max(all_fitness))])):\n",
    "                print(\"converged\")\n",
    "                convergence_count = convergence_count + 1\n",
    "            else:\n",
    "                convergence_count=0\n",
    "        #get best fit\n",
    "        index = all_fitness.index(max(all_fitness))\n",
    "        print(\"in gen\",gen)\n",
    "        print(\"best fitness\",max(all_fitness))\n",
    "        print(\"chromosome\",population[index])\n",
    "        best_fits[str(gen)]={str(population[index]):[max(all_fitness),all_info[index]]}\n",
    "        print(\"best_fits\",best_fits)\n",
    "        print(\"all fitness\",all_fitness)\n",
    "        print(\"all_info\",all_info)\n",
    "        try:\n",
    "            if gen ==0:\n",
    "                models.append(all_mod[index])\n",
    "                emod=all_mod[index]\n",
    "                print(index)\n",
    "                filename = 'gen0_modelexp1.sav'\n",
    "                with open(filename, \"wb\") as file:\n",
    "                  pickle.dump(emod, file)\n",
    "            if gen == 99:\n",
    "                models.append(all_mod[index])\n",
    "                emod=all_mod[index]\n",
    "                print(index)\n",
    "                filename = 'gen99_modelexp1.sav'\n",
    "                with open(filename, \"wb\") as file:\n",
    "                  pickle.dump(emod, file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"not saved\")\n",
    "        if gen ==99   :\n",
    "            mods.append(all_mod[index])\n",
    "       \n",
    "        gen=gen+1\n",
    "        #check stop conditions and generate new data\n",
    "        if gen<max_generation and convergence_count<convergence_rate:\n",
    "            population=generateNewPopulation(population,X_train=X_train,y_train=y_train,X_val=X_val,y_val=y_val,crossover_prob=crossover_prob,mutation_prob=mutation_prob,elitism_range=elitism_range,all_fitness=all_fitness)\n",
    "        #increase mutation rate\n",
    "        if (convergence_count >0 and convergence_count% 5==0 ):\n",
    "            mutation_prob+=0.1\n",
    "            convergence_count=0\n",
    "    return best_fits, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ8NXqAh_t27",
    "outputId": "8c398027-2b3e-4008-c292-137fb254750a"
   },
   "outputs": [],
   "source": [
    "print(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2Yp7xXp_t27"
   },
   "outputs": [],
   "source": [
    "#x1, y1=balanced_subsample(X,y,5000)\n",
    "#x1=np.array(x1)\n",
    "#savetxt('dataexp1x.csv', x1, delimiter=',')\n",
    "#savetxt('dataexp1y.csv', y1, delimiter=',')\n",
    "X=loadtxt(\"dataexp1x.csv\", delimiter=\",\")\n",
    "y=loadtxt(\"dataexp1y.csv\", delimiter=\",\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK-egBac_t27",
    "outputId": "1609e4b6-8acc-4e3c-c175-f6efb5b5713d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_fits,models=GA()\n",
    "print(best_fits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzlOTx-O_t28"
   },
   "outputs": [],
   "source": [
    "chromosome0=best_fits['0']\n",
    "chromosome99=best_fits['99']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqcDslydVIa1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSKo3xxs_t28"
   },
   "source": [
    "#validate on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00YD0swt_t28"
   },
   "outputs": [],
   "source": [
    "print(\"equinox\")\n",
    "data = arff.loadarff('Equinox-3.4-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yS0pk6XO_t28"
   },
   "outputs": [],
   "source": [
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwN-rrvW_t28"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iq3oMJUJ_t29"
   },
   "outputs": [],
   "source": [
    "print(\"Mylyn\")\n",
    "data = arff.loadarff('Mylyn-3.1-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVrSMFQk_t29"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PahiSoP1_t29"
   },
   "outputs": [],
   "source": [
    "print(\"Eclipse_JDT_Core\")\n",
    "\n",
    "data = arff.loadarff('Eclipse_JDT_Core-3.4-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-79qIW_7_t29"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlvp5_pH_t29"
   },
   "outputs": [],
   "source": [
    "print(\"all\")\n",
    "BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvvFVUMT_t2-"
   },
   "outputs": [],
   "source": [
    "X=BugPrediction_data_minmax_scalled\n",
    "y=BugPrediction_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXZ6MsKa_t2-"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "commbined.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

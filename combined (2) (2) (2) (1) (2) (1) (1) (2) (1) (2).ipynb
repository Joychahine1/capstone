{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svK-Tlf8_t2v"
   },
   "source": [
    "enerate random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vCsgJqhN_t2p",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-08a478c7e99b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# !conda install --yes --prefix {sys.prefix} scikit-learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Install a conda package in the current Jupyter kernel\n",
    "\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} keras\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn \n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from itertools import combinations\n",
    "from math import sqrt, isnan\n",
    "from scipy.io import arff\t\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cJamNM__t2v"
   },
   "outputs": [],
   "source": [
    "def SVM_params():\n",
    "    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\", \"decision_function_shape\",\n",
    "                         \"break_ties\"]\n",
    "    default_values=[1.0, \"rbf\", 3,\"scale\", 0.0, True, False, 0.001, 200, None, False, -1, 'ovr', False, None]\n",
    "    return default_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz_ukkbb_t2w"
   },
   "outputs": [],
   "source": [
    "def SVM_paramsRandom():\n",
    "    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    kernel_index = random.randint(0, len(kernel)-1)\n",
    "    TF=[True, False]\n",
    "    BN=[\"balanced\", None]\n",
    "    RN=[random.randint(0, 100), None]\n",
    "    list_of_parameters= [\"C\", \"kernel\", \"degree\", \"gamma\",\"coef0\",\"shrinking\",\"probability\",\"tol\",\"cache_size\",\"class_weight\", \"verbose\",\"max_iter\",\n",
    "                         \"decision_function_shape\", \"break_ties\"]\n",
    "    random_values=[random.uniform(0,100), kernel[kernel_index], random.randint(0,100), 0.001, random.uniform(0, 1),\n",
    "                    TF[random.randint(0,len(TF)-1)], TF[random.randint(0,len(TF)-1)], 0.001, 200,\n",
    "                    BN[random.randint(0,len(BN)-1)], TF[random.randint(0,len(TF)-1)], -1, 'ovr',\n",
    "                   False,  RN[random.randint(0,len(RN)-1)]]\n",
    "    return random_values\n",
    "def KNN_params():\n",
    "    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n",
    "    default_values=[5, 'uniform', 'auto', 30, 2, 'minkowski', None, None]\n",
    "    return default_values\n",
    "def KNN_paramsRandom():\n",
    "    weights=['uniform', \"distance\"]\n",
    "    metric=['minkowski', 'euclidean', 'manhattan']\n",
    "    list_of_parameters= [\"n_neighbors\", \"weights\", \"algorithm\", \"leaf_size\", \"p\", \"metric\", \"metric_params\", \"n_jobs\" ]\n",
    "    random_values=[random.randint(1,10),weights[random.randint(0, len(weights)-1)], 'auto',\n",
    "                   random.randint(30,100), random.randint(2,10), metric[random.randint(0, len(metric)-1)], None, None]\n",
    "    return random_values\n",
    "def LR_params():\n",
    "    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\", \"random_state\", \"solver\",\"max_iter\",\n",
    "                         \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\", \"l1_ratio\"]\n",
    "    default_values=[ 'l2',False, 0.0001,1.0, True, 1, None, None, 'lbfgs', 100, 'auto', 0, False, None, None]\n",
    "    return default_values\n",
    "def LR_paramsRandom():\n",
    "    penalty=['l1', 'l2', 'elasticnet', None]\n",
    "    TF=[True, False]\n",
    "    BN=[\"balanced\", None]\n",
    "    RN=[random.randint(0, 100), None]\n",
    "    l1_ratio=[0,1, random.uniform(0,1),None]\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    s= solver[random.randint(0,len(solver)-1)]\n",
    "    if(s==\"lbgs\" or s=='sag'):\n",
    "        p='l2'\n",
    "    else:\n",
    "        p=penalty[random.randint(0,len(penalty)-1)]\n",
    "    list_of_parameters= [\"penalty\",\"dual\", \"tol\", \"C\", \"fit_intercept\",\"intercept_scaling\", \"class_weight\",\n",
    "                         \"random_state\", \"solver\",\"max_iter\", \"multi_class\", \"verbose\", \"warm_start\", \"n_jobs\",\n",
    "                         \"l1_ratio\"]\n",
    "    random_values=[ p,TF[random.randint(0,len(TF)-1)], 0.0001,\n",
    "                     random.uniform(0,100), True, random.uniform(0,100), BN[random.randint(0,len(BN)-1)],\n",
    "                     RN[random.randint(0,len(RN)-1)], s, random.randint(50,200),\n",
    "                     'ovr', random.randint(0,20), TF[random.randint(0,len(TF)-1)],\n",
    "                     None, l1_ratio[random.randint(0,len(l1_ratio)-1)]]\n",
    "    return random_values\n",
    "def RF_params():\n",
    "    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n",
    "                                          \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\", \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n",
    "    default_values=[100,\"gini\",None, 2, 1, 0.0,\"auto\",None,0.0, None, True, False,None,None, 0, False,None,0.0,None ]\n",
    "    return default_values\n",
    "def RF_paramsRandom():\n",
    "    criterion =[\"gini\", \"entropy\"]\n",
    "    max_features=['auto', 'sqrt', 'log2',None]\n",
    "    BN= ['balanced', 'balanced_subsample', None]\n",
    "    RN=[random.randint(0,100), None]\n",
    "    TF=[True,False]\n",
    "    list_of_parameters= [\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\",\n",
    "                         \"min_weight_fraction_leaf\", \"max_features\",\"max_leaf_nodes\", \"min_impurity_decrease\",\n",
    "                         \"min_impurity_split\",\"bootstrap\", \"oob_score\", \"n_jobs\", \"random_state\", \"verbose\",\n",
    "                         \"warm_start\",\"class_weight\", \"ccp_alpha\", \"max_samples\"]\n",
    "    random_values=[random.randint(100,200),criterion[random.randint(0,len(criterion)-1)],None,\n",
    "                   random.randint(2,10),random.randint(1,10),\n",
    "                   0.0,max_features[random.randint(0,len(max_features)-1)],\n",
    "                   None,0.0, None, TF[random.randint(0,len(TF)-1)], False,None,\n",
    "                   RN[random.randint(0,len(RN)-1)],random.randint(0,100), False,\n",
    "                   BN[random.randint(0,len(BN)-1)],0.0,None ]\n",
    "    return random_values\n",
    "def DT_params():\n",
    "    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n",
    "                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n",
    "    default_values=[\"gini\",\"best\",None, 2, 1, 0.0,None, None,None,0.0,None,None,0.0]\n",
    "    return default_values\n",
    "def DT_paramsRandom():\n",
    "    criterion =[\"gini\", \"entropy\"]\n",
    "    BN= ['balanced', None]\n",
    "    RN=[random.randint(0,100), None]\n",
    "    list_of_parameters= [\"criterion\",\"splitter\",\"max_depth\",\"min_samples_split\",\"min_samples_leaf\",\"min_weight_fraction_leaf\",\"max_features\",\n",
    "                         \"random_state\",\"max_leaf_nodes\",\"min_impurity_decrease\",\"class_weight\",\"ccp_alpha\" ]\n",
    "    random_values=[criterion[random.randint(0,len(criterion)-1)],\"best\",None,\n",
    "                   random.randint(2, 10), random.randint(1, 10),0.0,None, RN[random.randint(0,len(RN)-1)],None,0.0,None,\n",
    "                   BN[random.randint(0,len(BN)-1)],0.0]\n",
    "    return random_values\n",
    "def ANN_params():\n",
    "    return \"\"\n",
    "def ANN_paramsRandom():\n",
    "    return [random.randint(10,100)]\n",
    "#these functions split the datasets into target and data and return the preprocessed form\n",
    "def BugCatcherDatasetPreprocess():\n",
    "    data = arff.loadarff('Bugcatchers-unified-file.arff')\n",
    "    BugCatchers= pd.DataFrame(data[0])\n",
    "    BugCatchers_data=BugCatchers.iloc[:, 0:6]\n",
    "    BugCatchers_target = BugCatchers.iloc[:, 16]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(BugCatchers_target)\n",
    "    BugCatchers_target=label_encoder.transform(BugCatchers_target)\n",
    "    BugCatchers_data_normalized = preprocessing.normalize(BugCatchers_data)\n",
    "    BugCatchers_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugCatchers_data)\n",
    "    BugCatchers_data_standardized= preprocessing.StandardScaler().fit_transform(BugCatchers_data)\n",
    "    print( \"Bug Catchers dataset is preprocessed \\n\")\n",
    "    return BugCatchers_target,BugCatchers_data_normalized,BugCatchers_data_minmax_scalled,BugCatchers_data_standardized\n",
    "def PromiseDatasetPreprocess():\n",
    "    data = arff.loadarff('PROMISE-unified-class.arff')\n",
    "    PROMISE = pd.DataFrame(data[0])\n",
    "    PROMISE_data = PROMISE.iloc[:, 0:60]\n",
    "    PROMISE_target = PROMISE.iloc[:, 80]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(PROMISE_target)\n",
    "    PROMISE_target=label_encoder.transform(PROMISE_target)\n",
    "    PROMISE_data_normalized = preprocessing.normalize(PROMISE_data)\n",
    "    PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "    PROMISE_data_standardized= preprocessing.StandardScaler().fit_transform(PROMISE_data)\n",
    "    print(\"PROMISE dataset is preprocessed \\n\")\n",
    "    return PROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized\n",
    "def EclipseDatasetPreprocess():\n",
    "    data = arff.loadarff('Zimmerman-unified-file.arff')\n",
    "    Eclipse= pd.DataFrame(data[0])\n",
    "    Eclipse_data=Eclipse.iloc[:, 0:6]\n",
    "    Eclipse_target = Eclipse.iloc[:, 204]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(Eclipse_target)\n",
    "    Eclipse_target=label_encoder.transform(Eclipse_target)\n",
    "    Eclipse_data_normalized = preprocessing.normalize(Eclipse_data)\n",
    "    Eclipse_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(Eclipse_data)\n",
    "    Eclipse_data_standardized= preprocessing.StandardScaler().fit_transform(Eclipse_data)\n",
    "    print(\"Eclipse dataset is preprocessed \\n\")\n",
    "    return Eclipse_target, Eclipse_data_normalized,Eclipse_data_minmax_scalled,Eclipse_data_standardized\n",
    "def BugPredictionDatasetPreprocess():\n",
    "    data = arff.loadarff('BugPrediction-unified-class.arff')\n",
    "    BugPrediction= pd.DataFrame(data[0])\n",
    "    BugPrediction_data=BugPrediction.iloc[:, 0:60]\n",
    "    BugPrediction_target = BugPrediction.iloc[:, 97]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(BugPrediction_target)\n",
    "    BugPrediction_target=label_encoder.transform(BugPrediction_target)\n",
    "    BugPrediction_data_normalized = preprocessing.normalize(BugPrediction_data)\n",
    "    BugPrediction_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(BugPrediction_data)\n",
    "    BugPrediction_data_standardized= preprocessing.StandardScaler().fit_transform(BugPrediction_data)\n",
    "    print( \"Bug Prediction dataset is preprocessed \\n\")\n",
    "    return BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized\n",
    "def GitHubFileDatasetPreprocess():\n",
    "    data = arff.loadarff('GitHub-unified-file.arff')\n",
    "    GitHub_File= pd.DataFrame(data[0])\n",
    "    GitHub_File_data=GitHub_File.iloc[:, 0:6]\n",
    "    GitHub_File_target = GitHub_File.iloc[:, 10]\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(GitHub_File_target)\n",
    "    GitHub_File_target=label_encoder.transform(GitHub_File_target)\n",
    "    GitHub_File_data_normalized = preprocessing.normalize(GitHub_File_data)\n",
    "    GitHub_File_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_File_data)\n",
    "    GitHub_File_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_File_data)\n",
    "    print( \"GitHub File dataset is preprocessed \\n\")\n",
    "    return GitHub_File_target,GitHub_File_data_normalized,GitHub_File_data_minmax_scalled,GitHub_File_data_standardized\n",
    "def GitHubClassDatasetPreprocess():\n",
    "    data = arff.loadarff('GitHub-unified-class.arff')\n",
    "    GitHub_class= np.array(dataset['data'])\n",
    "    GitHub_class_data=GitHub_class.iloc[:, 0:60]\n",
    "    GitHub_class_target = GitHub_class.iloc[:, 60]\n",
    "    GitHub_class_data=data\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(GitHub_class_target)\n",
    "    GitHub_class_target=label_encoder.transform(GitHub_class_target)\n",
    "    GitHub_class_data_normalized = preprocessing.normalize(GitHub_class_data)\n",
    "    GitHub_class_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(GitHub_class_data)\n",
    "    GitHub_class_data_standardized= preprocessing.StandardScaler().fit_transform(GitHub_class_data)\n",
    "    print( \"GitHub Class dataset is preprocessed \\n\")\n",
    "    return GitHub_class_target,GitHub_class_data_normalized,GitHub_class_data_minmax_scalled,GitHub_class_data_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7URJPNv_t20",
    "outputId": "ed11d337-c9c6-46a3-a7ea-df2df9e47428"
   },
   "outputs": [],
   "source": [
    "BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()\n",
    "PROMISE_target,PROMISE_data_normalized,PROMISE_data_minmax_scalled,PROMISE_data_standardized=PromiseDatasetPreprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UH5ANUvF_t24"
   },
   "outputs": [],
   "source": [
    "X=PROMISE_data_normalized\n",
    "y=PROMISE_target\n",
    "def balanced_subsample(X,y,  min_elems = 5000):\n",
    "    #return a balnced subsample of min_elems of each class\n",
    "    x=[]\n",
    "    y_s=[]\n",
    "    for yi in np.unique(y):\n",
    "        elems = X[(y == yi)]\n",
    "        np.random.shuffle(elems)\n",
    "        for e in elems[0:min_elems,:]:\n",
    "            xx=[]\n",
    "            for c in e:\n",
    "                xx.append(c)\n",
    "            x.append(xx)\n",
    "        for e in range(0,min_elems):\n",
    "            y_s.append(0 if yi == 0 else 1)\n",
    "    return x,y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsP0VPc6_t24"
   },
   "outputs": [],
   "source": [
    "def generateInitialPopulation(SVM=1, KNN=1, DT=1, RF=1, LR=1, ANN=1):\n",
    "    included_clf=[\"SVM\", \"KNN\", \"DT\", \"RF\", \"LR\", \"ANN\"]\n",
    "    included=[1,1,1,1,1,1]\n",
    "    if(SVM==0):\n",
    "        included[0]=0\n",
    "    if (KNN == 0):\n",
    "        included[1] = 0\n",
    "    if (DT == 0):\n",
    "        included[2] = 0\n",
    "    if (RF == 0):\n",
    "        included[3] = 0\n",
    "    if (LR == 0):\n",
    "        included[4] = 0\n",
    "    if (ANN == 0):\n",
    "        included[5] = 0\n",
    "    in_use=[]\n",
    "    combinations_of_clf=[]\n",
    "    for i in range(6):\n",
    "        if(included[i]==1):\n",
    "            in_use.append(included_clf[i])\n",
    "    #generate diffrent combinations\n",
    "    for i in range(len(in_use)+1):\n",
    "        comb= combinations(in_use,i)\n",
    "        for j in list(comb):\n",
    "            element=[]\n",
    "            for k in range(len(j)):\n",
    "                element.append(j[k])\n",
    "            if element!=[]:\n",
    "                combinations_of_clf.append( element)\n",
    "    population = []\n",
    "    # generate random paramters for all diffrent combinations\n",
    "    for combination in list(combinations_of_clf):\n",
    "        chromosome = {}\n",
    "        for clf in list(combination):\n",
    "            genes=[]\n",
    "            if(clf==\"SVM\"):\n",
    "                genes= SVM_paramsRandom()\n",
    "                chromosome[\"SVM\"]=genes\n",
    "            if (clf == \"LR\"):\n",
    "                genes = LR_paramsRandom()\n",
    "                chromosome[\"LR\"]=genes\n",
    "            if (clf == \"KNN\"):\n",
    "                genes = KNN_paramsRandom()\n",
    "                chromosome[\"KNN\"]=genes\n",
    "            if (clf == \"RF\"):\n",
    "                genes = RF_paramsRandom()\n",
    "                chromosome[\"RF\"]=genes\n",
    "            if (clf == \"DT\"):\n",
    "                genes = DT_paramsRandom()\n",
    "                chromosome[\"DT\"]=genes\n",
    "            if (clf == \"ANN\"):\n",
    "                genes = ANN_paramsRandom()\n",
    "                chromosome[\"ANN\"]=genes\n",
    "        if population != None:\n",
    "            population.append(chromosome)\n",
    "        else:\n",
    "            population=chromosome\n",
    "        #combine into one population and return\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfjGAGvD_t25"
   },
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    #Generate random indices\n",
    "    index1 = random.randint(0, len(parent1) - 1)\n",
    "    index2 = random.randint(0, len(parent2) - 1)\n",
    "    offspring1={}\n",
    "    #create offspring from 0 to index1 of parent 1 and index2 till the end of parent 2\n",
    "    for i in range(0,index1):\n",
    "        key = list(parent1)[i]\n",
    "        if (offspring1 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring1.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring1[keytoadd] = parent1[key]\n",
    "        else:\n",
    "            offspring1[key] = parent1[key]\n",
    "    for j in range(index2,len(parent2)):\n",
    "        key = list(parent2)[j]\n",
    "        if (offspring1 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring1.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring1[keytoadd] = parent2[key]\n",
    "        else:\n",
    "            offspring1[key] = parent2[key]\n",
    "\n",
    "    #create offspring from 0 to index2 of parent 2 and index1 till the end of parent 1\n",
    "    offspring2={}\n",
    "    for i in range(0,index2):\n",
    "        key = list(parent2)[i]\n",
    "        if(offspring2!={}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring2.keys():\n",
    "                count+=1\n",
    "                keytoadd=key.split('-')[0]+\"-\"+str(count)\n",
    "            offspring2[keytoadd] = parent2[key]\n",
    "        else:\n",
    "             offspring2[key]=parent2[key]\n",
    "    for j in range(index1,len(parent1)):\n",
    "        key = list(parent1)[j]\n",
    "        if (offspring2 != {}):\n",
    "            count = 0\n",
    "            keytoadd =key.split('-')[0]\n",
    "            while keytoadd in offspring2.keys():\n",
    "                count+=1\n",
    "                keytoadd = key.split('-')[0] + \"-\" + str(count)\n",
    "            offspring2[keytoadd] = parent1[key]\n",
    "        else:\n",
    "            offspring2[key] = parent1[key]\n",
    "    print(\"offspring1\",offspring1)\n",
    "    print(\"offspring2\",offspring2)\n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iindbiY_t25"
   },
   "outputs": [],
   "source": [
    "def ANN_model(num=50):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create an ANN\n",
    "    model =Sequential()\n",
    "    model.add(Dense(num, activation='relu', input_shape=[60]))\n",
    "    model.add(Dense(int(num/2),activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDwsHHDW_t25"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fitness(chromosome,X_train,y_train,X_test,y_test,alpha=1, beta=0,gamma=0, ensemble=\"vote\" ,count=0,gen=0):\n",
    "    fitness=0\n",
    "    clfs={}\n",
    "    for gene in chromosome:\n",
    "        # Check the gene classifier and creates a model from the paramters\n",
    "        params = chromosome[gene]\n",
    "        gene1=gene\n",
    "        if(len(gene.split('-'))>1):\n",
    "            genecount=gene.split('-')[1]\n",
    "            print(genecount)\n",
    "        else:\n",
    "            genecount=None\n",
    "        gene=gene.split('-')[0]\n",
    "        clf1=gene\n",
    "        if(genecount==None or genecount!='0'):\n",
    "            if gene==\"SVM\":\n",
    "                clf1=SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n",
    "                        coef0=params[4], shrinking=params[5], probability=True,\n",
    "                        tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10], max_iter=params[11],\n",
    "                        decision_function_shape=params[12])\n",
    "            if gene==\"KNN\":\n",
    "                clf1=KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n",
    "                                         leaf_size=params[3], p=params[4], metric=params[5],\n",
    "                                         metric_params=params[6], n_jobs=1)\n",
    "            if gene==\"DT\":\n",
    "                clf1=DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n",
    "                                            min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                            min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                            random_state=params[7], max_leaf_nodes=params[8], min_impurity_decrease=params[9],\n",
    "                                            min_impurity_split=params[10], class_weight=params[11])\n",
    "            if gene == \"RF\":\n",
    "                clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n",
    "                                              min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                              min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                              max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                              min_impurity_split=params[9],\n",
    "                                              bootstrap=params[10], oob_score=params[11], n_jobs=1,\n",
    "                                              random_state=params[13], verbose=params[14], warm_start=params[15],\n",
    "                                              class_weight=params[16])\n",
    "            if gene==\"LR\":\n",
    "                clf1=LogisticRegression(penalty='l2',dual=False, tol=params[2], C=params[3], fit_intercept=params[4],\n",
    "                                       intercept_scaling=params[5], class_weight=params[6], random_state=params[7], solver=params[8],\n",
    "                                       max_iter=params[9], multi_class=params[10], verbose=params[11], warm_start=params[12], n_jobs=1,\n",
    "                                      )\n",
    "            if gene==\"ANN\":\n",
    "                clf1 =KerasClassifier(build_fn=ANN_model,num=params[0], epochs=500, verbose=False)\n",
    "                clf1._estimator_type = \"classifier\"\n",
    "            clfs[gene1]=clf1\n",
    "    estimators=[]\n",
    "    for clf in clfs:\n",
    "        print(clf)\n",
    "        estimators.append((clf,clfs[clf]))\n",
    "    if(len(estimators)>0):\n",
    "        eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n",
    "        eclf.fit(X_train,y_train)\n",
    "        y_pred=eclf.predict(X_test)\n",
    "\n",
    "        #Get confusion matrix and calculate the ACC, MCC AND F1\n",
    "        cm=confusion_matrix(y_test, y_pred)\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        print( cm)\n",
    "        accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "        print(\"accuracy:\",accuracy)\n",
    "        mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "        print(\"mcc:\",mcc)\n",
    "        precision =(TP/(TP+FP))\n",
    "        recall= (TP/(TP+FN))\n",
    "        f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "        print(\"f1_score:\",f1_score)\n",
    "        if isnan(accuracy) or isnan(f1_score):\n",
    "            accuracy=0\n",
    "        if isnan(mcc):\n",
    "            mcc=0\n",
    "        if isnan(f1_score):\n",
    "            f1_score=0\n",
    "        fitness=(((alpha*accuracy)+ (beta*mcc)+(gamma*f1_score)))\n",
    "        print(\"Fitness:\",fitness)\n",
    "        return fitness, {\"mcc\":[mcc],\"acc\":[accuracy],\"f1\":[f1_score],\"cm\":[cm]},eclf\n",
    "    else:\n",
    "        return 0,{},None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_-xMWlC_t26"
   },
   "outputs": [],
   "source": [
    "def rename(old_dict,old_name,new_name):\n",
    "    new_dict = {}\n",
    "    for key,value in zip(old_dict.keys(),old_dict.values()):\n",
    "        new_key = key if key != old_name else new_name\n",
    "        new_dict[new_key] = old_dict[key]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5wesBFd_t26"
   },
   "outputs": [],
   "source": [
    "def Mutation(chromosome,X_train,y_train,X_val,y_val):\n",
    "    #Generate random index and set to 0 or 1 accordingly\n",
    "    threshold = random.uniform(0, 1)\n",
    "    index= random.randint(0,len(chromosome)-1)\n",
    "    if(threshold<=0.5):\n",
    "        if len(list(chromosome)[index].split('-'))==1:\n",
    "            print(\"set to 0\")\n",
    "            chromosome= rename(chromosome,list(chromosome)[index], list(chromosome)[index]+\"-0\")\n",
    "        elif(( len(list(chromosome)[index].split('-'))>1 and list(chromosome)[index].split('-')[1]=='0') or (len(list(chromosome)[index].split('-'))>2 and (list(chromosome)[index].split('-'))[2]=='0') ):\n",
    "            print(\"set to 1\")\n",
    "            count = 0\n",
    "            key=list(chromosome)[index].split('-')[0]\n",
    "            keytoadd = key\n",
    "            while keytoadd in chromosome.keys():\n",
    "                count+=1\n",
    "                keytoadd = key + \"-\" + str(count)\n",
    "            chromosome =rename(chromosome,list(chromosome)[index], keytoadd)\n",
    "        else:\n",
    "            print(\"set to 0\")\n",
    "            chromosome = rename(chromosome, list(chromosome)[index], list(chromosome)[index] + \"-0\")\n",
    "    else:\n",
    "        print(index)\n",
    "        gene = list(chromosome)[index]\n",
    "        print(gene)\n",
    "        clf1 = gene\n",
    "        options = []\n",
    "        gene1 = list(chromosome)[index]\n",
    "        gene=list(chromosome)[index].split('-')[0]\n",
    "        if gene == \"SVM\" or gene == \"KNN\" or gene == \"DT\" or gene == \"RF\" or gene == \"LR\" or gene == \"ANN\":\n",
    "            if gene == \"SVM\" or gene == \"SVM-0\":\n",
    "                clf1 = SVC()\n",
    "                c = list(range(1, 1000))\n",
    "                c.append(0.01)\n",
    "                c.append(0.1)\n",
    "                params = {'C': c, 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                          \"degree\": list(range(0, 100)), 'gamma': [1e-3, 1e-4],\n",
    "                          \"coef0\": [x * 0.1 for x in range(0, 10)],\n",
    "                          'class_weight': [{0: 0.01}, {1: 1}, {1: 2}, {1: 10}, {1: 50}, 'balanced']}\n",
    "            if gene == \"KNN\" or gene == \"KNN-0\":\n",
    "                clf1 = KNeighborsClassifier()\n",
    "                params = {\"n_neighbors\": list(range(1, 50)), \"weights\": ['uniform', \"distance\"],\n",
    "                          \"leaf_size\": list(range(1, 100)), \"p\": [1, 2],\n",
    "                          \"metric\": ['minkowski', 'euclidean', 'manhattan']}\n",
    "            if gene == \"DT\" or gene == \"DT-0\":\n",
    "                clf1 = DecisionTreeClassifier()\n",
    "                BN = ['balanced', None]\n",
    "                RN = [random.randint(0, 100), None]\n",
    "                max_features = ['auto', 'sqrt']\n",
    "                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "                max_depth.append(None)\n",
    "                min_samples_split = list(range(2, 10))\n",
    "                min_samples_leaf = list(range(1, 6))\n",
    "                params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                          'max_features': max_features,\n",
    "                          'max_depth': max_depth,\n",
    "                          'min_samples_split': min_samples_split,\n",
    "                          'min_samples_leaf': min_samples_leaf,\n",
    "                          }\n",
    "            if gene == \"RF\" or gene == \"RF-0\":\n",
    "                clf1 = RandomForestClassifier()\n",
    "                n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "                max_features = ['auto', 'sqrt']\n",
    "                max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "                max_depth.append(None)\n",
    "                min_samples_split = list(range(2, 10))\n",
    "                min_samples_leaf = list(range(1, 4))\n",
    "                bootstrap = [True, False]\n",
    "                params = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "                          'n_estimators': n_estimators,\n",
    "                          'max_features': max_features,\n",
    "                          'max_depth': max_depth,\n",
    "                          'min_samples_split': min_samples_split,\n",
    "                          'min_samples_leaf': min_samples_leaf,\n",
    "                          'bootstrap': bootstrap}\n",
    "            if gene == \"LR\" or gene == \"LR-0\":\n",
    "                clf1 = LogisticRegression()\n",
    "                c = list(range(1, 1000))\n",
    "                c.append(0.1)\n",
    "                c.append(0.001)\n",
    "                params = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                          'penalty': ['l2'],\n",
    "                          'C': c}\n",
    "            if gene == \"ANN\" or gene == \"ANN-0\":\n",
    "                params = {\"num\": list(range(2, 100)), \"epochs\": list(range(400, 600))}\n",
    "                clf1 = KerasClassifier(build_fn=ANN_model, epochs=500, verbose=False)\n",
    "                clf1._estimator_type = \"classifier\"\n",
    "            print(clf1)\n",
    "            randomclf = RandomizedSearchCV(estimator=clf1, param_distributions=params,\n",
    "                                           n_iter=len(params), cv=5, verbose=2, random_state=42,\n",
    "                                           n_jobs=1)\n",
    "            search = randomclf.fit(X_train, y_train)\n",
    "            param = search.cv_results_\n",
    "            options = param['params']\n",
    "        if gene1 == \"SVM-0\" or gene1 == \"KNN-0\" or gene1 == \"DT-0\" or gene1 == \"RF-0\" or gene1 == \"LR-0\" or gene1 == \"ANN-0\":\n",
    "            options.append(None)\n",
    "        clfs = {}\n",
    "        eclfs = {}\n",
    "        ocount = 0\n",
    "        fop = {}\n",
    "        ecount = 0\n",
    "        # for all other calssifers get the parameters from the chromosomes and generate a new model\n",
    "        for option in options:\n",
    "            op = {}\n",
    "            count = 0\n",
    "            for gene in chromosome:\n",
    "                op1 = {}\n",
    "                params = chromosome[gene]\n",
    "                clf1 = gene\n",
    "                if count == index:\n",
    "                    if option == None:\n",
    "                        clf1 = None\n",
    "                    if option != None:\n",
    "                        gene1=gene\n",
    "                        gene=gene.split('-')[0]\n",
    "                        print(gene)\n",
    "                        if gene == \"SVM\" or gene == \"SVM-0\":\n",
    "                            clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], degree=option[\"degree\"],\n",
    "                                       gamma=option[\"gamma\"],\n",
    "                                       coef0=option[\"coef0\"], shrinking=params[5], probability=True,\n",
    "                                       tol=params[7], cache_size=params[8], class_weight=option[\"class_weight\"],\n",
    "                                       verbose=params[10],\n",
    "                                       max_iter=params[11],\n",
    "                                       decision_function_shape=params[12])\n",
    "                            # clf1 = SVC(C=option[\"C\"], kernel=option[\"kernel\"], gamma=option[\"gamma\"],\n",
    "                            # class_weight=option[\"class_weight\"])\n",
    "                            op1[gene1] = [option[\"C\"], option[\"kernel\"], option[\"degree\"], option[\"gamma\"],\n",
    "                                          option[\"coef0\"], params[5], True,\n",
    "                                          params[7], params[8], option[\"class_weight\"], params[10], params[11],\n",
    "                                          params[12]]\n",
    "                        if gene == \"KNN\" or gene == \"KNN-0\":\n",
    "                            clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"], weights=option[\"weights\"],\n",
    "                                                        algorithm=params[2],\n",
    "                                                        leaf_size=option[\"leaf_size\"], p=option[\"p\"],\n",
    "                                                        metric=option[\"metric\"],\n",
    "                                                        metric_params=params[6], n_jobs=1)\n",
    "                            op1[gene1] = [option[\"n_neighbors\"], option[\"weights\"], params[2], option[\"leaf_size\"],\n",
    "                                          option[\"p\"], option[\"metric\"],\n",
    "                                          params[6], 1]\n",
    "                            # clf1 = KNeighborsClassifier(n_neighbors=option[\"n_neighbors\"],\n",
    "                            # leaf_size=option[\"leaf_size\"], p=option[\"p\"])\n",
    "                            # op1[\"KNN\"]=[option[\"n_neighbors\"],option[\"leaf_size\"],option[\"p\"]]\n",
    "                        if gene == \"DT\" or gene == \"DT-0\":\n",
    "                            clf1 = DecisionTreeClassifier(criterion=option[\"criterion\"], splitter=params[1],\n",
    "                                                          max_depth=option[\"max_depth\"],\n",
    "                                                          min_samples_split=option[\"min_samples_split\"],\n",
    "                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                                                          min_weight_fraction_leaf=params[5],\n",
    "                                                          max_features=option[\"max_features\"],\n",
    "                                                          random_state=params[7], max_leaf_nodes=params[8],\n",
    "                                                          min_impurity_decrease=params[9],\n",
    "                                                          min_impurity_split=params[10], class_weight=params[11])\n",
    "                            op1[gene1] = [option[\"criterion\"], params[1], option[\"max_depth\"],\n",
    "                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"], params[5],\n",
    "                                         option[\"max_features\"],\n",
    "                                         params[7], params[8], params[9], params[10], params[11]]\n",
    "                            # clf1 = DecisionTreeClassifier(max_depth=option[\"max_depth\"],\n",
    "                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                            #                               max_features=option[\"max_features\"])\n",
    "                            # op1[\"DT\"]=[option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],option[\"max_features\"]]\n",
    "                        if gene == \"RF\" or gene == \" RF-0\":\n",
    "                            clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"],\n",
    "                                                          criterion=option[\"criterion\"], max_depth=option[\"max_depth\"],\n",
    "                                                          min_samples_split=option[\"min_samples_split\"],\n",
    "                                                          min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                                                          min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                          max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                                          min_impurity_split=params[9],\n",
    "                                                          bootstrap=option[\"bootstrap\"], oob_score=params[11], n_jobs=1,\n",
    "                                                          random_state=params[13], verbose=params[14],\n",
    "                                                          warm_start=params[15],\n",
    "                                                          class_weight=params[16])\n",
    "                            op1[gene1] = [option[\"n_estimators\"], option[\"criterion\"], option[\"max_depth\"],\n",
    "                                         option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n",
    "                                         params[5], option[\"max_features\"],\n",
    "                                         params[7], params[8], params[9], option[\"bootstrap\"], params[11], 1,\n",
    "                                         params[13], params[14],\n",
    "                                         params[15], params[16]]\n",
    "                            # clf1 = RandomForestClassifier(n_estimators=option[\"n_estimators\"], max_depth=option[\"max_depth\"],\n",
    "                            #                               min_samples_split=option[\"min_samples_split\"], min_samples_leaf=option[\"min_samples_leaf\"],\n",
    "                            #                               max_features=option[\"max_features\"],\n",
    "                            #                               bootstrap=option[\"bootstrap\"])\n",
    "                            # op1[\"RF\"]=[option[\"n_estimators\"],option[\"max_depth\"],option[\"min_samples_split\"], option[\"min_samples_leaf\"],\n",
    "                            #            option[\"max_features\"],option[\"bootstrap\"]]\n",
    "                        if gene == \"LR\" or gene == \" LR-0\":\n",
    "                            clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=option[\"C\"],\n",
    "                                                      fit_intercept=params[4],\n",
    "                                                      intercept_scaling=params[5], class_weight=params[6],\n",
    "                                                      random_state=params[7],\n",
    "                                                      solver=option[\"solver\"],\n",
    "                                                      max_iter=params[9], multi_class=params[10], verbose=params[11],\n",
    "                                                      warm_start=params[12], n_jobs=1,\n",
    "                                                      )\n",
    "                            op1[gene1] = [\"l2\", False, params[2], option[\"C\"], params[4], params[5], params[6],\n",
    "                                         params[7], option[\"solver\"], params[9], params[10], params[11], params[12],\n",
    "                                         1, ]\n",
    "                            # clf1 = LogisticRegression(penalty='l2', C=option[\"C\"],solver=option[\"solver\"])\n",
    "                            # op1[\"LR\"]=[\"l2\",option[\"C\"],option[\"solver\"]]\n",
    "                        if gene == \"ANN\" or gene == \"ANN -0\":\n",
    "                            clf1 = KerasClassifier(build_fn=ANN_model, num=option[\"num\"],\n",
    "                                                                                  epochs=500,\n",
    "                                                                                  verbose=False)\n",
    "                            clf1._estimator_type = \"classifier\"\n",
    "                            op1[gene1] = [option[\"num\"]]\n",
    "                else:\n",
    "                    gene1=gene\n",
    "                    gene=gene.split('-')[0]\n",
    "                    if gene == \"SVM\":\n",
    "                        clf1 = SVC(C=params[0], kernel=params[1], degree=params[2], gamma=params[3],\n",
    "                                   coef0=params[4], shrinking=params[5], probability=True,\n",
    "                                   tol=params[7], cache_size=params[8], class_weight=params[9], verbose=params[10],\n",
    "                                   max_iter=params[11],\n",
    "                                   decision_function_shape=params[12])\n",
    "                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], True,\n",
    "                                      params[7], params[8], params[9], params[10], params[11],\n",
    "                                      params[12]]\n",
    "                    if gene == \"KNN\":\n",
    "                        clf1 = KNeighborsClassifier(n_neighbors=params[0], weights=params[1], algorithm=params[2],\n",
    "                                                    leaf_size=params[3], p=params[4], metric=params[5],\n",
    "                                                    metric_params=params[6], n_jobs=1)\n",
    "                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5],\n",
    "                                      params[6], 1]\n",
    "                    if gene == \"DT\":\n",
    "                        clf1 = DecisionTreeClassifier(criterion=params[0], splitter=params[1], max_depth=params[2],\n",
    "                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                      random_state=params[7], max_leaf_nodes=params[8],\n",
    "                                                      min_impurity_decrease=params[9],\n",
    "                                                      min_impurity_split=params[10], class_weight=params[11])\n",
    "                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11]]\n",
    "                    if gene == \"RF\":\n",
    "                        clf1 = RandomForestClassifier(n_estimators=params[0], criterion=params[1], max_depth=params[2],\n",
    "                                                      min_samples_split=params[3], min_samples_leaf=params[4],\n",
    "                                                      min_weight_fraction_leaf=params[5], max_features=params[6],\n",
    "                                                      max_leaf_nodes=params[7], min_impurity_decrease=params[8],\n",
    "                                                      min_impurity_split=params[9],\n",
    "                                                      bootstrap=params[10], oob_score=params[11], n_jobs=1,\n",
    "                                                      random_state=params[13], verbose=params[14],\n",
    "                                                      warm_start=params[15],\n",
    "                                                      class_weight=params[16])\n",
    "                        op1[gene1] = [params[0], params[1], params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11], 1, params[13], params[14],\n",
    "                                     params[15], params[16]]\n",
    "                    if gene == \"LR\":\n",
    "                        clf1 = LogisticRegression(penalty='l2', dual=False, tol=params[2], C=params[3],\n",
    "                                                  fit_intercept=params[4],\n",
    "                                                  intercept_scaling=params[5], class_weight=params[6],\n",
    "                                                  random_state=params[7],\n",
    "                                                  solver=params[8],\n",
    "                                                  max_iter=params[9], multi_class=params[10], verbose=params[11],\n",
    "                                                  warm_start=params[12], n_jobs=1,\n",
    "                                                  )\n",
    "                        op1[gene1] = [\"l2\", False, params[2], params[3], params[4], params[5], params[6],\n",
    "                                     params[7], params[8], params[9], params[10], params[11], params[12], 1, ]\n",
    "                    if gene == \"ANN\":\n",
    "                        clf1 = KerasClassifier(build_fn=ANN_model, num=params[0],\n",
    "                                                                              epochs=500,\n",
    "                                                                              verbose=False)\n",
    "                        clf1._estimator_type = \"classifier\"\n",
    "                        op1[gene1] = [params[0]]\n",
    "                op[str(count)] = op1\n",
    "                count = count + 1\n",
    "                clfs[gene1] = clf1\n",
    "            fop[str(ocount)] = op\n",
    "            ocount = ocount + 1\n",
    "            estimators=[]\n",
    "            for clf in clfs:\n",
    "              print(clf)\n",
    "              estimators.append((clf,clfs[clf]))\n",
    "            if(len(estimators)>0):\n",
    "              eclf = VotingClassifier(estimators, voting='hard',flatten_transform=True)\n",
    "              eclfs[str(ecount)] = eclf\n",
    "              ecount = ecount + 1\n",
    "        print(fop)\n",
    "        print(eclfs)\n",
    "        try:\n",
    "            # set all the ensembles model in a pipeline to be able to select the best out of them using gridsearch\n",
    "            pipe = Pipeline([(\"classifier\", VotingClassifier(estimators=KNeighborsClassifier()))])\n",
    "            search_space = []\n",
    "            for ens in eclfs:\n",
    "                search_space.append({\"classifier\": [eclfs[ens]]})\n",
    "            print(search_space)\n",
    "            gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=5, n_jobs=1)\n",
    "            best_model = gridsearch.fit(X_val, y_val)\n",
    "            best = best_model.best_params_\n",
    "            print(best)\n",
    "            c = 0\n",
    "            for ss in eclfs:\n",
    "                print({'classifier': eclfs[ss]} == best)\n",
    "                if ({'classifier': eclfs[ss]} == best):\n",
    "                    chromosomes = fop[str(c)]\n",
    "                    if c == len(eclfs):\n",
    "                        index -= 1\n",
    "                c = c + 1\n",
    "            print(chromosomes)\n",
    "\n",
    "            # return the best ensemble in the right chromosome form\n",
    "            chromosome1 = chromosomes\n",
    "            chromosome2 = {}\n",
    "            for key in chromosome1:\n",
    "                ch = chromosome1[key]\n",
    "                for k in ch:\n",
    "                    chromosome2[k] = ch[k]\n",
    "            chromosome = chromosome2\n",
    "        except:\n",
    "            c = 0\n",
    "            fit=[]\n",
    "            cc=[]\n",
    "            for eclf in eclfs:\n",
    "                chromosomes = fop[str(c)]\n",
    "                c = c + 1\n",
    "                print(chromosomes)\n",
    "                chromosome1 = chromosomes\n",
    "                chromosome2 = {}\n",
    "                for key in chromosome1:\n",
    "                    ch = chromosome1[key]\n",
    "                    for k in ch:\n",
    "                        chromosome2[k] = ch[k]\n",
    "                f, info,model=fitness(chromosome2,X_train,y_train,X_val,y_val)\n",
    "                fit.append(f)\n",
    "                cc.append(chromosome2)\n",
    "            chromosome = cc[fit.index(max(fit))]\n",
    "\n",
    "    print(chromosome)\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvoLiXNm_t26"
   },
   "outputs": [],
   "source": [
    "def roulette2(poplulation, n, fit_array):\n",
    "    fit={}\n",
    "    fitness = fit_array\n",
    "    for chromosome, i in zip(poplulation, range(0, len(poplulation))):\n",
    "        fit[str(chromosome)] = fit_array[i]\n",
    "    #calculate total fitness\n",
    "    total_fitness = float(sum(fit[str(chromosome)] for chromosome in poplulation))\n",
    "    parents=[]\n",
    "    weights=[]\n",
    "    #generate probability of Fi/sum of weights\n",
    "    for  i in range(0, len(fitness)):\n",
    "        weights.append(fitness[i] / total_fitness)\n",
    "\n",
    "    #genrate a random number and return when the chromosome at that weight is reached\n",
    "    while n:\n",
    "        r = np.random.rand()\n",
    "        acc = 0\n",
    "        idx = -1\n",
    "        while acc < r:\n",
    "            idx += 1\n",
    "            acc += weights[idx]\n",
    "        parents.append(poplulation[idx])\n",
    "        n-=1\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwgyJsjO_t26"
   },
   "outputs": [],
   "source": [
    "def generateNewPopulation(population,all_fitness, X_train,y_train,X_val,y_val,crossover_prob=0.8, mutation_prob=0.1,elitism_range=0.2):\n",
    "    new_population=[]\n",
    "    elitism_fitness= all_fitness.copy()\n",
    "    elitism_population= population.copy()\n",
    "    #copy chromosomes in range of elitism rate and check for repetition\n",
    "    for i in range(0, int(elitism_range*len(population))):\n",
    "        max_index=elitism_fitness.index(max(elitism_fitness))\n",
    "        if(elitism_population[max_index] in new_population):\n",
    "            elitism_fitness.pop(max_index)\n",
    "            elitism_population.pop(max_index)\n",
    "        else:\n",
    "            new_population.append(elitism_population[max_index])\n",
    "            elitism_fitness.pop(max_index)\n",
    "            elitism_population.pop(max_index)\n",
    "    print(\"new_population\",new_population)\n",
    "\n",
    "    #while the length of the new population still has not reach 63 select mutate and crossover chromomsmes\n",
    "    while(len(new_population)<len(population)):\n",
    "        count = 0\n",
    "        parents = roulette2(population,2,all_fitness)\n",
    "        if np.random.random() < crossover_prob and len(new_population)<len(population)-1:\n",
    "            print(\"crossover\",parents[count])\n",
    "            print(\"and\",parents[count+1] )\n",
    "            sp1,sp2=crossover(parents[count], parents[count + 1])\n",
    "            new_population.append(sp1)\n",
    "            new_population.append(sp2)\n",
    "        parents = roulette2(population,1,all_fitness)\n",
    "        if np.random.random() < mutation_prob and len(new_population)<len(population):\n",
    "            print(\"Mutation\", parents[count])\n",
    "            try:\n",
    "              mutated=Mutation(parents[count],X_train,y_train,X_val,y_val)\n",
    "              new_population.append(mutated)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"not mutated\")\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zD7Lh6X_t27"
   },
   "outputs": [],
   "source": [
    "from numpy import array, savetxt, loadtxt\n",
    "from numpy import savetxt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "mods=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMV4bgaS_t27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GA( crossover_prob=0.85, mutation_prob=0.15, elitism_range=0.15, max_generation=100, convergence_rate=100):\n",
    "    #generate initial population\n",
    "    population=generateInitialPopulation()\n",
    "    print(\"initial population\", population)\n",
    "    gen=0\n",
    "    convergence_count=0\n",
    "    best_fits= {'0': {\"{'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}\": [0.6936, {'mcc': [0.3868607017236362], 'acc': [0.6936], 'f1': [0.683993399339934], 'cm': [array([[905, 367],\n",
    "           [399, 829]])]}]}, '1': {\"{'SVM': [56.651175987316705, 'linear', 93, 0.001, 0.5419741160525751, False, True, 0.001, 200, None, False, -1, 'ovr', False, 39], 'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}\": [0.6892, {'mcc': [0.37873304414332953], 'acc': [0.6892], 'f1': [0.6885771543086171], 'cm': [array([[864, 408],\n",
    "           [369, 859]])]}]}, '2': {\"{'DT': ['entropy', 'best', None, 6, 9, 0.0, None, 53, None, 0.0, None, 'balanced', 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [95]}\": [0.692, {'mcc': [0.3843162871199211], 'acc': [0.692], 'f1': [0.6912590216519647], 'cm': [array([[868, 404],\n",
    "           [366, 862]])]}]}, '3': {\"{'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}\": [0.6936, {'mcc': [0.38877714769982136], 'acc': [0.6936], 'f1': [0.6666666666666667], 'cm': [array([[968, 304],\n",
    "           [462, 766]])]}]}, '4': {\"{'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'KNN': [3, 'distance', 'auto', 99, 7, 'manhattan', None, None], 'RF': [164, 'gini', None, 10, 3, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 72, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 4, 9, 0.0, None, None, None, 0.0, None, None, 0.0]}\": [0.692, {'mcc': [0.38450722234769114], 'acc': [0.692], 'f1': [0.6706586826347305], 'cm': [array([[946, 326],\n",
    "           [444, 784]])]}]}, '5': {\"{'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [29]}\": [0.6952, {'mcc': [0.39086561376102064], 'acc': [0.6952], 'f1': [0.6746370623398804], 'cm': [array([[948, 324],\n",
    "           [438, 790]])]}]}, '6': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.6976, {'mcc': [0.39488837584444486], 'acc': [0.6976], 'f1': [0.6863070539419087], 'cm': [array([[917, 355],\n",
    "           [401, 827]])]}]}, '7': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.6944, {'mcc': [0.3884778918890737], 'acc': [0.6944], 'f1': [0.6829875518672198], 'cm': [array([[913, 359],\n",
    "           [405, 823]])]}]}, '8': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.6948, {'mcc': [0.39044156980468053], 'acc': [0.6948], 'f1': [0.6718279569892474], 'cm': [array([[956, 316],\n",
    "           [447, 781]])]}]}, '9': {\"{'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 9, 1, 0.0, None, 37, None, 0.0, None, 'balanced', 0.0], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}\": [0.6944, {'mcc': [0.3886106160244197], 'acc': [0.6944], 'f1': [0.6889250814332247], 'cm': [array([[890, 382],\n",
    "           [382, 846]])]}]}, '10': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.6972, {'mcc': [0.39475222745104804], 'acc': [0.6972], 'f1': [0.6777352064708387], 'cm': [array([[947, 325],\n",
    "           [432, 796]])]}]}, '11': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [15]}\": [0.6988, {'mcc': [0.39728542086093516], 'acc': [0.6988], 'f1': [0.690505548705302], 'cm': [array([[907, 365],\n",
    "           [388, 840]])]}]}, '12': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [15]}\": [0.6972, {'mcc': [0.3943055767931843], 'acc': [0.6972], 'f1': [0.6817990752416981], 'cm': [array([[932, 340],\n",
    "           [417, 811]])]}]}, '13': {\"{'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.6996, {'mcc': [0.39891468547875875], 'acc': [0.6996], 'f1': [0.6877338877338878], 'cm': [array([[922, 350],\n",
    "           [401, 827]])]}]}, '14': {\"{'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, 1, None, 11, False, 'balanced'], 'ANN': [11]}\": [0.6964, {'mcc': [0.3924724619610522], 'acc': [0.6964], 'f1': [0.6857142857142857], 'cm': [array([[913, 359],\n",
    "           [400, 828]])]}]}, '15': {\"{'RF-2': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}\": [0.7064, {'mcc': [0.41308197526509216], 'acc': [0.7064], 'f1': [0.6887192536047497], 'cm': [array([[954, 318],\n",
    "           [416, 812]])]}]}, '16': {\"{'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [15]}\": [0.7012, {'mcc': [0.4021206529515525], 'acc': [0.7012], 'f1': [0.6893970893970893], 'cm': [array([[924, 348],\n",
    "           [399, 829]])]}]}, '17': {\"{'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}\": [0.7, {'mcc': [0.3998322819838717], 'acc': [0.7], 'f1': [0.685929648241206], 'cm': [array([[931, 341],\n",
    "           [409, 819]])]}]}, '18': {\"{'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [11]}\": [0.7, {'mcc': [0.40070187812968333], 'acc': [0.7], 'f1': [0.6786632390745502], 'cm': [array([[958, 314],\n",
    "           [436, 792]])]}]}, '19': {\"{'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR-1': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}\": [0.7004, {'mcc': [0.4004838829043361], 'acc': [0.7004], 'f1': [0.6898550724637681], 'cm': [array([[918, 354],\n",
    "           [395, 833]])]}]}}\n",
    "    for i in range(0,len( best_fits)-1):\n",
    "        if best_fits[str(i)]==best_fits[str(i+1)]:\n",
    "            convergence_count+=1\n",
    "        if (convergence_count >0 and convergence_count% 5==0 ):\n",
    "            if mutation <0.85:\n",
    "                    mutation_prob+=0.1\n",
    "                    convergence_count=0\n",
    "    \n",
    "    models=[]\n",
    "    #split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "    #while stop conditions not met\n",
    "\n",
    "    ii=0\n",
    "    while gen<max_generation  and convergence_count<convergence_rate:\n",
    "        print(\"gen\", gen)\n",
    "        print(\"population\", population)\n",
    "        all_fitness = []\n",
    "        all_mod = []\n",
    "        done=[]\n",
    "        all_info = []\n",
    "        if gen ==20:\n",
    "            population= [{'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR-1': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [15]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [15]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, 1, None, 11, False, 'balanced'], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-3': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [15]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-2': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-3': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [11]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, 1, None, 11, False, 'balanced'], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, 1, None, 11, False, 'balanced'], 'ANN': [19]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [11]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'ANN': [15]}, {'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [11]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'RF': [1000, 'gini', 10, 6, 3, 0.0, 'sqrt', None, 0.0, None, False, False, 1, 25, 31, False, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'ANN': [11]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'LR': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-2': ['entropy', 'best', 50, 8, 2, 0.0, 'auto', 61, None, 0.0, None, None]}, {'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'ANN': [19]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [15]}, {'RF-1-0': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [1000, 'gini', 10, 6, 3, 0.0, 'sqrt', None, 0.0, None, False, False, 1, 25, 31, False, None], 'ANN': [11]}, {'RF-1-0': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [15]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'ANN': [15]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, False, 0.001, 200, 'balanced', True, -1, 'ovr', False, None], 'ANN': [11]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [15]}, {'ANN': [15]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-3': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'DT-2': ['gini', 'best', None, 9, 3, 0.0, None, None, None, 0.0, None, None, 0.0]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR-1': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [11]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'ANN': [15]}, {'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, 1, 2, 19, False, None], 'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'ANN': [11]}, {'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'SVM': [34.05017443007109, 'linear', 24, 0.001, 0.6819152317877569, False, True, 0.001, 200, 'balanced', True, -1, 'ovr'], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None], 'DT-1': ['gini', 'best', 110, 6, 3, 0.0, 'sqrt', 29, None, 0.0, None, None], 'ANN': [11]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-1': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-2': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'ANN': [11]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, 1, 25, 31, False, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None], 'LR': ['l2', False, 0.0001, 432, True, 35.781403706811055, None, None, 'lbfgs', 139, 'ovr', 3, True, 1]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'RF-1': [168, 'gini', None, 6, 6, 0.0, 'log2', None, 0.0, None, False, False, None, 35, 56, False, 'balanced_subsample', 0.0, None], 'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-3': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'KNN': [2, 'uniform', 'auto', 100, 9, 'minkowski', None, None], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'ANN': [11]}, {'LR': ['l2', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, 1], 'DT': ['entropy', 'best', 30, 4, 2, 0.0, 'auto', 29, None, 0.0, None, None], 'LR-1': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, 1, None, 11, False, 'balanced'], 'LR': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'RF': [182, 'entropy', None, 2, 7, 0.0, 'log2', None, 0.0, None, False, False, None, 25, 31, False, None, 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, None, 23, 83, False, None, 0.0, None]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'LR': ['l1', False, 0.0001, 29.11751571756812, True, 4.314227682695792, None, 19, 'saga', 143, 'ovr', 7, False, None, 0.050970430431922065], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'LR-1': ['l2', False, 0.0001, 60.81019857941157, True, 35.781403706811055, None, None, 'saga', 139, 'ovr', 3, True, 1]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-2': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-1': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF-2': [149, 'gini', None, 5, 7, 0.0, 'sqrt', None, 0.0, None, False, False, None, 2, 19, False, None, 0.0, None], 'RF-3': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'SVM': [86.1077970069117, 'linear', 47, 0.001, 0.024398332864562833, False, True, 0.001, 200, None, True, -1, 'ovr', False, 71], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'DT-1': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'ANN': [11]}, {'DT': ['gini', 'best', None, 5, 9, 0.0, None, 29, None, 0.0, None, None, 0.0], 'RF': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF-1': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'RF-1': [128, 'gini', None, 8, 8, 0.0, 'sqrt', None, 0.0, None, True, False, None, None, 11, False, 'balanced', 0.0, None], 'RF': [142, 'gini', None, 9, 7, 0.0, 'sqrt', None, 0.0, None, True, False, 1, 23, 83, False, None]}, {'DT': ['gini', 'best', 110, 6, 3, 0.0, 'sqrt', 29, None, 0.0, None, None], 'ANN': [11]}]\n",
    "\n",
    "        if gen<20:\n",
    "            print(gen)\n",
    "            print(done)\n",
    "        else:\n",
    "            for chromosome in population:\n",
    "                if chromosome in done:\n",
    "                    print(\"chromosome\", chromosome)\n",
    "                    fit = all_fitness[done.index(chromosome)]\n",
    "                    info = all_info[done.index(chromosome)]\n",
    "                    model=all_mod[done.index(chromosome)]\n",
    "                    all_fitness.append(fit)\n",
    "                    all_info.append(info)\n",
    "                    all_mod.append(model)\n",
    "                    done.append(chromosome)\n",
    "                    print(\"done out of 63\", len(done))\n",
    "                else:\n",
    "                    print(\"chromosome\", chromosome)\n",
    "                    print(ii)\n",
    "                    fit, info,model = fitness(chromosome,X_train,y_train,X_test,y_test,count=ii,gen=gen)\n",
    "                    all_fitness.append(fit)\n",
    "                    all_info.append(info)\n",
    "                    all_mod.append(model)\n",
    "                    done.append(chromosome)\n",
    "                    print(\"done out of 63\", len(done))\n",
    "                    if gen ==0 or gen ==99:\n",
    "                                ii+=1\n",
    "        if gen >19:\n",
    "          #check if converged\n",
    "            if best_fits!={} and gen >0:\n",
    "                if(str(list(best_fits[str(gen-1)])[0])== str(population[all_fitness.index(max(all_fitness))])):\n",
    "                    print(\"converged\")\n",
    "                    convergence_count = convergence_count + 1\n",
    "                else:\n",
    "                    convergence_count=0\n",
    "            #get best fit\n",
    "            index = all_fitness.index(max(all_fitness))\n",
    "            print(\"in gen\",gen)\n",
    "            print(\"best fitness\",max(all_fitness))\n",
    "            print(\"chromosome\",population[index])\n",
    "            best_fits[str(gen)]={str(population[index]):[max(all_fitness),all_info[index]]}\n",
    "            print(\"best_fits\",best_fits)\n",
    "            print(\"all fitness\",all_fitness)\n",
    "            print(\"all_info\",all_info)\n",
    "            try:\n",
    "                if gen ==0:\n",
    "                    models.append(all_mod[index])\n",
    "                    emod=all_mod[index]\n",
    "                    print(index)\n",
    "                    filename = 'gen0_modelexp1.sav'\n",
    "                    with open(filename, \"wb\") as file:\n",
    "                      pickle.dump(emod, file)\n",
    "                if gen == 99:\n",
    "                    models.append(all_mod[index])\n",
    "                    emod=all_mod[index]\n",
    "                    print(index)\n",
    "                    filename = 'gen99_modelexp1.sav'\n",
    "                    with open(filename, \"wb\") as file:\n",
    "                      pickle.dump(emod, file)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"not saved\")\n",
    "            if gen ==99   :\n",
    "                mods.append(all_mod[index])\n",
    "       \n",
    "        gen=gen+1\n",
    "        #check stop conditions and generate new data\n",
    "        if gen >20 and gen<max_generation and convergence_count<convergence_rate:\n",
    "            population=generateNewPopulation(population,X_train=X_train,y_train=y_train,X_val=X_val,y_val=y_val,crossover_prob=crossover_prob,mutation_prob=mutation_prob,elitism_range=elitism_range,all_fitness=all_fitness)\n",
    "        #increase mutation rate\n",
    "        if (convergence_count >0 and convergence_count% 5==0 ):\n",
    "            if mutation <0.85:\n",
    "                mutation_prob+=0.1\n",
    "                convergence_count=0\n",
    "    return best_fits, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ8NXqAh_t27",
    "outputId": "8c398027-2b3e-4008-c292-137fb254750a"
   },
   "outputs": [],
   "source": [
    "print(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2Yp7xXp_t27"
   },
   "outputs": [],
   "source": [
    "#x1, y1=balanced_subsample(X,y,5000)\n",
    "#x1=np.array(x1)\n",
    "#savetxt('dataexp1x.csv', x1, delimiter=',')\n",
    "#savetxt('dataexp1y.csv', y1, delimiter=',')\n",
    "X=loadtxt(\"dataexp1x.csv\", delimiter=\",\")\n",
    "y=loadtxt(\"dataexp1y.csv\", delimiter=\",\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fits,models=GA()\n",
    "print(best_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK-egBac_t27",
    "outputId": "1609e4b6-8acc-4e3c-c175-f6efb5b5713d",
    "scrolled": false
   },
   "source": [
    "best_fits,models=GA()\n",
    "print(best_fits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzlOTx-O_t28"
   },
   "outputs": [],
   "source": [
    "chromosome0=best_fits['0']\n",
    "chromosome99=best_fits['99']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqcDslydVIa1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSKo3xxs_t28"
   },
   "source": [
    "#validate on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00YD0swt_t28"
   },
   "outputs": [],
   "source": [
    "print(\"equinox\")\n",
    "data = arff.loadarff('Equinox-3.4-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yS0pk6XO_t28"
   },
   "outputs": [],
   "source": [
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwN-rrvW_t28"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iq3oMJUJ_t29"
   },
   "outputs": [],
   "source": [
    "print(\"Mylyn\")\n",
    "data = arff.loadarff('Mylyn-3.1-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVrSMFQk_t29"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PahiSoP1_t29"
   },
   "outputs": [],
   "source": [
    "print(\"Eclipse_JDT_Core\")\n",
    "\n",
    "data = arff.loadarff('Eclipse_JDT_Core-3.4-OSA.arff')\n",
    "data_value = pd.DataFrame(data[0])\n",
    "PROMISE_data = data_value[:, 0:60]\n",
    "PROMISE_target = data_value[:,60]\n",
    "PROMISE_data_minmax_scalled = preprocessing.MinMaxScaler().fit_transform(PROMISE_data)\n",
    "X=PROMISE_data_minmax_scalled\n",
    "y=PROMISE_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-79qIW_7_t29"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlvp5_pH_t29"
   },
   "outputs": [],
   "source": [
    "print(\"all\")\n",
    "BugPrediction_target,BugPrediction_data_normalized,BugPrediction_data_minmax_scalled,BugPrediction_data_standardized=BugPredictionDatasetPreprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvvFVUMT_t2-"
   },
   "outputs": [],
   "source": [
    "X=BugPrediction_data_minmax_scalled\n",
    "y=BugPrediction_target\n",
    "y_pred0=model0.predict(X)\n",
    "cm=confusion_matrix(y, y_pred0)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXZ6MsKa_t2-"
   },
   "outputs": [],
   "source": [
    "y_pred99=model99.predict(X)\n",
    "cm=confusion_matrix(y, y_pred99)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print( cm)\n",
    "accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"accuracy:\",accuracy)\n",
    "mcc= ((TP *TN) - (FP *FN))/(sqrt((TP +FP)*(TP +FN)*(TN +FP)*(TN +FN)))\n",
    "print(\"mcc:\",mcc)\n",
    "precision =(TP/(TP+FP))\n",
    "recall= (TP/(TP+FN))\n",
    "f1_score= 2 *(precision*recall)/(precision+recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "commbined.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
